{"cells":[{"cell_type":"markdown","metadata":{"id":"_JKeWTy4pn2L"},"source":["## Principal component analysis (PCA)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"LFvXGZ-AmVI3","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1675497830153,"user_tz":300,"elapsed":18661,"user":{"displayName":"Randy Huynh","userId":"07672825704789203793"}},"outputId":"d2b1ea44-4f73-4493-8d45-73671200c8a1"},"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}],"source":["from google.colab import drive\n","drive.mount('/content/drive')"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Fc1_IlMzpn2S"},"outputs":[],"source":["import numpy as np\n","import pandas as pd\n","\n","import matplotlib.pyplot as plt\n","import pylab as plt\n","import seaborn as sb\n","from IPython.display import Image\n","from IPython.core.display import HTML \n","from pylab import rcParams\n","\n","import sklearn\n","from sklearn import datasets"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"algntS4Rpn2d"},"outputs":[],"source":["from sklearn import decomposition\n","from sklearn.decomposition import PCA"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Aq45aQmypn2h"},"outputs":[],"source":["%matplotlib inline\n","rcParams['figure.figsize'] = 5, 4\n","sb.set_style('whitegrid')"]},{"cell_type":"markdown","metadata":{"id":"ab55duq0pn2k"},"source":["### PCA on the iris dataset"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"uKYIlzM0mrlC","colab":{"base_uri":"https://localhost:8080/","height":206},"executionInfo":{"status":"ok","timestamp":1675497835640,"user_tz":300,"elapsed":658,"user":{"displayName":"Randy Huynh","userId":"07672825704789203793"}},"outputId":"30d27993-2bec-4eac-8d71-6f14ae35a6e0"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["   Sample ID  Pollen\n","0          0       0\n","1          1       0\n","2          2       0\n","3          3       0\n","4          4       0"],"text/html":["\n","  <div id=\"df-6348b895-b703-4cd9-a1c8-e68b7050b5a9\">\n","    <div class=\"colab-df-container\">\n","      <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>Sample ID</th>\n","      <th>Pollen</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>0</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>1</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>2</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>3</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>4</td>\n","      <td>0</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>\n","      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-6348b895-b703-4cd9-a1c8-e68b7050b5a9')\"\n","              title=\"Convert this dataframe to an interactive table.\"\n","              style=\"display:none;\">\n","        \n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","       width=\"24px\">\n","    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n","    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n","  </svg>\n","      </button>\n","      \n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      flex-wrap:wrap;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","      <script>\n","        const buttonEl =\n","          document.querySelector('#df-6348b895-b703-4cd9-a1c8-e68b7050b5a9 button.colab-df-convert');\n","        buttonEl.style.display =\n","          google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","        async function convertToInteractive(key) {\n","          const element = document.querySelector('#df-6348b895-b703-4cd9-a1c8-e68b7050b5a9');\n","          const dataTable =\n","            await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                     [key], {});\n","          if (!dataTable) return;\n","\n","          const docLinkHtml = 'Like what you see? Visit the ' +\n","            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","            + ' to learn more about interactive tables.';\n","          element.innerHTML = '';\n","          dataTable['output_type'] = 'display_data';\n","          await google.colab.output.renderOutput(dataTable, element);\n","          const docLink = document.createElement('div');\n","          docLink.innerHTML = docLinkHtml;\n","          element.appendChild(docLink);\n","        }\n","      </script>\n","    </div>\n","  </div>\n","  "]},"metadata":{},"execution_count":5}],"source":["#Import labels (these will the target variables we will use to predict)\n","labels = pd.read_csv(\"/content/drive/MyDrive/ENG 4000/labels.csv\") \n","labels.head()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"ghmwYrNDm2bu","colab":{"base_uri":"https://localhost:8080/","height":297},"executionInfo":{"status":"ok","timestamp":1675497837088,"user_tz":300,"elapsed":1455,"user":{"displayName":"Randy Huynh","userId":"07672825704789203793"}},"outputId":"7f41dacb-fe1e-4689-eec6-9fd77e8e0f59"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["   Sample ID  350-400 nm, t=0  350-400 nm, t=1  350-400 nm, t=2  \\\n","0          0        -0.010454         0.000201         0.010856   \n","1          1         0.119942         0.184249         0.248555   \n","2          2        -0.016149         0.063383         0.142915   \n","3          3         0.067116         0.198401         0.329687   \n","4          4        -0.043760         0.090762         0.225284   \n","\n","   350-400 nm, t=3  350-400 nm, t=4  350-400 nm, t=5  350-400 nm, t=6  \\\n","0         0.114194         0.217531         0.166868         0.116204   \n","1         0.236994         0.225434         0.098988        -0.028179   \n","2         0.286637         0.430359         0.262414         0.094469   \n","3         0.366400         0.403114         0.235325         0.067536   \n","4         0.214749         0.204214         0.213128         0.222042   \n","\n","   350-400 nm, t=7  350-400 nm, t=8  ...  672-800 nm, t=14  672-800 nm, t=15  \\\n","0         0.109168         0.102131  ...         -0.015480         -0.016084   \n","1        -0.054191        -0.081647  ...          0.013006          0.028179   \n","2         0.082761         0.071054  ...          0.024223          0.023819   \n","3         0.063644         0.059752  ...         -0.008100         -0.006627   \n","4         0.133712         0.044571  ...         -0.059157         -0.068882   \n","\n","   672-800 nm, t=16  672-800 nm, t=17  672-800 nm, t=18  672-800 nm, t=19  \\\n","0         -0.017089         -0.014877         -0.013068         -0.003418   \n","1          0.043353          0.057081          0.070809          0.057081   \n","2          0.023415          0.014534          0.005248         -0.009285   \n","3         -0.005365         -0.001999          0.001262          0.003787   \n","4         -0.080227         -0.052674         -0.026742         -0.004052   \n","\n","   672-800 nm, t=20  672-800 nm, t=21  672-800 nm, t=22  672-800 nm, t=23  \n","0          0.006031          0.011460          0.016888          0.013872  \n","1          0.043353          0.013728         -0.016618         -0.026012  \n","2         -0.024627         -0.027049         -0.030279         -0.015745  \n","3          0.006312          0.007469          0.008626          0.004103  \n","4          0.017828          0.031605          0.045381          0.020259  \n","\n","[5 rows x 97 columns]"],"text/html":["\n","  <div id=\"df-e87df947-e2e2-40b4-a848-ddebc5c1427b\">\n","    <div class=\"colab-df-container\">\n","      <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>Sample ID</th>\n","      <th>350-400 nm, t=0</th>\n","      <th>350-400 nm, t=1</th>\n","      <th>350-400 nm, t=2</th>\n","      <th>350-400 nm, t=3</th>\n","      <th>350-400 nm, t=4</th>\n","      <th>350-400 nm, t=5</th>\n","      <th>350-400 nm, t=6</th>\n","      <th>350-400 nm, t=7</th>\n","      <th>350-400 nm, t=8</th>\n","      <th>...</th>\n","      <th>672-800 nm, t=14</th>\n","      <th>672-800 nm, t=15</th>\n","      <th>672-800 nm, t=16</th>\n","      <th>672-800 nm, t=17</th>\n","      <th>672-800 nm, t=18</th>\n","      <th>672-800 nm, t=19</th>\n","      <th>672-800 nm, t=20</th>\n","      <th>672-800 nm, t=21</th>\n","      <th>672-800 nm, t=22</th>\n","      <th>672-800 nm, t=23</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>0</td>\n","      <td>-0.010454</td>\n","      <td>0.000201</td>\n","      <td>0.010856</td>\n","      <td>0.114194</td>\n","      <td>0.217531</td>\n","      <td>0.166868</td>\n","      <td>0.116204</td>\n","      <td>0.109168</td>\n","      <td>0.102131</td>\n","      <td>...</td>\n","      <td>-0.015480</td>\n","      <td>-0.016084</td>\n","      <td>-0.017089</td>\n","      <td>-0.014877</td>\n","      <td>-0.013068</td>\n","      <td>-0.003418</td>\n","      <td>0.006031</td>\n","      <td>0.011460</td>\n","      <td>0.016888</td>\n","      <td>0.013872</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>1</td>\n","      <td>0.119942</td>\n","      <td>0.184249</td>\n","      <td>0.248555</td>\n","      <td>0.236994</td>\n","      <td>0.225434</td>\n","      <td>0.098988</td>\n","      <td>-0.028179</td>\n","      <td>-0.054191</td>\n","      <td>-0.081647</td>\n","      <td>...</td>\n","      <td>0.013006</td>\n","      <td>0.028179</td>\n","      <td>0.043353</td>\n","      <td>0.057081</td>\n","      <td>0.070809</td>\n","      <td>0.057081</td>\n","      <td>0.043353</td>\n","      <td>0.013728</td>\n","      <td>-0.016618</td>\n","      <td>-0.026012</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>2</td>\n","      <td>-0.016149</td>\n","      <td>0.063383</td>\n","      <td>0.142915</td>\n","      <td>0.286637</td>\n","      <td>0.430359</td>\n","      <td>0.262414</td>\n","      <td>0.094469</td>\n","      <td>0.082761</td>\n","      <td>0.071054</td>\n","      <td>...</td>\n","      <td>0.024223</td>\n","      <td>0.023819</td>\n","      <td>0.023415</td>\n","      <td>0.014534</td>\n","      <td>0.005248</td>\n","      <td>-0.009285</td>\n","      <td>-0.024627</td>\n","      <td>-0.027049</td>\n","      <td>-0.030279</td>\n","      <td>-0.015745</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>3</td>\n","      <td>0.067116</td>\n","      <td>0.198401</td>\n","      <td>0.329687</td>\n","      <td>0.366400</td>\n","      <td>0.403114</td>\n","      <td>0.235325</td>\n","      <td>0.067536</td>\n","      <td>0.063644</td>\n","      <td>0.059752</td>\n","      <td>...</td>\n","      <td>-0.008100</td>\n","      <td>-0.006627</td>\n","      <td>-0.005365</td>\n","      <td>-0.001999</td>\n","      <td>0.001262</td>\n","      <td>0.003787</td>\n","      <td>0.006312</td>\n","      <td>0.007469</td>\n","      <td>0.008626</td>\n","      <td>0.004103</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>4</td>\n","      <td>-0.043760</td>\n","      <td>0.090762</td>\n","      <td>0.225284</td>\n","      <td>0.214749</td>\n","      <td>0.204214</td>\n","      <td>0.213128</td>\n","      <td>0.222042</td>\n","      <td>0.133712</td>\n","      <td>0.044571</td>\n","      <td>...</td>\n","      <td>-0.059157</td>\n","      <td>-0.068882</td>\n","      <td>-0.080227</td>\n","      <td>-0.052674</td>\n","      <td>-0.026742</td>\n","      <td>-0.004052</td>\n","      <td>0.017828</td>\n","      <td>0.031605</td>\n","      <td>0.045381</td>\n","      <td>0.020259</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>5 rows × 97 columns</p>\n","</div>\n","      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-e87df947-e2e2-40b4-a848-ddebc5c1427b')\"\n","              title=\"Convert this dataframe to an interactive table.\"\n","              style=\"display:none;\">\n","        \n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","       width=\"24px\">\n","    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n","    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n","  </svg>\n","      </button>\n","      \n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      flex-wrap:wrap;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","      <script>\n","        const buttonEl =\n","          document.querySelector('#df-e87df947-e2e2-40b4-a848-ddebc5c1427b button.colab-df-convert');\n","        buttonEl.style.display =\n","          google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","        async function convertToInteractive(key) {\n","          const element = document.querySelector('#df-e87df947-e2e2-40b4-a848-ddebc5c1427b');\n","          const dataTable =\n","            await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                     [key], {});\n","          if (!dataTable) return;\n","\n","          const docLinkHtml = 'Like what you see? Visit the ' +\n","            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","            + ' to learn more about interactive tables.';\n","          element.innerHTML = '';\n","          dataTable['output_type'] = 'display_data';\n","          await google.colab.output.renderOutput(dataTable, element);\n","          const docLink = document.createElement('div');\n","          docLink.innerHTML = docLinkHtml;\n","          element.appendChild(docLink);\n","        }\n","      </script>\n","    </div>\n","  </div>\n","  "]},"metadata":{},"execution_count":6}],"source":["#Import features (these will the be data we use to predict the labels)\n","lifetime = pd.read_csv(\"/content/drive/MyDrive/ENG 4000/lifetime.csv\")\n","lifetime.head() #Head allows us to show the first 4 rows of the data"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"109Lltrsm4Ed","colab":{"base_uri":"https://localhost:8080/","height":314},"executionInfo":{"status":"ok","timestamp":1675497838345,"user_tz":300,"elapsed":1261,"user":{"displayName":"Randy Huynh","userId":"07672825704789203793"}},"outputId":"e5efbc3b-956e-4f24-8277-9ac020bee683"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["   Sample ID  350 nm, t=0  364 nm, t=0  379 nm, t=0  393 nm, t=0  408 nm, t=0  \\\n","0          0     0.129278     0.041910     0.121054     0.496012     0.800121   \n","1          1    -0.011963     0.086481     0.099374     0.132618     0.527263   \n","2          2    -0.006165     0.110295     0.157199     0.232229     0.404684   \n","3          3    -0.005657     0.036070     0.101411     0.245322     0.426752   \n","4          4    -0.007325     0.063621     0.125746     0.214150     0.409600   \n","\n","   422 nm, t=0  437 nm, t=0  451 nm, t=0  466 nm, t=0  ...  669 nm, t=3  \\\n","0     1.000000     0.853183     0.962091     0.745947  ...     0.000000   \n","1     0.820056     0.939995     1.000000     0.914903  ...     0.000000   \n","2     0.739406     1.000000     0.887348     0.716564  ...     0.000000   \n","3     0.674580     0.992005     1.000000     0.851382  ...    -0.000191   \n","4     0.782647     1.000000     0.770002     0.544802  ...     0.001524   \n","\n","   683 nm, t=3  698 nm, t=3  712 nm, t=3  727 nm, t=3  741 nm, t=3  \\\n","0     0.000000          0.0     0.000144    -0.000576    -0.000790   \n","1     0.000000          0.0     0.000286    -0.001143    -0.001451   \n","2     0.000000          0.0     0.000000     0.000000    -0.000157   \n","3     0.000048          0.0     0.000000     0.000000     0.000000   \n","4    -0.000381          0.0     0.000466    -0.001863    -0.001919   \n","\n","   756 nm, t=3  770 nm, t=3  785 nm, t=3   800 nm, t=3  \n","0    -0.000681    -0.000004    -0.000105 -1.480000e-19  \n","1    -0.001815    -0.000667    -0.000672 -9.580000e-19  \n","2     0.000630     0.000892     0.000630 -3.147950e-04  \n","3    -0.000130     0.000519     0.000606  1.038110e-03  \n","4    -0.004657    -0.003952    -0.003444 -4.060000e-18  \n","\n","[5 rows x 129 columns]"],"text/html":["\n","  <div id=\"df-073e0cca-b931-420b-9409-e1975cde1567\">\n","    <div class=\"colab-df-container\">\n","      <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>Sample ID</th>\n","      <th>350 nm, t=0</th>\n","      <th>364 nm, t=0</th>\n","      <th>379 nm, t=0</th>\n","      <th>393 nm, t=0</th>\n","      <th>408 nm, t=0</th>\n","      <th>422 nm, t=0</th>\n","      <th>437 nm, t=0</th>\n","      <th>451 nm, t=0</th>\n","      <th>466 nm, t=0</th>\n","      <th>...</th>\n","      <th>669 nm, t=3</th>\n","      <th>683 nm, t=3</th>\n","      <th>698 nm, t=3</th>\n","      <th>712 nm, t=3</th>\n","      <th>727 nm, t=3</th>\n","      <th>741 nm, t=3</th>\n","      <th>756 nm, t=3</th>\n","      <th>770 nm, t=3</th>\n","      <th>785 nm, t=3</th>\n","      <th>800 nm, t=3</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>0</td>\n","      <td>0.129278</td>\n","      <td>0.041910</td>\n","      <td>0.121054</td>\n","      <td>0.496012</td>\n","      <td>0.800121</td>\n","      <td>1.000000</td>\n","      <td>0.853183</td>\n","      <td>0.962091</td>\n","      <td>0.745947</td>\n","      <td>...</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.0</td>\n","      <td>0.000144</td>\n","      <td>-0.000576</td>\n","      <td>-0.000790</td>\n","      <td>-0.000681</td>\n","      <td>-0.000004</td>\n","      <td>-0.000105</td>\n","      <td>-1.480000e-19</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>1</td>\n","      <td>-0.011963</td>\n","      <td>0.086481</td>\n","      <td>0.099374</td>\n","      <td>0.132618</td>\n","      <td>0.527263</td>\n","      <td>0.820056</td>\n","      <td>0.939995</td>\n","      <td>1.000000</td>\n","      <td>0.914903</td>\n","      <td>...</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.0</td>\n","      <td>0.000286</td>\n","      <td>-0.001143</td>\n","      <td>-0.001451</td>\n","      <td>-0.001815</td>\n","      <td>-0.000667</td>\n","      <td>-0.000672</td>\n","      <td>-9.580000e-19</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>2</td>\n","      <td>-0.006165</td>\n","      <td>0.110295</td>\n","      <td>0.157199</td>\n","      <td>0.232229</td>\n","      <td>0.404684</td>\n","      <td>0.739406</td>\n","      <td>1.000000</td>\n","      <td>0.887348</td>\n","      <td>0.716564</td>\n","      <td>...</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.0</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>-0.000157</td>\n","      <td>0.000630</td>\n","      <td>0.000892</td>\n","      <td>0.000630</td>\n","      <td>-3.147950e-04</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>3</td>\n","      <td>-0.005657</td>\n","      <td>0.036070</td>\n","      <td>0.101411</td>\n","      <td>0.245322</td>\n","      <td>0.426752</td>\n","      <td>0.674580</td>\n","      <td>0.992005</td>\n","      <td>1.000000</td>\n","      <td>0.851382</td>\n","      <td>...</td>\n","      <td>-0.000191</td>\n","      <td>0.000048</td>\n","      <td>0.0</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>-0.000130</td>\n","      <td>0.000519</td>\n","      <td>0.000606</td>\n","      <td>1.038110e-03</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>4</td>\n","      <td>-0.007325</td>\n","      <td>0.063621</td>\n","      <td>0.125746</td>\n","      <td>0.214150</td>\n","      <td>0.409600</td>\n","      <td>0.782647</td>\n","      <td>1.000000</td>\n","      <td>0.770002</td>\n","      <td>0.544802</td>\n","      <td>...</td>\n","      <td>0.001524</td>\n","      <td>-0.000381</td>\n","      <td>0.0</td>\n","      <td>0.000466</td>\n","      <td>-0.001863</td>\n","      <td>-0.001919</td>\n","      <td>-0.004657</td>\n","      <td>-0.003952</td>\n","      <td>-0.003444</td>\n","      <td>-4.060000e-18</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>5 rows × 129 columns</p>\n","</div>\n","      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-073e0cca-b931-420b-9409-e1975cde1567')\"\n","              title=\"Convert this dataframe to an interactive table.\"\n","              style=\"display:none;\">\n","        \n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","       width=\"24px\">\n","    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n","    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n","  </svg>\n","      </button>\n","      \n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      flex-wrap:wrap;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","      <script>\n","        const buttonEl =\n","          document.querySelector('#df-073e0cca-b931-420b-9409-e1975cde1567 button.colab-df-convert');\n","        buttonEl.style.display =\n","          google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","        async function convertToInteractive(key) {\n","          const element = document.querySelector('#df-073e0cca-b931-420b-9409-e1975cde1567');\n","          const dataTable =\n","            await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                     [key], {});\n","          if (!dataTable) return;\n","\n","          const docLinkHtml = 'Like what you see? Visit the ' +\n","            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","            + ' to learn more about interactive tables.';\n","          element.innerHTML = '';\n","          dataTable['output_type'] = 'display_data';\n","          await google.colab.output.renderOutput(dataTable, element);\n","          const docLink = document.createElement('div');\n","          docLink.innerHTML = docLinkHtml;\n","          element.appendChild(docLink);\n","        }\n","      </script>\n","    </div>\n","  </div>\n","  "]},"metadata":{},"execution_count":7}],"source":["spectrum = pd.read_csv(\"/content/drive/MyDrive/ENG 4000/spectrum.csv\")\n","spectrum.head()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"W_ho2c26m5nh","colab":{"base_uri":"https://localhost:8080/","height":317},"executionInfo":{"status":"ok","timestamp":1675497852141,"user_tz":300,"elapsed":13799,"user":{"displayName":"Randy Huynh","userId":"07672825704789203793"}},"outputId":"a2522ca2-d711-4d7a-eaa8-ebfb6202df7c"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["   Sample ID  angle=-37.5, t=0  angle=-37.5, t=1  angle=-37.5, t=2  \\\n","0          0               0.0               0.0               0.0   \n","1          1               0.0               0.0               0.0   \n","2          2               0.0               0.0               0.0   \n","3          3               0.0               0.0               0.0   \n","4          4               0.0               0.0               0.0   \n","\n","   angle=-37.5, t=3  angle=-37.5, t=4  angle=-37.5, t=5  angle=-37.5, t=6  \\\n","0               0.0               0.0               0.0               0.0   \n","1               0.0               0.0               0.0               0.0   \n","2               0.0               0.0               0.0               0.0   \n","3               0.0               0.0               0.0               0.0   \n","4               0.0               0.0               0.0               0.0   \n","\n","   angle=-37.5, t=7  angle=-37.5, t=8  ...  angle=37.5, t=110  \\\n","0               0.0               0.0  ...           0.000000   \n","1               0.0               0.0  ...           0.000000   \n","2               0.0               0.0  ...           0.000000   \n","3               0.0               0.0  ...         982.383616   \n","4               0.0               0.0  ...           0.000000   \n","\n","   angle=37.5, t=111  angle=37.5, t=112  angle=37.5, t=113  angle=37.5, t=114  \\\n","0            0.00000           0.000000           0.000000           0.000000   \n","1            0.00000           0.000000           0.000000           0.000000   \n","2            0.00000           0.000000           0.000000           0.000000   \n","3         1002.18053        1034.797552         892.183468         840.017425   \n","4            0.00000           0.000000           0.000000           0.000000   \n","\n","   angle=37.5, t=115  angle=37.5, t=116  angle=37.5, t=117  angle=37.5, t=118  \\\n","0           0.000000           0.000000            0.00000           0.000000   \n","1           0.000000           0.000000            0.00000           0.000000   \n","2           0.000000           0.000000            0.00000           0.000000   \n","3         739.383196         740.476799          600.65502         695.104062   \n","4           0.000000           0.000000            0.00000           0.000000   \n","\n","   angle=37.5, t=119  \n","0           0.000000  \n","1           0.000000  \n","2           0.000000  \n","3         873.792882  \n","4           0.000000  \n","\n","[5 rows x 2401 columns]"],"text/html":["\n","  <div id=\"df-61b88f2e-d3a7-4b63-8bc2-8a4e8bdb4016\">\n","    <div class=\"colab-df-container\">\n","      <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>Sample ID</th>\n","      <th>angle=-37.5, t=0</th>\n","      <th>angle=-37.5, t=1</th>\n","      <th>angle=-37.5, t=2</th>\n","      <th>angle=-37.5, t=3</th>\n","      <th>angle=-37.5, t=4</th>\n","      <th>angle=-37.5, t=5</th>\n","      <th>angle=-37.5, t=6</th>\n","      <th>angle=-37.5, t=7</th>\n","      <th>angle=-37.5, t=8</th>\n","      <th>...</th>\n","      <th>angle=37.5, t=110</th>\n","      <th>angle=37.5, t=111</th>\n","      <th>angle=37.5, t=112</th>\n","      <th>angle=37.5, t=113</th>\n","      <th>angle=37.5, t=114</th>\n","      <th>angle=37.5, t=115</th>\n","      <th>angle=37.5, t=116</th>\n","      <th>angle=37.5, t=117</th>\n","      <th>angle=37.5, t=118</th>\n","      <th>angle=37.5, t=119</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>...</td>\n","      <td>0.000000</td>\n","      <td>0.00000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.00000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>1</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>...</td>\n","      <td>0.000000</td>\n","      <td>0.00000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.00000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>2</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>...</td>\n","      <td>0.000000</td>\n","      <td>0.00000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.00000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>3</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>...</td>\n","      <td>982.383616</td>\n","      <td>1002.18053</td>\n","      <td>1034.797552</td>\n","      <td>892.183468</td>\n","      <td>840.017425</td>\n","      <td>739.383196</td>\n","      <td>740.476799</td>\n","      <td>600.65502</td>\n","      <td>695.104062</td>\n","      <td>873.792882</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>4</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>...</td>\n","      <td>0.000000</td>\n","      <td>0.00000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.00000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>5 rows × 2401 columns</p>\n","</div>\n","      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-61b88f2e-d3a7-4b63-8bc2-8a4e8bdb4016')\"\n","              title=\"Convert this dataframe to an interactive table.\"\n","              style=\"display:none;\">\n","        \n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","       width=\"24px\">\n","    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n","    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n","  </svg>\n","      </button>\n","      \n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      flex-wrap:wrap;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","      <script>\n","        const buttonEl =\n","          document.querySelector('#df-61b88f2e-d3a7-4b63-8bc2-8a4e8bdb4016 button.colab-df-convert');\n","        buttonEl.style.display =\n","          google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","        async function convertToInteractive(key) {\n","          const element = document.querySelector('#df-61b88f2e-d3a7-4b63-8bc2-8a4e8bdb4016');\n","          const dataTable =\n","            await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                     [key], {});\n","          if (!dataTable) return;\n","\n","          const docLinkHtml = 'Like what you see? Visit the ' +\n","            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","            + ' to learn more about interactive tables.';\n","          element.innerHTML = '';\n","          dataTable['output_type'] = 'display_data';\n","          await google.colab.output.renderOutput(dataTable, element);\n","          const docLink = document.createElement('div');\n","          docLink.innerHTML = docLinkHtml;\n","          element.appendChild(docLink);\n","        }\n","      </script>\n","    </div>\n","  </div>\n","  "]},"metadata":{},"execution_count":8}],"source":["scattering = pd.read_csv(\"/content/drive/MyDrive/ENG 4000/scattering.csv\")\n","scattering.head()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"lIwZLBHmm7KS","colab":{"base_uri":"https://localhost:8080/","height":206},"executionInfo":{"status":"ok","timestamp":1675497852310,"user_tz":300,"elapsed":174,"user":{"displayName":"Randy Huynh","userId":"07672825704789203793"}},"outputId":"3b672615-a155-471a-ef65-1a94a994dad1"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["   Unnamed: 0       size\n","0           0  12.513989\n","1           1  19.461646\n","2           2  25.726931\n","3           3  35.178985\n","4           4   4.672308"],"text/html":["\n","  <div id=\"df-f80ff849-70aa-4434-920c-ef656c895bfa\">\n","    <div class=\"colab-df-container\">\n","      <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>Unnamed: 0</th>\n","      <th>size</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>0</td>\n","      <td>12.513989</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>1</td>\n","      <td>19.461646</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>2</td>\n","      <td>25.726931</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>3</td>\n","      <td>35.178985</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>4</td>\n","      <td>4.672308</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>\n","      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-f80ff849-70aa-4434-920c-ef656c895bfa')\"\n","              title=\"Convert this dataframe to an interactive table.\"\n","              style=\"display:none;\">\n","        \n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","       width=\"24px\">\n","    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n","    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n","  </svg>\n","      </button>\n","      \n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      flex-wrap:wrap;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","      <script>\n","        const buttonEl =\n","          document.querySelector('#df-f80ff849-70aa-4434-920c-ef656c895bfa button.colab-df-convert');\n","        buttonEl.style.display =\n","          google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","        async function convertToInteractive(key) {\n","          const element = document.querySelector('#df-f80ff849-70aa-4434-920c-ef656c895bfa');\n","          const dataTable =\n","            await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                     [key], {});\n","          if (!dataTable) return;\n","\n","          const docLinkHtml = 'Like what you see? Visit the ' +\n","            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","            + ' to learn more about interactive tables.';\n","          element.innerHTML = '';\n","          dataTable['output_type'] = 'display_data';\n","          await google.colab.output.renderOutput(dataTable, element);\n","          const docLink = document.createElement('div');\n","          docLink.innerHTML = docLinkHtml;\n","          element.appendChild(docLink);\n","        }\n","      </script>\n","    </div>\n","  </div>\n","  "]},"metadata":{},"execution_count":9}],"source":["size = pd.read_csv(\"/content/drive/MyDrive/ENG 4000/size.csv\")\n","size.head()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"oLVH6QE2m8n0","colab":{"base_uri":"https://localhost:8080/","height":206},"executionInfo":{"status":"ok","timestamp":1675497852652,"user_tz":300,"elapsed":347,"user":{"displayName":"Randy Huynh","userId":"07672825704789203793"}},"outputId":"e233588f-46dd-4c85-db23-a9187637dad3"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["   Unnamed: 0  lt feature 1  lt feature 2  lt feature 3  lt feature 4\n","0           0      0.280202           1.0      0.134079     -0.008439\n","1           1      0.481173           1.0      0.266975      0.140432\n","2           2      0.519641           1.0      0.145762      0.002905\n","3           3      0.639556           1.0      0.305319     -0.015814\n","4           4      0.624575           1.0      0.396259     -0.059949"],"text/html":["\n","  <div id=\"df-caf10970-5014-41a1-9f7f-3f6bcd79dfe3\">\n","    <div class=\"colab-df-container\">\n","      <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>Unnamed: 0</th>\n","      <th>lt feature 1</th>\n","      <th>lt feature 2</th>\n","      <th>lt feature 3</th>\n","      <th>lt feature 4</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>0</td>\n","      <td>0.280202</td>\n","      <td>1.0</td>\n","      <td>0.134079</td>\n","      <td>-0.008439</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>1</td>\n","      <td>0.481173</td>\n","      <td>1.0</td>\n","      <td>0.266975</td>\n","      <td>0.140432</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>2</td>\n","      <td>0.519641</td>\n","      <td>1.0</td>\n","      <td>0.145762</td>\n","      <td>0.002905</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>3</td>\n","      <td>0.639556</td>\n","      <td>1.0</td>\n","      <td>0.305319</td>\n","      <td>-0.015814</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>4</td>\n","      <td>0.624575</td>\n","      <td>1.0</td>\n","      <td>0.396259</td>\n","      <td>-0.059949</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>\n","      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-caf10970-5014-41a1-9f7f-3f6bcd79dfe3')\"\n","              title=\"Convert this dataframe to an interactive table.\"\n","              style=\"display:none;\">\n","        \n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","       width=\"24px\">\n","    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n","    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n","  </svg>\n","      </button>\n","      \n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      flex-wrap:wrap;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","      <script>\n","        const buttonEl =\n","          document.querySelector('#df-caf10970-5014-41a1-9f7f-3f6bcd79dfe3 button.colab-df-convert');\n","        buttonEl.style.display =\n","          google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","        async function convertToInteractive(key) {\n","          const element = document.querySelector('#df-caf10970-5014-41a1-9f7f-3f6bcd79dfe3');\n","          const dataTable =\n","            await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                     [key], {});\n","          if (!dataTable) return;\n","\n","          const docLinkHtml = 'Like what you see? Visit the ' +\n","            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","            + ' to learn more about interactive tables.';\n","          element.innerHTML = '';\n","          dataTable['output_type'] = 'display_data';\n","          await google.colab.output.renderOutput(dataTable, element);\n","          const docLink = document.createElement('div');\n","          docLink.innerHTML = docLinkHtml;\n","          element.appendChild(docLink);\n","        }\n","      </script>\n","    </div>\n","  </div>\n","  "]},"metadata":{},"execution_count":10}],"source":["lifetime_features = pd.read_csv(\"/content/drive/MyDrive/ENG 4000/lifetime_features.csv\")\n","lifetime_features.head()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"ZuLhgoyNm_wp","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1675497854239,"user_tz":300,"elapsed":1591,"user":{"displayName":"Randy Huynh","userId":"07672825704789203793"}},"outputId":"d62d4494-c4ea-4f83-a6a8-e38ed82b21ab"},"outputs":[{"output_type":"stream","name":"stdout","text":["lifetime\n","Nulls: 0\n","Duplicates: 0\n","\n","spectrum\n","Nulls: 0\n","Duplicates: 0\n","\n","scattering\n","Nulls: 0\n","Duplicates: 0\n","\n","size\n","Nulls: 0\n","Duplicates: 0\n","\n","lifetime_features\n","Nulls: 0\n","Duplicates: 0\n","\n"]}],"source":["data = {'lifetime':lifetime,\n","        'spectrum':spectrum,\n","        'scattering':scattering,\n","        'size':size,\n","        'lifetime_features':lifetime_features}\n","pd.set_option('display.max_rows',None)\n","for x in data:\n","  print(x)\n","  print(f'Nulls: {(data[x][data[x].isna().any(axis=1)].sum() > 0).sum()}')\n","  print(f'Duplicates: {data[x].duplicated().sum()}\\n')\n","\n","  #No null features so we will not need to adjust our dataset"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"5eWXKyJanDgZ","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1675497854239,"user_tz":300,"elapsed":8,"user":{"displayName":"Randy Huynh","userId":"07672825704789203793"}},"outputId":"11f21c4b-888f-475b-f0fd-f8bb7ac53efc"},"outputs":[{"output_type":"stream","name":"stdout","text":["<class 'pandas.core.frame.DataFrame'>\n","RangeIndex: 9866 entries, 0 to 9865\n","Data columns (total 2 columns):\n"," #   Column     Non-Null Count  Dtype\n","---  ------     --------------  -----\n"," 0   Sample ID  9866 non-null   int64\n"," 1   Pollen     9866 non-null   int64\n","dtypes: int64(2)\n","memory usage: 154.3 KB\n"]}],"source":["labels.info() #Check the data types and how many nulls in the labels table"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"t1EXyQK9na-V","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1675497854239,"user_tz":300,"elapsed":6,"user":{"displayName":"Randy Huynh","userId":"07672825704789203793"}},"outputId":"710bf6b7-0c5b-4410-8b18-25b3f923d611"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["array([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11])"]},"metadata":{},"execution_count":13}],"source":["labels['Pollen'].unique() #There are 11 unique values for pollen, which correlates to 12 different types of pollen"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Lq-pEs6-ngjK","colab":{"base_uri":"https://localhost:8080/","height":334},"executionInfo":{"status":"ok","timestamp":1675497854661,"user_tz":300,"elapsed":424,"user":{"displayName":"Randy Huynh","userId":"07672825704789203793"}},"outputId":"a50bf3a0-c0e2-4c18-961d-10e72a28b742"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["   350-400 nm, t=0  350-400 nm, t=1  350-400 nm, t=2  350-400 nm, t=3  \\\n","0        -0.010454         0.000201         0.010856         0.114194   \n","1         0.119942         0.184249         0.248555         0.236994   \n","2        -0.016149         0.063383         0.142915         0.286637   \n","3         0.067116         0.198401         0.329687         0.366400   \n","4        -0.043760         0.090762         0.225284         0.214749   \n","\n","   350-400 nm, t=4  350-400 nm, t=5  350-400 nm, t=6  350-400 nm, t=7  \\\n","0         0.217531         0.166868         0.116204         0.109168   \n","1         0.225434         0.098988        -0.028179        -0.054191   \n","2         0.430359         0.262414         0.094469         0.082761   \n","3         0.403114         0.235325         0.067536         0.063644   \n","4         0.204214         0.213128         0.222042         0.133712   \n","\n","   350-400 nm, t=8  350-400 nm, t=9  ...  angle=37.5, t=115  \\\n","0         0.102131         0.054684  ...           0.000000   \n","1        -0.081647        -0.058526  ...           0.000000   \n","2         0.071054         0.093258  ...           0.000000   \n","3         0.059752         0.032085  ...         739.383196   \n","4         0.044571        -0.012966  ...           0.000000   \n","\n","   angle=37.5, t=116  angle=37.5, t=117  angle=37.5, t=118  angle=37.5, t=119  \\\n","0           0.000000            0.00000           0.000000           0.000000   \n","1           0.000000            0.00000           0.000000           0.000000   \n","2           0.000000            0.00000           0.000000           0.000000   \n","3         740.476799          600.65502         695.104062         873.792882   \n","4           0.000000            0.00000           0.000000           0.000000   \n","\n","        size  lt feature 1  lt feature 2  lt feature 3  lt feature 4  \n","0  12.513989      0.280202           1.0      0.134079     -0.008439  \n","1  19.461646      0.481173           1.0      0.266975      0.140432  \n","2  25.726931      0.519641           1.0      0.145762      0.002905  \n","3  35.178985      0.639556           1.0      0.305319     -0.015814  \n","4   4.672308      0.624575           1.0      0.396259     -0.059949  \n","\n","[5 rows x 2629 columns]"],"text/html":["\n","  <div id=\"df-d6460469-11bf-4e92-9937-926e51e6653c\">\n","    <div class=\"colab-df-container\">\n","      <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>350-400 nm, t=0</th>\n","      <th>350-400 nm, t=1</th>\n","      <th>350-400 nm, t=2</th>\n","      <th>350-400 nm, t=3</th>\n","      <th>350-400 nm, t=4</th>\n","      <th>350-400 nm, t=5</th>\n","      <th>350-400 nm, t=6</th>\n","      <th>350-400 nm, t=7</th>\n","      <th>350-400 nm, t=8</th>\n","      <th>350-400 nm, t=9</th>\n","      <th>...</th>\n","      <th>angle=37.5, t=115</th>\n","      <th>angle=37.5, t=116</th>\n","      <th>angle=37.5, t=117</th>\n","      <th>angle=37.5, t=118</th>\n","      <th>angle=37.5, t=119</th>\n","      <th>size</th>\n","      <th>lt feature 1</th>\n","      <th>lt feature 2</th>\n","      <th>lt feature 3</th>\n","      <th>lt feature 4</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>-0.010454</td>\n","      <td>0.000201</td>\n","      <td>0.010856</td>\n","      <td>0.114194</td>\n","      <td>0.217531</td>\n","      <td>0.166868</td>\n","      <td>0.116204</td>\n","      <td>0.109168</td>\n","      <td>0.102131</td>\n","      <td>0.054684</td>\n","      <td>...</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.00000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>12.513989</td>\n","      <td>0.280202</td>\n","      <td>1.0</td>\n","      <td>0.134079</td>\n","      <td>-0.008439</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>0.119942</td>\n","      <td>0.184249</td>\n","      <td>0.248555</td>\n","      <td>0.236994</td>\n","      <td>0.225434</td>\n","      <td>0.098988</td>\n","      <td>-0.028179</td>\n","      <td>-0.054191</td>\n","      <td>-0.081647</td>\n","      <td>-0.058526</td>\n","      <td>...</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.00000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>19.461646</td>\n","      <td>0.481173</td>\n","      <td>1.0</td>\n","      <td>0.266975</td>\n","      <td>0.140432</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>-0.016149</td>\n","      <td>0.063383</td>\n","      <td>0.142915</td>\n","      <td>0.286637</td>\n","      <td>0.430359</td>\n","      <td>0.262414</td>\n","      <td>0.094469</td>\n","      <td>0.082761</td>\n","      <td>0.071054</td>\n","      <td>0.093258</td>\n","      <td>...</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.00000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>25.726931</td>\n","      <td>0.519641</td>\n","      <td>1.0</td>\n","      <td>0.145762</td>\n","      <td>0.002905</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>0.067116</td>\n","      <td>0.198401</td>\n","      <td>0.329687</td>\n","      <td>0.366400</td>\n","      <td>0.403114</td>\n","      <td>0.235325</td>\n","      <td>0.067536</td>\n","      <td>0.063644</td>\n","      <td>0.059752</td>\n","      <td>0.032085</td>\n","      <td>...</td>\n","      <td>739.383196</td>\n","      <td>740.476799</td>\n","      <td>600.65502</td>\n","      <td>695.104062</td>\n","      <td>873.792882</td>\n","      <td>35.178985</td>\n","      <td>0.639556</td>\n","      <td>1.0</td>\n","      <td>0.305319</td>\n","      <td>-0.015814</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>-0.043760</td>\n","      <td>0.090762</td>\n","      <td>0.225284</td>\n","      <td>0.214749</td>\n","      <td>0.204214</td>\n","      <td>0.213128</td>\n","      <td>0.222042</td>\n","      <td>0.133712</td>\n","      <td>0.044571</td>\n","      <td>-0.012966</td>\n","      <td>...</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.00000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>4.672308</td>\n","      <td>0.624575</td>\n","      <td>1.0</td>\n","      <td>0.396259</td>\n","      <td>-0.059949</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>5 rows × 2629 columns</p>\n","</div>\n","      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-d6460469-11bf-4e92-9937-926e51e6653c')\"\n","              title=\"Convert this dataframe to an interactive table.\"\n","              style=\"display:none;\">\n","        \n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","       width=\"24px\">\n","    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n","    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n","  </svg>\n","      </button>\n","      \n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      flex-wrap:wrap;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","      <script>\n","        const buttonEl =\n","          document.querySelector('#df-d6460469-11bf-4e92-9937-926e51e6653c button.colab-df-convert');\n","        buttonEl.style.display =\n","          google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","        async function convertToInteractive(key) {\n","          const element = document.querySelector('#df-d6460469-11bf-4e92-9937-926e51e6653c');\n","          const dataTable =\n","            await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                     [key], {});\n","          if (!dataTable) return;\n","\n","          const docLinkHtml = 'Like what you see? Visit the ' +\n","            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","            + ' to learn more about interactive tables.';\n","          element.innerHTML = '';\n","          dataTable['output_type'] = 'display_data';\n","          await google.colab.output.renderOutput(dataTable, element);\n","          const docLink = document.createElement('div');\n","          docLink.innerHTML = docLinkHtml;\n","          element.appendChild(docLink);\n","        }\n","      </script>\n","    </div>\n","  </div>\n","  "]},"metadata":{},"execution_count":14}],"source":["#Courtesy of Randy\n","features = pd.DataFrame()\n","\n","for x in data:\n","  features = pd.concat([features,data[x].iloc[: , 1:]], axis=1)\n","\n","features.head()\n","\n","#Thanks Randy!!"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"ga5B78Snnp3r","colab":{"base_uri":"https://localhost:8080/","height":942},"executionInfo":{"status":"ok","timestamp":1675497854848,"user_tz":300,"elapsed":193,"user":{"displayName":"Randy Huynh","userId":"07672825704789203793"}},"outputId":"edc37317-bf69-4df5-cbfc-66a009b354b1"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["    Sample ID  Pollen  350-400 nm, t=0  350-400 nm, t=1  350-400 nm, t=2  \\\n","0           0       0        -0.010454         0.000201         0.010856   \n","1           1       0         0.119942         0.184249         0.248555   \n","2           2       0        -0.016149         0.063383         0.142915   \n","3           3       0         0.067116         0.198401         0.329687   \n","4           4       0        -0.043760         0.090762         0.225284   \n","5           5       0         0.004977         0.024748         0.044518   \n","6           6       0        -0.004771         0.002135         0.009041   \n","7           7       0        -0.034386        -0.019729        -0.005637   \n","8           8       0         0.051364         0.197967         0.344569   \n","9           9       0         0.032342         0.212160         0.391979   \n","10         10       0         0.041036         0.093508         0.145980   \n","11         11       0         0.003179         0.003709         0.004238   \n","12         12       0         0.028302         0.102404         0.176506   \n","13         13       0         0.048544         0.064725         0.080906   \n","14         14       0        -0.111416         0.037443         0.186301   \n","15         15       0         0.037859         0.084886         0.131914   \n","16         16       0        -0.008780         0.123373         0.255525   \n","17         17       0         0.102941         0.107026         0.111111   \n","18         18       0        -0.001626         0.020325         0.042276   \n","19         19       0        -0.045455         0.062500         0.170455   \n","20         20       0         0.015745         0.168738         0.321730   \n","21         21       0         0.043549         0.043549         0.043549   \n","22         22       0         0.004676         0.111141         0.217606   \n","23         23       0        -0.088571         0.005714         0.100000   \n","24         24       0         0.124931         0.215516         0.306102   \n","\n","    350-400 nm, t=3  350-400 nm, t=4  350-400 nm, t=5  350-400 nm, t=6  \\\n","0          0.114194         0.217531         0.166868         0.116204   \n","1          0.236994         0.225434         0.098988        -0.028179   \n","2          0.286637         0.430359         0.262414         0.094469   \n","3          0.366400         0.403114         0.235325         0.067536   \n","4          0.214749         0.204214         0.213128         0.222042   \n","5          0.202820         0.361123         0.254390         0.147657   \n","6          0.184957         0.360874         0.289427         0.217981   \n","7          0.249154         0.503946         0.315671         0.127396   \n","8          0.212413         0.080257         0.124131         0.168004   \n","9          0.239327         0.086675         0.124838         0.163001   \n","10         0.202825         0.259670         0.133199         0.006727   \n","11         0.141192         0.278146         0.179338         0.080530   \n","12         0.178180         0.179854         0.123554         0.067255   \n","13         0.197411         0.313916         0.319310         0.324703   \n","14         0.398174         0.610046         0.416438         0.222831   \n","15         0.239130         0.346347         0.251405         0.156463   \n","16         0.271874         0.288223         0.189525         0.090827   \n","17         0.330882         0.550654         0.347222         0.143791   \n","18         0.176016         0.309756         0.255285         0.200813   \n","19         0.217330         0.264205         0.198864         0.133523   \n","20         0.354927         0.388125         0.388125         0.388125   \n","21         0.043549         0.268042         0.147380         0.095655   \n","22         0.292779         0.367953         0.333064         0.298175   \n","23         0.177143         0.254286         0.208571         0.162857   \n","24         0.322441         0.338780         0.209403         0.080027   \n","\n","    350-400 nm, t=7  ...  angle=37.5, t=115  angle=37.5, t=116  \\\n","0          0.109168  ...           0.000000           0.000000   \n","1         -0.054191  ...           0.000000           0.000000   \n","2          0.082761  ...           0.000000           0.000000   \n","3          0.063644  ...         739.383196         740.476799   \n","4          0.133712  ...           0.000000           0.000000   \n","5          0.106180  ...           0.000000           0.000000   \n","6          0.142516  ...           0.000000           0.000000   \n","7          0.106539  ...           0.000000           0.000000   \n","8          0.113965  ...           0.000000           0.000000   \n","9          0.172057  ...           0.000000           0.000000   \n","10         0.003700  ...           0.000000           0.000000   \n","11         0.053510  ...           0.000000           0.000000   \n","12         0.030280  ...           0.000000           0.000000   \n","13         0.151564  ...           0.000000           0.000000   \n","14         0.212785  ...           0.000000           0.000000   \n","15         0.091393  ...           0.000000           0.000000   \n","16         0.055404  ...           0.000000           0.000000   \n","17         0.030229  ...           0.000000           0.000000   \n","18         0.106098  ...           0.000000           0.000000   \n","19         0.061080  ...           0.000000           0.000000   \n","20         0.283885  ...           0.000000           0.000000   \n","21         0.043929  ...           0.000000           0.000000   \n","22         0.201061  ...           0.000000           0.000000   \n","23         0.074286  ...           0.000000           0.000000   \n","24         0.056352  ...           0.000000           0.000000   \n","\n","    angle=37.5, t=117  angle=37.5, t=118  angle=37.5, t=119       size  \\\n","0             0.00000           0.000000           0.000000  12.513989   \n","1             0.00000           0.000000           0.000000  19.461646   \n","2             0.00000           0.000000           0.000000  25.726931   \n","3           600.65502         695.104062         873.792882  35.178985   \n","4             0.00000           0.000000           0.000000   4.672308   \n","5             0.00000           0.000000           0.000000  32.669015   \n","6             0.00000           0.000000           0.000000  16.917568   \n","7             0.00000           0.000000           0.000000   5.183246   \n","8             0.00000           0.000000           0.000000  10.300820   \n","9             0.00000           0.000000           0.000000  10.891347   \n","10            0.00000           0.000000           0.000000  13.280824   \n","11            0.00000           0.000000           0.000000  16.409027   \n","12            0.00000           0.000000           0.000000  34.757318   \n","13            0.00000           0.000000           0.000000  23.499978   \n","14            0.00000           0.000000           0.000000  13.441137   \n","15            0.00000           0.000000           0.000000  23.008255   \n","16            0.00000           0.000000           0.000000  19.037387   \n","17            0.00000           0.000000           0.000000   6.463340   \n","18            0.00000           0.000000           0.000000   8.009680   \n","19            0.00000           0.000000           0.000000   9.573579   \n","20            0.00000           0.000000           0.000000  44.312520   \n","21            0.00000           0.000000           0.000000  36.279895   \n","22            0.00000           0.000000           0.000000  42.207121   \n","23            0.00000           0.000000           0.000000   5.570237   \n","24            0.00000           0.000000           0.000000  32.478891   \n","\n","    lt feature 1  lt feature 2  lt feature 3  lt feature 4  \n","0       0.280202      1.000000      0.134079     -0.008439  \n","1       0.481173      1.000000      0.266975      0.140432  \n","2       0.519641      1.000000      0.145762      0.002905  \n","3       0.639556      1.000000      0.305319     -0.015814  \n","4       0.624575      1.000000      0.396259     -0.059949  \n","5       0.508910      1.000000      0.384810      0.028841  \n","6       0.528344      1.000000      0.325935     -0.021346  \n","7       0.542076      1.000000      0.058968     -0.143428  \n","8       0.487222      1.000000      0.185278      0.069306  \n","9       0.349795      1.000000      0.157729     -0.011491  \n","10      0.319376      1.000000      0.244995      0.040220  \n","11      0.332133      1.000000      0.381038      0.032803  \n","12      0.252751      1.000000      0.260605      0.000475  \n","13      0.562924      1.000000      0.369398      0.039384  \n","14      0.735643      1.000000      0.023720     -0.035268  \n","15      0.620442      1.000000      0.192139      0.014740  \n","16      0.378269      1.000000      0.249493     -0.021156  \n","17      0.673014      1.000000      0.217869      0.115342  \n","18      0.640159      1.000000      0.522061     -0.032497  \n","19      0.490219      1.000000      0.063291      0.216341  \n","20      0.880653      1.000000      0.371460      0.001787  \n","21      0.239246      0.956772      1.000000      0.017297  \n","22      0.650017      1.000000      0.387423      0.003739  \n","23      0.695596      1.000000      0.009067      0.006477  \n","24      0.499374      1.000000      0.547399     -0.003362  \n","\n","[25 rows x 2631 columns]"],"text/html":["\n","  <div id=\"df-0ef5027c-46c1-4acc-b9fe-2fa153d51d6f\">\n","    <div class=\"colab-df-container\">\n","      <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>Sample ID</th>\n","      <th>Pollen</th>\n","      <th>350-400 nm, t=0</th>\n","      <th>350-400 nm, t=1</th>\n","      <th>350-400 nm, t=2</th>\n","      <th>350-400 nm, t=3</th>\n","      <th>350-400 nm, t=4</th>\n","      <th>350-400 nm, t=5</th>\n","      <th>350-400 nm, t=6</th>\n","      <th>350-400 nm, t=7</th>\n","      <th>...</th>\n","      <th>angle=37.5, t=115</th>\n","      <th>angle=37.5, t=116</th>\n","      <th>angle=37.5, t=117</th>\n","      <th>angle=37.5, t=118</th>\n","      <th>angle=37.5, t=119</th>\n","      <th>size</th>\n","      <th>lt feature 1</th>\n","      <th>lt feature 2</th>\n","      <th>lt feature 3</th>\n","      <th>lt feature 4</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>-0.010454</td>\n","      <td>0.000201</td>\n","      <td>0.010856</td>\n","      <td>0.114194</td>\n","      <td>0.217531</td>\n","      <td>0.166868</td>\n","      <td>0.116204</td>\n","      <td>0.109168</td>\n","      <td>...</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.00000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>12.513989</td>\n","      <td>0.280202</td>\n","      <td>1.000000</td>\n","      <td>0.134079</td>\n","      <td>-0.008439</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0.119942</td>\n","      <td>0.184249</td>\n","      <td>0.248555</td>\n","      <td>0.236994</td>\n","      <td>0.225434</td>\n","      <td>0.098988</td>\n","      <td>-0.028179</td>\n","      <td>-0.054191</td>\n","      <td>...</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.00000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>19.461646</td>\n","      <td>0.481173</td>\n","      <td>1.000000</td>\n","      <td>0.266975</td>\n","      <td>0.140432</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>2</td>\n","      <td>0</td>\n","      <td>-0.016149</td>\n","      <td>0.063383</td>\n","      <td>0.142915</td>\n","      <td>0.286637</td>\n","      <td>0.430359</td>\n","      <td>0.262414</td>\n","      <td>0.094469</td>\n","      <td>0.082761</td>\n","      <td>...</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.00000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>25.726931</td>\n","      <td>0.519641</td>\n","      <td>1.000000</td>\n","      <td>0.145762</td>\n","      <td>0.002905</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>3</td>\n","      <td>0</td>\n","      <td>0.067116</td>\n","      <td>0.198401</td>\n","      <td>0.329687</td>\n","      <td>0.366400</td>\n","      <td>0.403114</td>\n","      <td>0.235325</td>\n","      <td>0.067536</td>\n","      <td>0.063644</td>\n","      <td>...</td>\n","      <td>739.383196</td>\n","      <td>740.476799</td>\n","      <td>600.65502</td>\n","      <td>695.104062</td>\n","      <td>873.792882</td>\n","      <td>35.178985</td>\n","      <td>0.639556</td>\n","      <td>1.000000</td>\n","      <td>0.305319</td>\n","      <td>-0.015814</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>4</td>\n","      <td>0</td>\n","      <td>-0.043760</td>\n","      <td>0.090762</td>\n","      <td>0.225284</td>\n","      <td>0.214749</td>\n","      <td>0.204214</td>\n","      <td>0.213128</td>\n","      <td>0.222042</td>\n","      <td>0.133712</td>\n","      <td>...</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.00000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>4.672308</td>\n","      <td>0.624575</td>\n","      <td>1.000000</td>\n","      <td>0.396259</td>\n","      <td>-0.059949</td>\n","    </tr>\n","    <tr>\n","      <th>5</th>\n","      <td>5</td>\n","      <td>0</td>\n","      <td>0.004977</td>\n","      <td>0.024748</td>\n","      <td>0.044518</td>\n","      <td>0.202820</td>\n","      <td>0.361123</td>\n","      <td>0.254390</td>\n","      <td>0.147657</td>\n","      <td>0.106180</td>\n","      <td>...</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.00000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>32.669015</td>\n","      <td>0.508910</td>\n","      <td>1.000000</td>\n","      <td>0.384810</td>\n","      <td>0.028841</td>\n","    </tr>\n","    <tr>\n","      <th>6</th>\n","      <td>6</td>\n","      <td>0</td>\n","      <td>-0.004771</td>\n","      <td>0.002135</td>\n","      <td>0.009041</td>\n","      <td>0.184957</td>\n","      <td>0.360874</td>\n","      <td>0.289427</td>\n","      <td>0.217981</td>\n","      <td>0.142516</td>\n","      <td>...</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.00000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>16.917568</td>\n","      <td>0.528344</td>\n","      <td>1.000000</td>\n","      <td>0.325935</td>\n","      <td>-0.021346</td>\n","    </tr>\n","    <tr>\n","      <th>7</th>\n","      <td>7</td>\n","      <td>0</td>\n","      <td>-0.034386</td>\n","      <td>-0.019729</td>\n","      <td>-0.005637</td>\n","      <td>0.249154</td>\n","      <td>0.503946</td>\n","      <td>0.315671</td>\n","      <td>0.127396</td>\n","      <td>0.106539</td>\n","      <td>...</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.00000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>5.183246</td>\n","      <td>0.542076</td>\n","      <td>1.000000</td>\n","      <td>0.058968</td>\n","      <td>-0.143428</td>\n","    </tr>\n","    <tr>\n","      <th>8</th>\n","      <td>8</td>\n","      <td>0</td>\n","      <td>0.051364</td>\n","      <td>0.197967</td>\n","      <td>0.344569</td>\n","      <td>0.212413</td>\n","      <td>0.080257</td>\n","      <td>0.124131</td>\n","      <td>0.168004</td>\n","      <td>0.113965</td>\n","      <td>...</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.00000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>10.300820</td>\n","      <td>0.487222</td>\n","      <td>1.000000</td>\n","      <td>0.185278</td>\n","      <td>0.069306</td>\n","    </tr>\n","    <tr>\n","      <th>9</th>\n","      <td>9</td>\n","      <td>0</td>\n","      <td>0.032342</td>\n","      <td>0.212160</td>\n","      <td>0.391979</td>\n","      <td>0.239327</td>\n","      <td>0.086675</td>\n","      <td>0.124838</td>\n","      <td>0.163001</td>\n","      <td>0.172057</td>\n","      <td>...</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.00000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>10.891347</td>\n","      <td>0.349795</td>\n","      <td>1.000000</td>\n","      <td>0.157729</td>\n","      <td>-0.011491</td>\n","    </tr>\n","    <tr>\n","      <th>10</th>\n","      <td>10</td>\n","      <td>0</td>\n","      <td>0.041036</td>\n","      <td>0.093508</td>\n","      <td>0.145980</td>\n","      <td>0.202825</td>\n","      <td>0.259670</td>\n","      <td>0.133199</td>\n","      <td>0.006727</td>\n","      <td>0.003700</td>\n","      <td>...</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.00000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>13.280824</td>\n","      <td>0.319376</td>\n","      <td>1.000000</td>\n","      <td>0.244995</td>\n","      <td>0.040220</td>\n","    </tr>\n","    <tr>\n","      <th>11</th>\n","      <td>11</td>\n","      <td>0</td>\n","      <td>0.003179</td>\n","      <td>0.003709</td>\n","      <td>0.004238</td>\n","      <td>0.141192</td>\n","      <td>0.278146</td>\n","      <td>0.179338</td>\n","      <td>0.080530</td>\n","      <td>0.053510</td>\n","      <td>...</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.00000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>16.409027</td>\n","      <td>0.332133</td>\n","      <td>1.000000</td>\n","      <td>0.381038</td>\n","      <td>0.032803</td>\n","    </tr>\n","    <tr>\n","      <th>12</th>\n","      <td>12</td>\n","      <td>0</td>\n","      <td>0.028302</td>\n","      <td>0.102404</td>\n","      <td>0.176506</td>\n","      <td>0.178180</td>\n","      <td>0.179854</td>\n","      <td>0.123554</td>\n","      <td>0.067255</td>\n","      <td>0.030280</td>\n","      <td>...</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.00000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>34.757318</td>\n","      <td>0.252751</td>\n","      <td>1.000000</td>\n","      <td>0.260605</td>\n","      <td>0.000475</td>\n","    </tr>\n","    <tr>\n","      <th>13</th>\n","      <td>13</td>\n","      <td>0</td>\n","      <td>0.048544</td>\n","      <td>0.064725</td>\n","      <td>0.080906</td>\n","      <td>0.197411</td>\n","      <td>0.313916</td>\n","      <td>0.319310</td>\n","      <td>0.324703</td>\n","      <td>0.151564</td>\n","      <td>...</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.00000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>23.499978</td>\n","      <td>0.562924</td>\n","      <td>1.000000</td>\n","      <td>0.369398</td>\n","      <td>0.039384</td>\n","    </tr>\n","    <tr>\n","      <th>14</th>\n","      <td>14</td>\n","      <td>0</td>\n","      <td>-0.111416</td>\n","      <td>0.037443</td>\n","      <td>0.186301</td>\n","      <td>0.398174</td>\n","      <td>0.610046</td>\n","      <td>0.416438</td>\n","      <td>0.222831</td>\n","      <td>0.212785</td>\n","      <td>...</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.00000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>13.441137</td>\n","      <td>0.735643</td>\n","      <td>1.000000</td>\n","      <td>0.023720</td>\n","      <td>-0.035268</td>\n","    </tr>\n","    <tr>\n","      <th>15</th>\n","      <td>15</td>\n","      <td>0</td>\n","      <td>0.037859</td>\n","      <td>0.084886</td>\n","      <td>0.131914</td>\n","      <td>0.239130</td>\n","      <td>0.346347</td>\n","      <td>0.251405</td>\n","      <td>0.156463</td>\n","      <td>0.091393</td>\n","      <td>...</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.00000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>23.008255</td>\n","      <td>0.620442</td>\n","      <td>1.000000</td>\n","      <td>0.192139</td>\n","      <td>0.014740</td>\n","    </tr>\n","    <tr>\n","      <th>16</th>\n","      <td>16</td>\n","      <td>0</td>\n","      <td>-0.008780</td>\n","      <td>0.123373</td>\n","      <td>0.255525</td>\n","      <td>0.271874</td>\n","      <td>0.288223</td>\n","      <td>0.189525</td>\n","      <td>0.090827</td>\n","      <td>0.055404</td>\n","      <td>...</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.00000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>19.037387</td>\n","      <td>0.378269</td>\n","      <td>1.000000</td>\n","      <td>0.249493</td>\n","      <td>-0.021156</td>\n","    </tr>\n","    <tr>\n","      <th>17</th>\n","      <td>17</td>\n","      <td>0</td>\n","      <td>0.102941</td>\n","      <td>0.107026</td>\n","      <td>0.111111</td>\n","      <td>0.330882</td>\n","      <td>0.550654</td>\n","      <td>0.347222</td>\n","      <td>0.143791</td>\n","      <td>0.030229</td>\n","      <td>...</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.00000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>6.463340</td>\n","      <td>0.673014</td>\n","      <td>1.000000</td>\n","      <td>0.217869</td>\n","      <td>0.115342</td>\n","    </tr>\n","    <tr>\n","      <th>18</th>\n","      <td>18</td>\n","      <td>0</td>\n","      <td>-0.001626</td>\n","      <td>0.020325</td>\n","      <td>0.042276</td>\n","      <td>0.176016</td>\n","      <td>0.309756</td>\n","      <td>0.255285</td>\n","      <td>0.200813</td>\n","      <td>0.106098</td>\n","      <td>...</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.00000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>8.009680</td>\n","      <td>0.640159</td>\n","      <td>1.000000</td>\n","      <td>0.522061</td>\n","      <td>-0.032497</td>\n","    </tr>\n","    <tr>\n","      <th>19</th>\n","      <td>19</td>\n","      <td>0</td>\n","      <td>-0.045455</td>\n","      <td>0.062500</td>\n","      <td>0.170455</td>\n","      <td>0.217330</td>\n","      <td>0.264205</td>\n","      <td>0.198864</td>\n","      <td>0.133523</td>\n","      <td>0.061080</td>\n","      <td>...</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.00000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>9.573579</td>\n","      <td>0.490219</td>\n","      <td>1.000000</td>\n","      <td>0.063291</td>\n","      <td>0.216341</td>\n","    </tr>\n","    <tr>\n","      <th>20</th>\n","      <td>20</td>\n","      <td>0</td>\n","      <td>0.015745</td>\n","      <td>0.168738</td>\n","      <td>0.321730</td>\n","      <td>0.354927</td>\n","      <td>0.388125</td>\n","      <td>0.388125</td>\n","      <td>0.388125</td>\n","      <td>0.283885</td>\n","      <td>...</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.00000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>44.312520</td>\n","      <td>0.880653</td>\n","      <td>1.000000</td>\n","      <td>0.371460</td>\n","      <td>0.001787</td>\n","    </tr>\n","    <tr>\n","      <th>21</th>\n","      <td>21</td>\n","      <td>0</td>\n","      <td>0.043549</td>\n","      <td>0.043549</td>\n","      <td>0.043549</td>\n","      <td>0.043549</td>\n","      <td>0.268042</td>\n","      <td>0.147380</td>\n","      <td>0.095655</td>\n","      <td>0.043929</td>\n","      <td>...</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.00000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>36.279895</td>\n","      <td>0.239246</td>\n","      <td>0.956772</td>\n","      <td>1.000000</td>\n","      <td>0.017297</td>\n","    </tr>\n","    <tr>\n","      <th>22</th>\n","      <td>22</td>\n","      <td>0</td>\n","      <td>0.004676</td>\n","      <td>0.111141</td>\n","      <td>0.217606</td>\n","      <td>0.292779</td>\n","      <td>0.367953</td>\n","      <td>0.333064</td>\n","      <td>0.298175</td>\n","      <td>0.201061</td>\n","      <td>...</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.00000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>42.207121</td>\n","      <td>0.650017</td>\n","      <td>1.000000</td>\n","      <td>0.387423</td>\n","      <td>0.003739</td>\n","    </tr>\n","    <tr>\n","      <th>23</th>\n","      <td>23</td>\n","      <td>0</td>\n","      <td>-0.088571</td>\n","      <td>0.005714</td>\n","      <td>0.100000</td>\n","      <td>0.177143</td>\n","      <td>0.254286</td>\n","      <td>0.208571</td>\n","      <td>0.162857</td>\n","      <td>0.074286</td>\n","      <td>...</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.00000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>5.570237</td>\n","      <td>0.695596</td>\n","      <td>1.000000</td>\n","      <td>0.009067</td>\n","      <td>0.006477</td>\n","    </tr>\n","    <tr>\n","      <th>24</th>\n","      <td>24</td>\n","      <td>0</td>\n","      <td>0.124931</td>\n","      <td>0.215516</td>\n","      <td>0.306102</td>\n","      <td>0.322441</td>\n","      <td>0.338780</td>\n","      <td>0.209403</td>\n","      <td>0.080027</td>\n","      <td>0.056352</td>\n","      <td>...</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.00000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>32.478891</td>\n","      <td>0.499374</td>\n","      <td>1.000000</td>\n","      <td>0.547399</td>\n","      <td>-0.003362</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>25 rows × 2631 columns</p>\n","</div>\n","      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-0ef5027c-46c1-4acc-b9fe-2fa153d51d6f')\"\n","              title=\"Convert this dataframe to an interactive table.\"\n","              style=\"display:none;\">\n","        \n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","       width=\"24px\">\n","    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n","    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n","  </svg>\n","      </button>\n","      \n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      flex-wrap:wrap;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","      <script>\n","        const buttonEl =\n","          document.querySelector('#df-0ef5027c-46c1-4acc-b9fe-2fa153d51d6f button.colab-df-convert');\n","        buttonEl.style.display =\n","          google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","        async function convertToInteractive(key) {\n","          const element = document.querySelector('#df-0ef5027c-46c1-4acc-b9fe-2fa153d51d6f');\n","          const dataTable =\n","            await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                     [key], {});\n","          if (!dataTable) return;\n","\n","          const docLinkHtml = 'Like what you see? Visit the ' +\n","            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","            + ' to learn more about interactive tables.';\n","          element.innerHTML = '';\n","          dataTable['output_type'] = 'display_data';\n","          await google.colab.output.renderOutput(dataTable, element);\n","          const docLink = document.createElement('div');\n","          docLink.innerHTML = docLinkHtml;\n","          element.appendChild(docLink);\n","        }\n","      </script>\n","    </div>\n","  </div>\n","  "]},"metadata":{},"execution_count":15}],"source":["results = pd.concat([labels, features],axis=1)\n","results.head(25)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"aKdsnoQxnncY","colab":{"base_uri":"https://localhost:8080/","height":962},"executionInfo":{"status":"ok","timestamp":1675497855010,"user_tz":300,"elapsed":165,"user":{"displayName":"Randy Huynh","userId":"07672825704789203793"}},"outputId":"4c3bc749-e005-41df-f434-ab69e0b5d3ca"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["    Pollen  350-400 nm, t=0  350-400 nm, t=1  350-400 nm, t=2  \\\n","0        0        -0.010454         0.000201         0.010856   \n","1        0         0.119942         0.184249         0.248555   \n","2        0        -0.016149         0.063383         0.142915   \n","3        0         0.067116         0.198401         0.329687   \n","4        0        -0.043760         0.090762         0.225284   \n","5        0         0.004977         0.024748         0.044518   \n","6        0        -0.004771         0.002135         0.009041   \n","7        0        -0.034386        -0.019729        -0.005637   \n","8        0         0.051364         0.197967         0.344569   \n","9        0         0.032342         0.212160         0.391979   \n","10       0         0.041036         0.093508         0.145980   \n","11       0         0.003179         0.003709         0.004238   \n","12       0         0.028302         0.102404         0.176506   \n","13       0         0.048544         0.064725         0.080906   \n","14       0        -0.111416         0.037443         0.186301   \n","15       0         0.037859         0.084886         0.131914   \n","16       0        -0.008780         0.123373         0.255525   \n","17       0         0.102941         0.107026         0.111111   \n","18       0        -0.001626         0.020325         0.042276   \n","19       0        -0.045455         0.062500         0.170455   \n","20       0         0.015745         0.168738         0.321730   \n","21       0         0.043549         0.043549         0.043549   \n","22       0         0.004676         0.111141         0.217606   \n","23       0        -0.088571         0.005714         0.100000   \n","24       0         0.124931         0.215516         0.306102   \n","\n","    350-400 nm, t=3  350-400 nm, t=4  350-400 nm, t=5  350-400 nm, t=6  \\\n","0          0.114194         0.217531         0.166868         0.116204   \n","1          0.236994         0.225434         0.098988        -0.028179   \n","2          0.286637         0.430359         0.262414         0.094469   \n","3          0.366400         0.403114         0.235325         0.067536   \n","4          0.214749         0.204214         0.213128         0.222042   \n","5          0.202820         0.361123         0.254390         0.147657   \n","6          0.184957         0.360874         0.289427         0.217981   \n","7          0.249154         0.503946         0.315671         0.127396   \n","8          0.212413         0.080257         0.124131         0.168004   \n","9          0.239327         0.086675         0.124838         0.163001   \n","10         0.202825         0.259670         0.133199         0.006727   \n","11         0.141192         0.278146         0.179338         0.080530   \n","12         0.178180         0.179854         0.123554         0.067255   \n","13         0.197411         0.313916         0.319310         0.324703   \n","14         0.398174         0.610046         0.416438         0.222831   \n","15         0.239130         0.346347         0.251405         0.156463   \n","16         0.271874         0.288223         0.189525         0.090827   \n","17         0.330882         0.550654         0.347222         0.143791   \n","18         0.176016         0.309756         0.255285         0.200813   \n","19         0.217330         0.264205         0.198864         0.133523   \n","20         0.354927         0.388125         0.388125         0.388125   \n","21         0.043549         0.268042         0.147380         0.095655   \n","22         0.292779         0.367953         0.333064         0.298175   \n","23         0.177143         0.254286         0.208571         0.162857   \n","24         0.322441         0.338780         0.209403         0.080027   \n","\n","    350-400 nm, t=7  350-400 nm, t=8  ...  angle=37.5, t=115  \\\n","0          0.109168         0.102131  ...           0.000000   \n","1         -0.054191        -0.081647  ...           0.000000   \n","2          0.082761         0.071054  ...           0.000000   \n","3          0.063644         0.059752  ...         739.383196   \n","4          0.133712         0.044571  ...           0.000000   \n","5          0.106180         0.064703  ...           0.000000   \n","6          0.142516         0.067052  ...           0.000000   \n","7          0.106539         0.085682  ...           0.000000   \n","8          0.113965         0.059925  ...           0.000000   \n","9          0.172057         0.181113  ...           0.000000   \n","10         0.003700         0.000673  ...           0.000000   \n","11         0.053510         0.026490  ...           0.000000   \n","12         0.030280        -0.006847  ...           0.000000   \n","13         0.151564        -0.022114  ...           0.000000   \n","14         0.212785         0.202740  ...           0.000000   \n","15         0.091393         0.026324  ...           0.000000   \n","16         0.055404         0.019982  ...           0.000000   \n","17         0.030229        -0.084150  ...           0.000000   \n","18         0.106098         0.010976  ...           0.000000   \n","19         0.061080        -0.012784  ...           0.000000   \n","20         0.283885         0.179645  ...           0.000000   \n","21         0.043929         0.023201  ...           0.000000   \n","22         0.201061         0.103947  ...           0.000000   \n","23         0.074286        -0.015714  ...           0.000000   \n","24         0.056352         0.032678  ...           0.000000   \n","\n","    angle=37.5, t=116  angle=37.5, t=117  angle=37.5, t=118  \\\n","0            0.000000            0.00000           0.000000   \n","1            0.000000            0.00000           0.000000   \n","2            0.000000            0.00000           0.000000   \n","3          740.476799          600.65502         695.104062   \n","4            0.000000            0.00000           0.000000   \n","5            0.000000            0.00000           0.000000   \n","6            0.000000            0.00000           0.000000   \n","7            0.000000            0.00000           0.000000   \n","8            0.000000            0.00000           0.000000   \n","9            0.000000            0.00000           0.000000   \n","10           0.000000            0.00000           0.000000   \n","11           0.000000            0.00000           0.000000   \n","12           0.000000            0.00000           0.000000   \n","13           0.000000            0.00000           0.000000   \n","14           0.000000            0.00000           0.000000   \n","15           0.000000            0.00000           0.000000   \n","16           0.000000            0.00000           0.000000   \n","17           0.000000            0.00000           0.000000   \n","18           0.000000            0.00000           0.000000   \n","19           0.000000            0.00000           0.000000   \n","20           0.000000            0.00000           0.000000   \n","21           0.000000            0.00000           0.000000   \n","22           0.000000            0.00000           0.000000   \n","23           0.000000            0.00000           0.000000   \n","24           0.000000            0.00000           0.000000   \n","\n","    angle=37.5, t=119       size  lt feature 1  lt feature 2  lt feature 3  \\\n","0            0.000000  12.513989      0.280202      1.000000      0.134079   \n","1            0.000000  19.461646      0.481173      1.000000      0.266975   \n","2            0.000000  25.726931      0.519641      1.000000      0.145762   \n","3          873.792882  35.178985      0.639556      1.000000      0.305319   \n","4            0.000000   4.672308      0.624575      1.000000      0.396259   \n","5            0.000000  32.669015      0.508910      1.000000      0.384810   \n","6            0.000000  16.917568      0.528344      1.000000      0.325935   \n","7            0.000000   5.183246      0.542076      1.000000      0.058968   \n","8            0.000000  10.300820      0.487222      1.000000      0.185278   \n","9            0.000000  10.891347      0.349795      1.000000      0.157729   \n","10           0.000000  13.280824      0.319376      1.000000      0.244995   \n","11           0.000000  16.409027      0.332133      1.000000      0.381038   \n","12           0.000000  34.757318      0.252751      1.000000      0.260605   \n","13           0.000000  23.499978      0.562924      1.000000      0.369398   \n","14           0.000000  13.441137      0.735643      1.000000      0.023720   \n","15           0.000000  23.008255      0.620442      1.000000      0.192139   \n","16           0.000000  19.037387      0.378269      1.000000      0.249493   \n","17           0.000000   6.463340      0.673014      1.000000      0.217869   \n","18           0.000000   8.009680      0.640159      1.000000      0.522061   \n","19           0.000000   9.573579      0.490219      1.000000      0.063291   \n","20           0.000000  44.312520      0.880653      1.000000      0.371460   \n","21           0.000000  36.279895      0.239246      0.956772      1.000000   \n","22           0.000000  42.207121      0.650017      1.000000      0.387423   \n","23           0.000000   5.570237      0.695596      1.000000      0.009067   \n","24           0.000000  32.478891      0.499374      1.000000      0.547399   \n","\n","    lt feature 4  \n","0      -0.008439  \n","1       0.140432  \n","2       0.002905  \n","3      -0.015814  \n","4      -0.059949  \n","5       0.028841  \n","6      -0.021346  \n","7      -0.143428  \n","8       0.069306  \n","9      -0.011491  \n","10      0.040220  \n","11      0.032803  \n","12      0.000475  \n","13      0.039384  \n","14     -0.035268  \n","15      0.014740  \n","16     -0.021156  \n","17      0.115342  \n","18     -0.032497  \n","19      0.216341  \n","20      0.001787  \n","21      0.017297  \n","22      0.003739  \n","23      0.006477  \n","24     -0.003362  \n","\n","[25 rows x 2630 columns]"],"text/html":["\n","  <div id=\"df-6f1039ac-2c34-49c9-88eb-60d0f7574f6a\">\n","    <div class=\"colab-df-container\">\n","      <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>Pollen</th>\n","      <th>350-400 nm, t=0</th>\n","      <th>350-400 nm, t=1</th>\n","      <th>350-400 nm, t=2</th>\n","      <th>350-400 nm, t=3</th>\n","      <th>350-400 nm, t=4</th>\n","      <th>350-400 nm, t=5</th>\n","      <th>350-400 nm, t=6</th>\n","      <th>350-400 nm, t=7</th>\n","      <th>350-400 nm, t=8</th>\n","      <th>...</th>\n","      <th>angle=37.5, t=115</th>\n","      <th>angle=37.5, t=116</th>\n","      <th>angle=37.5, t=117</th>\n","      <th>angle=37.5, t=118</th>\n","      <th>angle=37.5, t=119</th>\n","      <th>size</th>\n","      <th>lt feature 1</th>\n","      <th>lt feature 2</th>\n","      <th>lt feature 3</th>\n","      <th>lt feature 4</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>0</td>\n","      <td>-0.010454</td>\n","      <td>0.000201</td>\n","      <td>0.010856</td>\n","      <td>0.114194</td>\n","      <td>0.217531</td>\n","      <td>0.166868</td>\n","      <td>0.116204</td>\n","      <td>0.109168</td>\n","      <td>0.102131</td>\n","      <td>...</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.00000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>12.513989</td>\n","      <td>0.280202</td>\n","      <td>1.000000</td>\n","      <td>0.134079</td>\n","      <td>-0.008439</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>0</td>\n","      <td>0.119942</td>\n","      <td>0.184249</td>\n","      <td>0.248555</td>\n","      <td>0.236994</td>\n","      <td>0.225434</td>\n","      <td>0.098988</td>\n","      <td>-0.028179</td>\n","      <td>-0.054191</td>\n","      <td>-0.081647</td>\n","      <td>...</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.00000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>19.461646</td>\n","      <td>0.481173</td>\n","      <td>1.000000</td>\n","      <td>0.266975</td>\n","      <td>0.140432</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>0</td>\n","      <td>-0.016149</td>\n","      <td>0.063383</td>\n","      <td>0.142915</td>\n","      <td>0.286637</td>\n","      <td>0.430359</td>\n","      <td>0.262414</td>\n","      <td>0.094469</td>\n","      <td>0.082761</td>\n","      <td>0.071054</td>\n","      <td>...</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.00000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>25.726931</td>\n","      <td>0.519641</td>\n","      <td>1.000000</td>\n","      <td>0.145762</td>\n","      <td>0.002905</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>0</td>\n","      <td>0.067116</td>\n","      <td>0.198401</td>\n","      <td>0.329687</td>\n","      <td>0.366400</td>\n","      <td>0.403114</td>\n","      <td>0.235325</td>\n","      <td>0.067536</td>\n","      <td>0.063644</td>\n","      <td>0.059752</td>\n","      <td>...</td>\n","      <td>739.383196</td>\n","      <td>740.476799</td>\n","      <td>600.65502</td>\n","      <td>695.104062</td>\n","      <td>873.792882</td>\n","      <td>35.178985</td>\n","      <td>0.639556</td>\n","      <td>1.000000</td>\n","      <td>0.305319</td>\n","      <td>-0.015814</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>0</td>\n","      <td>-0.043760</td>\n","      <td>0.090762</td>\n","      <td>0.225284</td>\n","      <td>0.214749</td>\n","      <td>0.204214</td>\n","      <td>0.213128</td>\n","      <td>0.222042</td>\n","      <td>0.133712</td>\n","      <td>0.044571</td>\n","      <td>...</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.00000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>4.672308</td>\n","      <td>0.624575</td>\n","      <td>1.000000</td>\n","      <td>0.396259</td>\n","      <td>-0.059949</td>\n","    </tr>\n","    <tr>\n","      <th>5</th>\n","      <td>0</td>\n","      <td>0.004977</td>\n","      <td>0.024748</td>\n","      <td>0.044518</td>\n","      <td>0.202820</td>\n","      <td>0.361123</td>\n","      <td>0.254390</td>\n","      <td>0.147657</td>\n","      <td>0.106180</td>\n","      <td>0.064703</td>\n","      <td>...</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.00000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>32.669015</td>\n","      <td>0.508910</td>\n","      <td>1.000000</td>\n","      <td>0.384810</td>\n","      <td>0.028841</td>\n","    </tr>\n","    <tr>\n","      <th>6</th>\n","      <td>0</td>\n","      <td>-0.004771</td>\n","      <td>0.002135</td>\n","      <td>0.009041</td>\n","      <td>0.184957</td>\n","      <td>0.360874</td>\n","      <td>0.289427</td>\n","      <td>0.217981</td>\n","      <td>0.142516</td>\n","      <td>0.067052</td>\n","      <td>...</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.00000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>16.917568</td>\n","      <td>0.528344</td>\n","      <td>1.000000</td>\n","      <td>0.325935</td>\n","      <td>-0.021346</td>\n","    </tr>\n","    <tr>\n","      <th>7</th>\n","      <td>0</td>\n","      <td>-0.034386</td>\n","      <td>-0.019729</td>\n","      <td>-0.005637</td>\n","      <td>0.249154</td>\n","      <td>0.503946</td>\n","      <td>0.315671</td>\n","      <td>0.127396</td>\n","      <td>0.106539</td>\n","      <td>0.085682</td>\n","      <td>...</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.00000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>5.183246</td>\n","      <td>0.542076</td>\n","      <td>1.000000</td>\n","      <td>0.058968</td>\n","      <td>-0.143428</td>\n","    </tr>\n","    <tr>\n","      <th>8</th>\n","      <td>0</td>\n","      <td>0.051364</td>\n","      <td>0.197967</td>\n","      <td>0.344569</td>\n","      <td>0.212413</td>\n","      <td>0.080257</td>\n","      <td>0.124131</td>\n","      <td>0.168004</td>\n","      <td>0.113965</td>\n","      <td>0.059925</td>\n","      <td>...</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.00000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>10.300820</td>\n","      <td>0.487222</td>\n","      <td>1.000000</td>\n","      <td>0.185278</td>\n","      <td>0.069306</td>\n","    </tr>\n","    <tr>\n","      <th>9</th>\n","      <td>0</td>\n","      <td>0.032342</td>\n","      <td>0.212160</td>\n","      <td>0.391979</td>\n","      <td>0.239327</td>\n","      <td>0.086675</td>\n","      <td>0.124838</td>\n","      <td>0.163001</td>\n","      <td>0.172057</td>\n","      <td>0.181113</td>\n","      <td>...</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.00000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>10.891347</td>\n","      <td>0.349795</td>\n","      <td>1.000000</td>\n","      <td>0.157729</td>\n","      <td>-0.011491</td>\n","    </tr>\n","    <tr>\n","      <th>10</th>\n","      <td>0</td>\n","      <td>0.041036</td>\n","      <td>0.093508</td>\n","      <td>0.145980</td>\n","      <td>0.202825</td>\n","      <td>0.259670</td>\n","      <td>0.133199</td>\n","      <td>0.006727</td>\n","      <td>0.003700</td>\n","      <td>0.000673</td>\n","      <td>...</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.00000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>13.280824</td>\n","      <td>0.319376</td>\n","      <td>1.000000</td>\n","      <td>0.244995</td>\n","      <td>0.040220</td>\n","    </tr>\n","    <tr>\n","      <th>11</th>\n","      <td>0</td>\n","      <td>0.003179</td>\n","      <td>0.003709</td>\n","      <td>0.004238</td>\n","      <td>0.141192</td>\n","      <td>0.278146</td>\n","      <td>0.179338</td>\n","      <td>0.080530</td>\n","      <td>0.053510</td>\n","      <td>0.026490</td>\n","      <td>...</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.00000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>16.409027</td>\n","      <td>0.332133</td>\n","      <td>1.000000</td>\n","      <td>0.381038</td>\n","      <td>0.032803</td>\n","    </tr>\n","    <tr>\n","      <th>12</th>\n","      <td>0</td>\n","      <td>0.028302</td>\n","      <td>0.102404</td>\n","      <td>0.176506</td>\n","      <td>0.178180</td>\n","      <td>0.179854</td>\n","      <td>0.123554</td>\n","      <td>0.067255</td>\n","      <td>0.030280</td>\n","      <td>-0.006847</td>\n","      <td>...</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.00000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>34.757318</td>\n","      <td>0.252751</td>\n","      <td>1.000000</td>\n","      <td>0.260605</td>\n","      <td>0.000475</td>\n","    </tr>\n","    <tr>\n","      <th>13</th>\n","      <td>0</td>\n","      <td>0.048544</td>\n","      <td>0.064725</td>\n","      <td>0.080906</td>\n","      <td>0.197411</td>\n","      <td>0.313916</td>\n","      <td>0.319310</td>\n","      <td>0.324703</td>\n","      <td>0.151564</td>\n","      <td>-0.022114</td>\n","      <td>...</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.00000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>23.499978</td>\n","      <td>0.562924</td>\n","      <td>1.000000</td>\n","      <td>0.369398</td>\n","      <td>0.039384</td>\n","    </tr>\n","    <tr>\n","      <th>14</th>\n","      <td>0</td>\n","      <td>-0.111416</td>\n","      <td>0.037443</td>\n","      <td>0.186301</td>\n","      <td>0.398174</td>\n","      <td>0.610046</td>\n","      <td>0.416438</td>\n","      <td>0.222831</td>\n","      <td>0.212785</td>\n","      <td>0.202740</td>\n","      <td>...</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.00000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>13.441137</td>\n","      <td>0.735643</td>\n","      <td>1.000000</td>\n","      <td>0.023720</td>\n","      <td>-0.035268</td>\n","    </tr>\n","    <tr>\n","      <th>15</th>\n","      <td>0</td>\n","      <td>0.037859</td>\n","      <td>0.084886</td>\n","      <td>0.131914</td>\n","      <td>0.239130</td>\n","      <td>0.346347</td>\n","      <td>0.251405</td>\n","      <td>0.156463</td>\n","      <td>0.091393</td>\n","      <td>0.026324</td>\n","      <td>...</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.00000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>23.008255</td>\n","      <td>0.620442</td>\n","      <td>1.000000</td>\n","      <td>0.192139</td>\n","      <td>0.014740</td>\n","    </tr>\n","    <tr>\n","      <th>16</th>\n","      <td>0</td>\n","      <td>-0.008780</td>\n","      <td>0.123373</td>\n","      <td>0.255525</td>\n","      <td>0.271874</td>\n","      <td>0.288223</td>\n","      <td>0.189525</td>\n","      <td>0.090827</td>\n","      <td>0.055404</td>\n","      <td>0.019982</td>\n","      <td>...</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.00000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>19.037387</td>\n","      <td>0.378269</td>\n","      <td>1.000000</td>\n","      <td>0.249493</td>\n","      <td>-0.021156</td>\n","    </tr>\n","    <tr>\n","      <th>17</th>\n","      <td>0</td>\n","      <td>0.102941</td>\n","      <td>0.107026</td>\n","      <td>0.111111</td>\n","      <td>0.330882</td>\n","      <td>0.550654</td>\n","      <td>0.347222</td>\n","      <td>0.143791</td>\n","      <td>0.030229</td>\n","      <td>-0.084150</td>\n","      <td>...</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.00000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>6.463340</td>\n","      <td>0.673014</td>\n","      <td>1.000000</td>\n","      <td>0.217869</td>\n","      <td>0.115342</td>\n","    </tr>\n","    <tr>\n","      <th>18</th>\n","      <td>0</td>\n","      <td>-0.001626</td>\n","      <td>0.020325</td>\n","      <td>0.042276</td>\n","      <td>0.176016</td>\n","      <td>0.309756</td>\n","      <td>0.255285</td>\n","      <td>0.200813</td>\n","      <td>0.106098</td>\n","      <td>0.010976</td>\n","      <td>...</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.00000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>8.009680</td>\n","      <td>0.640159</td>\n","      <td>1.000000</td>\n","      <td>0.522061</td>\n","      <td>-0.032497</td>\n","    </tr>\n","    <tr>\n","      <th>19</th>\n","      <td>0</td>\n","      <td>-0.045455</td>\n","      <td>0.062500</td>\n","      <td>0.170455</td>\n","      <td>0.217330</td>\n","      <td>0.264205</td>\n","      <td>0.198864</td>\n","      <td>0.133523</td>\n","      <td>0.061080</td>\n","      <td>-0.012784</td>\n","      <td>...</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.00000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>9.573579</td>\n","      <td>0.490219</td>\n","      <td>1.000000</td>\n","      <td>0.063291</td>\n","      <td>0.216341</td>\n","    </tr>\n","    <tr>\n","      <th>20</th>\n","      <td>0</td>\n","      <td>0.015745</td>\n","      <td>0.168738</td>\n","      <td>0.321730</td>\n","      <td>0.354927</td>\n","      <td>0.388125</td>\n","      <td>0.388125</td>\n","      <td>0.388125</td>\n","      <td>0.283885</td>\n","      <td>0.179645</td>\n","      <td>...</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.00000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>44.312520</td>\n","      <td>0.880653</td>\n","      <td>1.000000</td>\n","      <td>0.371460</td>\n","      <td>0.001787</td>\n","    </tr>\n","    <tr>\n","      <th>21</th>\n","      <td>0</td>\n","      <td>0.043549</td>\n","      <td>0.043549</td>\n","      <td>0.043549</td>\n","      <td>0.043549</td>\n","      <td>0.268042</td>\n","      <td>0.147380</td>\n","      <td>0.095655</td>\n","      <td>0.043929</td>\n","      <td>0.023201</td>\n","      <td>...</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.00000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>36.279895</td>\n","      <td>0.239246</td>\n","      <td>0.956772</td>\n","      <td>1.000000</td>\n","      <td>0.017297</td>\n","    </tr>\n","    <tr>\n","      <th>22</th>\n","      <td>0</td>\n","      <td>0.004676</td>\n","      <td>0.111141</td>\n","      <td>0.217606</td>\n","      <td>0.292779</td>\n","      <td>0.367953</td>\n","      <td>0.333064</td>\n","      <td>0.298175</td>\n","      <td>0.201061</td>\n","      <td>0.103947</td>\n","      <td>...</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.00000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>42.207121</td>\n","      <td>0.650017</td>\n","      <td>1.000000</td>\n","      <td>0.387423</td>\n","      <td>0.003739</td>\n","    </tr>\n","    <tr>\n","      <th>23</th>\n","      <td>0</td>\n","      <td>-0.088571</td>\n","      <td>0.005714</td>\n","      <td>0.100000</td>\n","      <td>0.177143</td>\n","      <td>0.254286</td>\n","      <td>0.208571</td>\n","      <td>0.162857</td>\n","      <td>0.074286</td>\n","      <td>-0.015714</td>\n","      <td>...</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.00000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>5.570237</td>\n","      <td>0.695596</td>\n","      <td>1.000000</td>\n","      <td>0.009067</td>\n","      <td>0.006477</td>\n","    </tr>\n","    <tr>\n","      <th>24</th>\n","      <td>0</td>\n","      <td>0.124931</td>\n","      <td>0.215516</td>\n","      <td>0.306102</td>\n","      <td>0.322441</td>\n","      <td>0.338780</td>\n","      <td>0.209403</td>\n","      <td>0.080027</td>\n","      <td>0.056352</td>\n","      <td>0.032678</td>\n","      <td>...</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.00000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>32.478891</td>\n","      <td>0.499374</td>\n","      <td>1.000000</td>\n","      <td>0.547399</td>\n","      <td>-0.003362</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>25 rows × 2630 columns</p>\n","</div>\n","      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-6f1039ac-2c34-49c9-88eb-60d0f7574f6a')\"\n","              title=\"Convert this dataframe to an interactive table.\"\n","              style=\"display:none;\">\n","        \n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","       width=\"24px\">\n","    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n","    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n","  </svg>\n","      </button>\n","      \n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      flex-wrap:wrap;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","      <script>\n","        const buttonEl =\n","          document.querySelector('#df-6f1039ac-2c34-49c9-88eb-60d0f7574f6a button.colab-df-convert');\n","        buttonEl.style.display =\n","          google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","        async function convertToInteractive(key) {\n","          const element = document.querySelector('#df-6f1039ac-2c34-49c9-88eb-60d0f7574f6a');\n","          const dataTable =\n","            await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                     [key], {});\n","          if (!dataTable) return;\n","\n","          const docLinkHtml = 'Like what you see? Visit the ' +\n","            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","            + ' to learn more about interactive tables.';\n","          element.innerHTML = '';\n","          dataTable['output_type'] = 'display_data';\n","          await google.colab.output.renderOutput(dataTable, element);\n","          const docLink = document.createElement('div');\n","          docLink.innerHTML = docLinkHtml;\n","          element.appendChild(docLink);\n","        }\n","      </script>\n","    </div>\n","  </div>\n","  "]},"metadata":{},"execution_count":16}],"source":["results.drop(['Sample ID'], axis=1, inplace=True)\n","results.head(25)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"aZ9X123KAZlq"},"outputs":[],"source":["feature_names = []\n","for col in features.columns:\n","    feature_names.append(col)\n","thresh = 3\n","data = results.copy()\n","for feat in feature_names:\n","    mean = np.mean(data[feat])\n","    std = np.std(data[feat]) \n","    for x in data[feat]:\n","        z = (x-mean)/std\n","        if z > thresh:\n","            data[feat] = data[feat].replace(x,mean)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"_z8mNrqUpn2m"},"outputs":[],"source":["y = results['Pollen'] # we are using channel as target variable\n","X = results.drop(['Pollen'], axis=1)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"v2cPwEn3db9C"},"outputs":[],"source":["temp = pd.DataFrame(results['Pollen'], columns=[\"0\", \"1\", \"2\",\"3\",\"4\",\"5\",\"6\",\"7\",\"8\",\"9\",\"10\",\"11\"])"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"6vffj4U8eDOg"},"outputs":[],"source":["for i in y:\n","  temp2 = np.zeros(12)\n","  temp2[i] = 1\n","  temp = temp.append(pd.DataFrame(temp2.reshape(1,-1), columns=list(temp)), ignore_index=True)\n","y = temp"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"dP7eHPt3pn2p"},"outputs":[],"source":["# pca = decomposition.PCA() #instantiates PCA object\n","# X_pca = pca.fit_transform(X) #performs dimension reduction on x and fits it to the PCA model\n","\n","# temp = pca.explained_variance_ratio_ #this ratio tells us how much information is compressed into the first few components\n","#                               #we can use this to calculate cumulative variance, with this we can figure out how many components to keep\n","#                               #we need to make sure we keep at least 70% of the original data set's information"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"JChoJwFcqka4"},"outputs":[],"source":["# print(temp[:10])"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"tI8UB5BZrpm9"},"outputs":[],"source":["# temp[:100].sum()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"I8y8a4IEZW1Y"},"outputs":[],"source":["from sklearn.model_selection import train_test_split\n","X_train, X_test, y_train, y_test = train_test_split(X, y, shuffle = True, test_size=0.4, random_state=42)\n","X_test, X_Val, y_test, y_Val = train_test_split(X_test, y_test, shuffle = True, test_size=0.5, random_state=42)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"VtZWKtv4Zbdu","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1675498043221,"user_tz":300,"elapsed":62085,"user":{"displayName":"Randy Huynh","userId":"07672825704789203793"}},"outputId":"ddf6129e-a3a7-4fda-a4d1-6e0f2a7961bd"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["array([[-0.05710052, -0.06293863, -0.03775057, ..., -0.19221746,\n","        -0.0423612 , -0.05352188],\n","       [-0.14328951, -0.27026613, -0.67146036, ..., -0.04831655,\n","        -0.01328223, -0.02007947],\n","       [-0.04551721, -0.04751691, -0.02697836, ...,  0.73916241,\n","        -0.57437807, -0.18120631],\n","       ...,\n","       [ 0.88946194,  0.17619084,  0.05636417, ..., -0.03066016,\n","        -0.00869233, -0.01356132],\n","       [ 0.88946194,  0.17619084,  0.05636417, ..., -0.03066016,\n","        -0.00869233, -0.01356132],\n","       [-0.0681344 , -0.07932107, -0.05061037, ..., -0.10667792,\n","        -0.02665181, -0.0369523 ]])"]},"metadata":{},"execution_count":25}],"source":["from sklearn.decomposition import PCA\n","import tensorflow as tf\n","pca = PCA(n_components = 0.95)\n","pca.fit_transform(X_train)\n","pca.fit_transform(X_test)\n","pca.fit_transform(X_Val)\n","pca.fit_transform(y_train)\n","pca.fit_transform(y_test)\n","pca.fit_transform(y_Val)\n","# y_train = pd.DataFrame(y_train.reshape(len(y_train),1))\n","# y_test = pd.DataFrame(y_test.reshape(len(y_test),1))\n","# y_train = tf.keras.utils.to_categorical(y_train,12)\n","# y_test = tf.keras.utils.to_categorical(y_test,12)\n","# y_Val = tf.keras.utils.to_categorical(y_Val, 12)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"W4aMoUEVgcQM"},"outputs":[],"source":["from tensorflow.keras.models import Sequential\n","from keras.layers import Dense, Dropout, BatchNormalization, Activation\n","from tensorflow.keras.optimizers import SGD\n","from keras.metrics import Precision, Recall\n","\n","# model = Sequential()\n","# model.add(tf.keras.layers.Input(shape = 2629,))\n","# model.add(tf.keras.layers.Dense(20,activation = 'relu'))\n","# model.add(tf.keras.layers.Dense(10,activation = 'relu'))\n","# model.add(tf.keras.layers.Dense(12,activation = 'relu'))\n","# model.add(tf.keras.layers.Dropout(0.5))\n","\n","# model.add(tf.keras.layers.Dense(12,activation = 'softmax'))\n","# model.compile(optimizer =SGD(lr = 0.01,momentum=0.9), loss = \"categorical_crossentropy\", metrics = [\"accuracy\", Precision(), Recall()])#metrics = [\"accuracy\", Precision(), Recall()]"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"7d7NG5iuhuv_","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1675498043750,"user_tz":300,"elapsed":538,"user":{"displayName":"Randy Huynh","userId":"07672825704789203793"}},"outputId":"57a6b48f-1a5d-40de-8fa9-742342b3e1fb"},"outputs":[{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.8/dist-packages/keras/optimizers/optimizer_v2/gradient_descent.py:108: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n","  super(SGD, self).__init__(name, **kwargs)\n"]}],"source":["model = tf.keras.Sequential([\n","    tf.keras.layers.Input(2629),\n","    tf.keras.layers.Dense(2048),\n","    tf.keras.layers.Dropout(0.5),\n","    tf.keras.layers.BatchNormalization(),\n","    tf.keras.layers.Dense(1024),\n","    tf.keras.layers.Dropout(0.5),\n","    tf.keras.layers.BatchNormalization(),\n","    tf.keras.layers.Activation(\"relu\"),\n","    tf.keras.layers.Dense(512),\n","    tf.keras.layers.BatchNormalization(),\n","    tf.keras.layers.Dropout(0.4),\n","    tf.keras.layers.Dense(400),\n","    tf.keras.layers.BatchNormalization(),\n","    tf.keras.layers.Dropout(0.5),\n","    tf.keras.layers.Dense(12, activation=\"softmax\")\n","    ])\n","model.compile(optimizer =SGD(lr = 0.001,momentum=0.9), loss = \"categorical_crossentropy\", metrics = [\"accuracy\", Precision(), Recall()])#metrics = [\"accuracy\", Precision(), Recall()]\n","# model.compile(optimizer=tf.optimizers.Adam(),\n","#                   loss='binary_crossentropy', \n","#                   )"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"2lssN7kV_PiS"},"outputs":[],"source":["# import pickle\n","# model = pickle.load(open('/content/drive/MyDrive/ENG 4000/model.pkl', 'rb'))"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"e5yDPIq__Sc2"},"outputs":[],"source":["# # valuesToPredict = X\n","# # pca.fit_transform(valuesToPredict)\n","# output = model.predict(X_Val)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"MScsXToLg2ch","outputId":"6f2410e3-f69c-4326-b5c5-d0ba080dca84"},"outputs":[{"output_type":"stream","name":"stdout","text":["Epoch 1/10000\n","185/185 [==============================] - 20s 99ms/step - loss: 3.4017 - accuracy: 0.1232 - precision: 0.1416 - recall: 0.0529 - val_loss: 2.3090 - val_accuracy: 0.2315 - val_precision: 0.2162 - val_recall: 0.0041\n","Epoch 2/10000\n","185/185 [==============================] - 17s 91ms/step - loss: 2.9475 - accuracy: 0.1417 - precision: 0.1688 - recall: 0.0416 - val_loss: 2.2735 - val_accuracy: 0.2143 - val_precision: 0.2162 - val_recall: 0.0041\n","Epoch 3/10000\n","185/185 [==============================] - 17s 92ms/step - loss: 2.7161 - accuracy: 0.1554 - precision: 0.2007 - recall: 0.0363 - val_loss: 2.2414 - val_accuracy: 0.2305 - val_precision: 1.0000 - val_recall: 5.0659e-04\n","Epoch 4/10000\n","185/185 [==============================] - 18s 98ms/step - loss: 2.5841 - accuracy: 0.1656 - precision: 0.2087 - recall: 0.0250 - val_loss: 2.2417 - val_accuracy: 0.2275 - val_precision: 0.3774 - val_recall: 0.0101\n","Epoch 5/10000\n","185/185 [==============================] - 18s 96ms/step - loss: 2.4806 - accuracy: 0.1772 - precision: 0.2481 - recall: 0.0223 - val_loss: 2.2344 - val_accuracy: 0.2300 - val_precision: 1.0000 - val_recall: 5.0659e-04\n","Epoch 6/10000\n","185/185 [==============================] - 17s 93ms/step - loss: 2.4057 - accuracy: 0.1896 - precision: 0.2814 - recall: 0.0189 - val_loss: 2.2256 - val_accuracy: 0.2340 - val_precision: 0.1000 - val_recall: 5.0659e-04\n","Epoch 7/10000\n","185/185 [==============================] - 19s 101ms/step - loss: 2.3704 - accuracy: 0.1899 - precision: 0.3084 - recall: 0.0161 - val_loss: 2.2192 - val_accuracy: 0.2310 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n","Epoch 8/10000\n","185/185 [==============================] - 17s 91ms/step - loss: 2.3320 - accuracy: 0.2034 - precision: 0.3142 - recall: 0.0139 - val_loss: 2.2057 - val_accuracy: 0.2447 - val_precision: 0.2353 - val_recall: 0.0020\n","Epoch 9/10000\n","185/185 [==============================] - 18s 97ms/step - loss: 2.3140 - accuracy: 0.1989 - precision: 0.2681 - recall: 0.0106 - val_loss: 2.2000 - val_accuracy: 0.2563 - val_precision: 0.3000 - val_recall: 0.0046\n","Epoch 10/10000\n","185/185 [==============================] - 22s 119ms/step - loss: 2.2781 - accuracy: 0.2147 - precision: 0.2926 - recall: 0.0113 - val_loss: 2.1951 - val_accuracy: 0.2629 - val_precision: 0.2632 - val_recall: 0.0025\n","Epoch 11/10000\n","185/185 [==============================] - 17s 92ms/step - loss: 2.2711 - accuracy: 0.2141 - precision: 0.2609 - recall: 0.0081 - val_loss: 2.1886 - val_accuracy: 0.2680 - val_precision: 0.6667 - val_recall: 0.0010\n","Epoch 12/10000\n","185/185 [==============================] - 17s 92ms/step - loss: 2.2521 - accuracy: 0.2169 - precision: 0.2750 - recall: 0.0093 - val_loss: 2.1938 - val_accuracy: 0.2660 - val_precision: 0.5000 - val_recall: 5.0659e-04\n","Epoch 13/10000\n","185/185 [==============================] - 17s 90ms/step - loss: 2.2342 - accuracy: 0.2239 - precision: 0.3086 - recall: 0.0084 - val_loss: 2.1775 - val_accuracy: 0.2720 - val_precision: 0.1429 - val_recall: 5.0659e-04\n","Epoch 14/10000\n","185/185 [==============================] - 18s 96ms/step - loss: 2.2166 - accuracy: 0.2429 - precision: 0.3202 - recall: 0.0123 - val_loss: 2.1711 - val_accuracy: 0.2857 - val_precision: 0.2500 - val_recall: 5.0659e-04\n","Epoch 15/10000\n","185/185 [==============================] - 16s 88ms/step - loss: 2.2153 - accuracy: 0.2386 - precision: 0.3770 - recall: 0.0122 - val_loss: 2.1744 - val_accuracy: 0.2771 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n","Epoch 16/10000\n","185/185 [==============================] - 16s 89ms/step - loss: 2.2034 - accuracy: 0.2391 - precision: 0.3732 - recall: 0.0132 - val_loss: 2.1818 - val_accuracy: 0.2776 - val_precision: 0.2889 - val_recall: 0.0066\n","Epoch 17/10000\n","185/185 [==============================] - 17s 90ms/step - loss: 2.1945 - accuracy: 0.2357 - precision: 0.3320 - recall: 0.0139 - val_loss: 2.1553 - val_accuracy: 0.2857 - val_precision: 0.3182 - val_recall: 0.0035\n","Epoch 18/10000\n","185/185 [==============================] - 19s 100ms/step - loss: 2.1929 - accuracy: 0.2397 - precision: 0.3476 - recall: 0.0137 - val_loss: 2.1610 - val_accuracy: 0.2867 - val_precision: 0.3103 - val_recall: 0.0091\n","Epoch 19/10000\n","185/185 [==============================] - 17s 94ms/step - loss: 2.1986 - accuracy: 0.2391 - precision: 0.3394 - recall: 0.0127 - val_loss: 2.1562 - val_accuracy: 0.2893 - val_precision: 0.3176 - val_recall: 0.0137\n","Epoch 20/10000\n","185/185 [==============================] - 16s 89ms/step - loss: 2.1772 - accuracy: 0.2446 - precision: 0.3577 - recall: 0.0157 - val_loss: 2.1588 - val_accuracy: 0.2776 - val_precision: 0.3208 - val_recall: 0.0086\n","Epoch 21/10000\n","185/185 [==============================] - 16s 89ms/step - loss: 2.1747 - accuracy: 0.2484 - precision: 0.3674 - recall: 0.0133 - val_loss: 2.1569 - val_accuracy: 0.2862 - val_precision: 0.3400 - val_recall: 0.0086\n","Epoch 22/10000\n","185/185 [==============================] - 16s 89ms/step - loss: 2.1584 - accuracy: 0.2563 - precision: 0.3138 - recall: 0.0127 - val_loss: 2.1419 - val_accuracy: 0.2999 - val_precision: 0.3333 - val_recall: 0.0051\n","Epoch 23/10000\n","185/185 [==============================] - 17s 92ms/step - loss: 2.1607 - accuracy: 0.2507 - precision: 0.4057 - recall: 0.0167 - val_loss: 2.1554 - val_accuracy: 0.3045 - val_precision: 0.3826 - val_recall: 0.0223\n","Epoch 24/10000\n","185/185 [==============================] - 18s 94ms/step - loss: 2.1523 - accuracy: 0.2663 - precision: 0.3709 - recall: 0.0189 - val_loss: 2.1112 - val_accuracy: 0.3090 - val_precision: 0.4286 - val_recall: 0.0106\n","Epoch 25/10000\n","185/185 [==============================] - 16s 89ms/step - loss: 2.1429 - accuracy: 0.2570 - precision: 0.4153 - recall: 0.0211 - val_loss: 2.1545 - val_accuracy: 0.3009 - val_precision: 0.4061 - val_recall: 0.0339\n","Epoch 26/10000\n","185/185 [==============================] - 16s 88ms/step - loss: 2.1477 - accuracy: 0.2509 - precision: 0.3664 - recall: 0.0181 - val_loss: 2.1222 - val_accuracy: 0.3110 - val_precision: 0.4362 - val_recall: 0.0208\n","Epoch 27/10000\n","185/185 [==============================] - 16s 89ms/step - loss: 2.1313 - accuracy: 0.2625 - precision: 0.4042 - recall: 0.0196 - val_loss: 2.1350 - val_accuracy: 0.3050 - val_precision: 0.4306 - val_recall: 0.0314\n","Epoch 28/10000\n","185/185 [==============================] - 16s 88ms/step - loss: 2.1279 - accuracy: 0.2669 - precision: 0.4079 - recall: 0.0191 - val_loss: 2.1579 - val_accuracy: 0.2999 - val_precision: 0.4036 - val_recall: 0.0562\n","Epoch 29/10000\n","185/185 [==============================] - 19s 104ms/step - loss: 2.1260 - accuracy: 0.2712 - precision: 0.4444 - recall: 0.0270 - val_loss: 2.1472 - val_accuracy: 0.2964 - val_precision: 0.3779 - val_recall: 0.0415\n","Epoch 30/10000\n","185/185 [==============================] - 17s 89ms/step - loss: 2.1165 - accuracy: 0.2712 - precision: 0.3972 - recall: 0.0242 - val_loss: 2.1062 - val_accuracy: 0.3019 - val_precision: 0.4167 - val_recall: 0.0279\n","Epoch 31/10000\n","185/185 [==============================] - 16s 88ms/step - loss: 2.1002 - accuracy: 0.2786 - precision: 0.4169 - recall: 0.0267 - val_loss: 2.0999 - val_accuracy: 0.3029 - val_precision: 0.4872 - val_recall: 0.0289\n","Epoch 32/10000\n","185/185 [==============================] - 17s 89ms/step - loss: 2.1268 - accuracy: 0.2720 - precision: 0.4162 - recall: 0.0260 - val_loss: 2.0920 - val_accuracy: 0.3141 - val_precision: 0.4957 - val_recall: 0.0289\n","Epoch 33/10000\n","185/185 [==============================] - 17s 91ms/step - loss: 2.1081 - accuracy: 0.2730 - precision: 0.3890 - recall: 0.0240 - val_loss: 2.1043 - val_accuracy: 0.3065 - val_precision: 0.4261 - val_recall: 0.0380\n","Epoch 34/10000\n","185/185 [==============================] - 17s 94ms/step - loss: 2.1175 - accuracy: 0.2691 - precision: 0.3969 - recall: 0.0257 - val_loss: 2.1099 - val_accuracy: 0.3055 - val_precision: 0.4509 - val_recall: 0.0395\n","Epoch 35/10000\n","185/185 [==============================] - 16s 88ms/step - loss: 2.0982 - accuracy: 0.2833 - precision: 0.4297 - recall: 0.0279 - val_loss: 2.1178 - val_accuracy: 0.3050 - val_precision: 0.4344 - val_recall: 0.0537\n","Epoch 36/10000\n","185/185 [==============================] - 16s 89ms/step - loss: 2.0830 - accuracy: 0.2823 - precision: 0.4200 - recall: 0.0306 - val_loss: 2.1150 - val_accuracy: 0.3131 - val_precision: 0.4405 - val_recall: 0.0562\n","Epoch 37/10000\n","185/185 [==============================] - 16s 89ms/step - loss: 2.0737 - accuracy: 0.2855 - precision: 0.4656 - recall: 0.0377 - val_loss: 2.1406 - val_accuracy: 0.2989 - val_precision: 0.4275 - val_recall: 0.0567\n","Epoch 38/10000\n","185/185 [==============================] - 16s 87ms/step - loss: 2.0690 - accuracy: 0.2903 - precision: 0.4481 - recall: 0.0372 - val_loss: 2.1033 - val_accuracy: 0.3040 - val_precision: 0.4359 - val_recall: 0.0517\n","Epoch 39/10000\n","185/185 [==============================] - 18s 95ms/step - loss: 2.0759 - accuracy: 0.2869 - precision: 0.4533 - recall: 0.0385 - val_loss: 2.0903 - val_accuracy: 0.3060 - val_precision: 0.5050 - val_recall: 0.0517\n","Epoch 40/10000\n","185/185 [==============================] - 18s 98ms/step - loss: 2.0592 - accuracy: 0.2943 - precision: 0.4598 - recall: 0.0377 - val_loss: 2.0967 - val_accuracy: 0.3131 - val_precision: 0.4503 - val_recall: 0.0689\n","Epoch 41/10000\n","185/185 [==============================] - 16s 89ms/step - loss: 2.0634 - accuracy: 0.2958 - precision: 0.4413 - recall: 0.0400 - val_loss: 2.0788 - val_accuracy: 0.3217 - val_precision: 0.4749 - val_recall: 0.0623\n","Epoch 42/10000\n","185/185 [==============================] - 17s 90ms/step - loss: 2.0590 - accuracy: 0.2948 - precision: 0.4429 - recall: 0.0387 - val_loss: 2.0873 - val_accuracy: 0.3242 - val_precision: 0.4962 - val_recall: 0.0659\n","Epoch 43/10000\n","185/185 [==============================] - 16s 89ms/step - loss: 2.0557 - accuracy: 0.2955 - precision: 0.4542 - recall: 0.0402 - val_loss: 2.0894 - val_accuracy: 0.3156 - val_precision: 0.4766 - val_recall: 0.0618\n","Epoch 44/10000\n","185/185 [==============================] - 18s 96ms/step - loss: 2.0498 - accuracy: 0.2990 - precision: 0.4484 - recall: 0.0382 - val_loss: 2.0711 - val_accuracy: 0.3116 - val_precision: 0.5212 - val_recall: 0.0623\n","Epoch 45/10000\n","185/185 [==============================] - 17s 92ms/step - loss: 2.0392 - accuracy: 0.3001 - precision: 0.4679 - recall: 0.0480 - val_loss: 2.0933 - val_accuracy: 0.3166 - val_precision: 0.4853 - val_recall: 0.0836\n","Epoch 46/10000\n","185/185 [==============================] - 21s 111ms/step - loss: 2.0382 - accuracy: 0.3085 - precision: 0.4393 - recall: 0.0416 - val_loss: 2.0713 - val_accuracy: 0.3090 - val_precision: 0.4641 - val_recall: 0.0719\n","Epoch 47/10000\n","185/185 [==============================] - 17s 90ms/step - loss: 2.0265 - accuracy: 0.3048 - precision: 0.4739 - recall: 0.0505 - val_loss: 2.0927 - val_accuracy: 0.3156 - val_precision: 0.4347 - val_recall: 0.0826\n","Epoch 48/10000\n","185/185 [==============================] - 17s 93ms/step - loss: 2.0300 - accuracy: 0.3038 - precision: 0.4626 - recall: 0.0449 - val_loss: 2.0819 - val_accuracy: 0.3121 - val_precision: 0.4366 - val_recall: 0.0907\n","Epoch 49/10000\n","185/185 [==============================] - 18s 96ms/step - loss: 2.0349 - accuracy: 0.3038 - precision: 0.4662 - recall: 0.0466 - val_loss: 2.0877 - val_accuracy: 0.3186 - val_precision: 0.4439 - val_recall: 0.0942\n","Epoch 50/10000\n","185/185 [==============================] - 17s 90ms/step - loss: 2.0356 - accuracy: 0.3016 - precision: 0.4682 - recall: 0.0485 - val_loss: 2.0836 - val_accuracy: 0.3126 - val_precision: 0.4442 - val_recall: 0.0907\n","Epoch 51/10000\n","185/185 [==============================] - 18s 99ms/step - loss: 2.0299 - accuracy: 0.3058 - precision: 0.4470 - recall: 0.0492 - val_loss: 2.0457 - val_accuracy: 0.3237 - val_precision: 0.5694 - val_recall: 0.0603\n","Epoch 52/10000\n","185/185 [==============================] - 17s 92ms/step - loss: 2.0272 - accuracy: 0.3046 - precision: 0.4517 - recall: 0.0443 - val_loss: 2.0766 - val_accuracy: 0.3207 - val_precision: 0.4398 - val_recall: 0.0851\n","Epoch 53/10000\n","185/185 [==============================] - 18s 95ms/step - loss: 2.0188 - accuracy: 0.3070 - precision: 0.4481 - recall: 0.0488 - val_loss: 2.0717 - val_accuracy: 0.3262 - val_precision: 0.4512 - val_recall: 0.0866\n","Epoch 54/10000\n","185/185 [==============================] - 17s 94ms/step - loss: 2.0032 - accuracy: 0.3171 - precision: 0.4713 - recall: 0.0541 - val_loss: 2.0296 - val_accuracy: 0.3343 - val_precision: 0.5612 - val_recall: 0.0674\n","Epoch 55/10000\n","185/185 [==============================] - 17s 89ms/step - loss: 2.0043 - accuracy: 0.3142 - precision: 0.4943 - recall: 0.0590 - val_loss: 2.1296 - val_accuracy: 0.2999 - val_precision: 0.4505 - val_recall: 0.1013\n","Epoch 56/10000\n","185/185 [==============================] - 17s 90ms/step - loss: 2.0093 - accuracy: 0.3120 - precision: 0.4470 - recall: 0.0534 - val_loss: 2.0441 - val_accuracy: 0.3323 - val_precision: 0.5170 - val_recall: 0.0770\n","Epoch 57/10000\n","185/185 [==============================] - 16s 89ms/step - loss: 1.9890 - accuracy: 0.3222 - precision: 0.4841 - recall: 0.0566 - val_loss: 2.0555 - val_accuracy: 0.3257 - val_precision: 0.5241 - val_recall: 0.0993\n","Epoch 58/10000\n","185/185 [==============================] - 17s 93ms/step - loss: 1.9989 - accuracy: 0.3190 - precision: 0.4812 - recall: 0.0607 - val_loss: 2.0760 - val_accuracy: 0.3110 - val_precision: 0.5113 - val_recall: 0.1033\n","Epoch 59/10000\n","185/185 [==============================] - 17s 93ms/step - loss: 1.9966 - accuracy: 0.3141 - precision: 0.4590 - recall: 0.0520 - val_loss: 2.0560 - val_accuracy: 0.3323 - val_precision: 0.4853 - val_recall: 0.0922\n","Epoch 60/10000\n","185/185 [==============================] - 17s 89ms/step - loss: 1.9725 - accuracy: 0.3212 - precision: 0.4894 - recall: 0.0662 - val_loss: 2.0430 - val_accuracy: 0.3338 - val_precision: 0.5172 - val_recall: 0.0912\n","Epoch 61/10000\n","185/185 [==============================] - 17s 90ms/step - loss: 1.9865 - accuracy: 0.3169 - precision: 0.4695 - recall: 0.0637 - val_loss: 2.0609 - val_accuracy: 0.3293 - val_precision: 0.4825 - val_recall: 0.0907\n","Epoch 62/10000\n","185/185 [==============================] - 18s 97ms/step - loss: 1.9894 - accuracy: 0.3168 - precision: 0.4910 - recall: 0.0649 - val_loss: 2.0711 - val_accuracy: 0.3166 - val_precision: 0.4887 - val_recall: 0.0988\n","Epoch 63/10000\n","185/185 [==============================] - 17s 94ms/step - loss: 1.9896 - accuracy: 0.3215 - precision: 0.4793 - recall: 0.0566 - val_loss: 2.0525 - val_accuracy: 0.3267 - val_precision: 0.4558 - val_recall: 0.0993\n","Epoch 64/10000\n","185/185 [==============================] - 17s 92ms/step - loss: 1.9836 - accuracy: 0.3210 - precision: 0.4493 - recall: 0.0576 - val_loss: 2.0901 - val_accuracy: 0.3313 - val_precision: 0.4988 - val_recall: 0.1023\n","Epoch 65/10000\n","185/185 [==============================] - 16s 89ms/step - loss: 1.9791 - accuracy: 0.3237 - precision: 0.4502 - recall: 0.0603 - val_loss: 2.0576 - val_accuracy: 0.3318 - val_precision: 0.5013 - val_recall: 0.0942\n","Epoch 66/10000\n","185/185 [==============================] - 16s 88ms/step - loss: 1.9653 - accuracy: 0.3313 - precision: 0.5206 - recall: 0.0684 - val_loss: 2.0566 - val_accuracy: 0.3267 - val_precision: 0.5272 - val_recall: 0.0983\n","Epoch 67/10000\n","185/185 [==============================] - 16s 89ms/step - loss: 1.9687 - accuracy: 0.3207 - precision: 0.4850 - recall: 0.0656 - val_loss: 2.0615 - val_accuracy: 0.3273 - val_precision: 0.4729 - val_recall: 0.1150\n","Epoch 68/10000\n","185/185 [==============================] - 17s 94ms/step - loss: 1.9716 - accuracy: 0.3323 - precision: 0.4891 - recall: 0.0644 - val_loss: 2.0478 - val_accuracy: 0.3318 - val_precision: 0.5344 - val_recall: 0.1140\n","Epoch 69/10000\n","185/185 [==============================] - 18s 95ms/step - loss: 1.9542 - accuracy: 0.3284 - precision: 0.5279 - recall: 0.0735 - val_loss: 2.0811 - val_accuracy: 0.3222 - val_precision: 0.4393 - val_recall: 0.1155\n","Epoch 70/10000\n","185/185 [==============================] - 17s 92ms/step - loss: 1.9576 - accuracy: 0.3381 - precision: 0.4791 - recall: 0.0696 - val_loss: 2.0600 - val_accuracy: 0.3333 - val_precision: 0.5136 - val_recall: 0.1145\n","Epoch 71/10000\n","185/185 [==============================] - 17s 91ms/step - loss: 1.9516 - accuracy: 0.3251 - precision: 0.5189 - recall: 0.0765 - val_loss: 2.0494 - val_accuracy: 0.3379 - val_precision: 0.4749 - val_recall: 0.1150\n","Epoch 72/10000\n","185/185 [==============================] - 17s 92ms/step - loss: 1.9557 - accuracy: 0.3330 - precision: 0.5089 - recall: 0.0726 - val_loss: 2.0092 - val_accuracy: 0.3526 - val_precision: 0.4907 - val_recall: 0.1069\n","Epoch 73/10000\n","185/185 [==============================] - 20s 107ms/step - loss: 1.9425 - accuracy: 0.3291 - precision: 0.5056 - recall: 0.0765 - val_loss: 2.0645 - val_accuracy: 0.3359 - val_precision: 0.4864 - val_recall: 0.1175\n","Epoch 74/10000\n","185/185 [==============================] - 17s 91ms/step - loss: 1.9534 - accuracy: 0.3357 - precision: 0.5005 - recall: 0.0799 - val_loss: 2.0566 - val_accuracy: 0.3303 - val_precision: 0.4676 - val_recall: 0.1317\n","Epoch 75/10000\n","185/185 [==============================] - 17s 91ms/step - loss: 1.9449 - accuracy: 0.3332 - precision: 0.5064 - recall: 0.0735 - val_loss: 2.0084 - val_accuracy: 0.3333 - val_precision: 0.5114 - val_recall: 0.1023\n","Epoch 76/10000\n","185/185 [==============================] - 17s 93ms/step - loss: 1.9322 - accuracy: 0.3441 - precision: 0.5346 - recall: 0.0848 - val_loss: 2.0466 - val_accuracy: 0.3303 - val_precision: 0.4567 - val_recall: 0.1175\n","Epoch 77/10000\n","185/185 [==============================] - 18s 98ms/step - loss: 1.9289 - accuracy: 0.3377 - precision: 0.5205 - recall: 0.0816 - val_loss: 2.0640 - val_accuracy: 0.3298 - val_precision: 0.4407 - val_recall: 0.1185\n","Epoch 78/10000\n","185/185 [==============================] - 17s 93ms/step - loss: 1.9355 - accuracy: 0.3379 - precision: 0.5170 - recall: 0.0823 - val_loss: 2.1144 - val_accuracy: 0.3186 - val_precision: 0.4397 - val_recall: 0.1424\n","Epoch 79/10000\n","185/185 [==============================] - 18s 95ms/step - loss: 1.9367 - accuracy: 0.3355 - precision: 0.5118 - recall: 0.0809 - val_loss: 2.0316 - val_accuracy: 0.3278 - val_precision: 0.4768 - val_recall: 0.1251\n","Epoch 80/10000\n","185/185 [==============================] - 18s 96ms/step - loss: 1.9249 - accuracy: 0.3414 - precision: 0.4990 - recall: 0.0848 - val_loss: 2.0727 - val_accuracy: 0.3394 - val_precision: 0.4545 - val_recall: 0.1292\n","Epoch 81/10000\n","185/185 [==============================] - 18s 100ms/step - loss: 1.9313 - accuracy: 0.3489 - precision: 0.5181 - recall: 0.0823 - val_loss: 2.0966 - val_accuracy: 0.3394 - val_precision: 0.4643 - val_recall: 0.1353\n","Epoch 82/10000\n","185/185 [==============================] - 18s 95ms/step - loss: 1.9280 - accuracy: 0.3377 - precision: 0.5268 - recall: 0.0897 - val_loss: 2.0950 - val_accuracy: 0.3242 - val_precision: 0.4381 - val_recall: 0.1398\n","Epoch 83/10000\n","185/185 [==============================] - 19s 101ms/step - loss: 1.9219 - accuracy: 0.3458 - precision: 0.5233 - recall: 0.0855 - val_loss: 2.1087 - val_accuracy: 0.3313 - val_precision: 0.4580 - val_recall: 0.1216\n","Epoch 84/10000\n","185/185 [==============================] - 17s 92ms/step - loss: 1.9081 - accuracy: 0.3419 - precision: 0.5244 - recall: 0.0890 - val_loss: 2.0515 - val_accuracy: 0.3369 - val_precision: 0.4958 - val_recall: 0.1206\n","Epoch 85/10000\n","185/185 [==============================] - 17s 92ms/step - loss: 1.8950 - accuracy: 0.3502 - precision: 0.5371 - recall: 0.0953 - val_loss: 2.0268 - val_accuracy: 0.3501 - val_precision: 0.4807 - val_recall: 0.1327\n","Epoch 86/10000\n","185/185 [==============================] - 18s 100ms/step - loss: 1.9194 - accuracy: 0.3440 - precision: 0.5233 - recall: 0.0948 - val_loss: 2.1136 - val_accuracy: 0.3242 - val_precision: 0.4378 - val_recall: 0.1302\n","Epoch 87/10000\n","185/185 [==============================] - 17s 92ms/step - loss: 1.9071 - accuracy: 0.3441 - precision: 0.5271 - recall: 0.0904 - val_loss: 2.0848 - val_accuracy: 0.3313 - val_precision: 0.4720 - val_recall: 0.1322\n","Epoch 88/10000\n","185/185 [==============================] - 17s 91ms/step - loss: 1.8845 - accuracy: 0.3605 - precision: 0.5385 - recall: 0.0958 - val_loss: 2.0873 - val_accuracy: 0.3338 - val_precision: 0.4506 - val_recall: 0.1408\n","Epoch 89/10000\n","185/185 [==============================] - 17s 91ms/step - loss: 1.8947 - accuracy: 0.3545 - precision: 0.5330 - recall: 0.0970 - val_loss: 2.0365 - val_accuracy: 0.3430 - val_precision: 0.4863 - val_recall: 0.1353\n","Epoch 90/10000\n","185/185 [==============================] - 18s 98ms/step - loss: 1.8903 - accuracy: 0.3565 - precision: 0.5226 - recall: 0.0997 - val_loss: 2.0866 - val_accuracy: 0.3207 - val_precision: 0.4805 - val_recall: 0.1499\n","Epoch 91/10000\n","185/185 [==============================] - 17s 93ms/step - loss: 1.9036 - accuracy: 0.3501 - precision: 0.5119 - recall: 0.0944 - val_loss: 2.0236 - val_accuracy: 0.3511 - val_precision: 0.5000 - val_recall: 0.1185\n","Epoch 92/10000\n","185/185 [==============================] - 17s 92ms/step - loss: 1.8999 - accuracy: 0.3609 - precision: 0.5474 - recall: 0.1034 - val_loss: 2.0654 - val_accuracy: 0.3409 - val_precision: 0.5173 - val_recall: 0.1211\n","Epoch 93/10000\n","185/185 [==============================] - 18s 100ms/step - loss: 1.8917 - accuracy: 0.3551 - precision: 0.5217 - recall: 0.0955 - val_loss: 2.0716 - val_accuracy: 0.3369 - val_precision: 0.4651 - val_recall: 0.1418\n","Epoch 94/10000\n","185/185 [==============================] - 18s 100ms/step - loss: 1.8804 - accuracy: 0.3543 - precision: 0.5409 - recall: 0.1085 - val_loss: 2.0740 - val_accuracy: 0.3283 - val_precision: 0.4369 - val_recall: 0.1297\n","Epoch 95/10000\n","185/185 [==============================] - 17s 93ms/step - loss: 1.8893 - accuracy: 0.3517 - precision: 0.5187 - recall: 0.0961 - val_loss: 2.0528 - val_accuracy: 0.3354 - val_precision: 0.4636 - val_recall: 0.1226\n","Epoch 96/10000\n","185/185 [==============================] - 17s 92ms/step - loss: 1.8793 - accuracy: 0.3553 - precision: 0.5481 - recall: 0.1059 - val_loss: 2.0842 - val_accuracy: 0.3338 - val_precision: 0.4789 - val_recall: 0.1439\n","Epoch 97/10000\n","185/185 [==============================] - 17s 92ms/step - loss: 1.8847 - accuracy: 0.3543 - precision: 0.5086 - recall: 0.0946 - val_loss: 2.0742 - val_accuracy: 0.3318 - val_precision: 0.4735 - val_recall: 0.1358\n","Epoch 98/10000\n","185/185 [==============================] - 19s 100ms/step - loss: 1.8831 - accuracy: 0.3648 - precision: 0.5406 - recall: 0.1034 - val_loss: 2.0766 - val_accuracy: 0.3349 - val_precision: 0.4618 - val_recall: 0.1439\n","Epoch 99/10000\n","185/185 [==============================] - 17s 93ms/step - loss: 1.8707 - accuracy: 0.3637 - precision: 0.5446 - recall: 0.1063 - val_loss: 2.0886 - val_accuracy: 0.3242 - val_precision: 0.4517 - val_recall: 0.1540\n","Epoch 100/10000\n","185/185 [==============================] - 17s 93ms/step - loss: 1.8722 - accuracy: 0.3653 - precision: 0.5526 - recall: 0.1118 - val_loss: 2.0962 - val_accuracy: 0.3237 - val_precision: 0.4343 - val_recall: 0.1439\n","Epoch 101/10000\n","185/185 [==============================] - 17s 92ms/step - loss: 1.8576 - accuracy: 0.3686 - precision: 0.5574 - recall: 0.1124 - val_loss: 2.0950 - val_accuracy: 0.3359 - val_precision: 0.4523 - val_recall: 0.1657\n","Epoch 102/10000\n","185/185 [==============================] - 18s 98ms/step - loss: 1.8698 - accuracy: 0.3624 - precision: 0.5445 - recall: 0.1188 - val_loss: 2.0333 - val_accuracy: 0.3506 - val_precision: 0.5010 - val_recall: 0.1277\n","Epoch 103/10000\n","185/185 [==============================] - 18s 95ms/step - loss: 1.8584 - accuracy: 0.3617 - precision: 0.5426 - recall: 0.1066 - val_loss: 2.0700 - val_accuracy: 0.3460 - val_precision: 0.4300 - val_recall: 0.1510\n","Epoch 104/10000\n","185/185 [==============================] - 18s 100ms/step - loss: 1.8545 - accuracy: 0.3604 - precision: 0.5524 - recall: 0.1140 - val_loss: 2.0877 - val_accuracy: 0.3374 - val_precision: 0.4578 - val_recall: 0.1565\n","Epoch 105/10000\n","185/185 [==============================] - 17s 93ms/step - loss: 1.8621 - accuracy: 0.3578 - precision: 0.5512 - recall: 0.1137 - val_loss: 2.0862 - val_accuracy: 0.3333 - val_precision: 0.4575 - val_recall: 0.1363\n","Epoch 106/10000\n","185/185 [==============================] - 18s 97ms/step - loss: 1.8543 - accuracy: 0.3686 - precision: 0.5543 - recall: 0.1139 - val_loss: 2.0722 - val_accuracy: 0.3409 - val_precision: 0.4706 - val_recall: 0.1540\n","Epoch 107/10000\n","185/185 [==============================] - 18s 95ms/step - loss: 1.8459 - accuracy: 0.3702 - precision: 0.5545 - recall: 0.1152 - val_loss: 2.0935 - val_accuracy: 0.3293 - val_precision: 0.4564 - val_recall: 0.1565\n","Epoch 108/10000\n","185/185 [==============================] - 17s 92ms/step - loss: 1.8471 - accuracy: 0.3708 - precision: 0.5510 - recall: 0.1167 - val_loss: 2.0906 - val_accuracy: 0.3354 - val_precision: 0.4806 - val_recall: 0.1383\n","Epoch 109/10000\n","185/185 [==============================] - 17s 92ms/step - loss: 1.8335 - accuracy: 0.3720 - precision: 0.5611 - recall: 0.1218 - val_loss: 2.1033 - val_accuracy: 0.3389 - val_precision: 0.4564 - val_recall: 0.1672\n","Epoch 110/10000\n","185/185 [==============================] - 17s 93ms/step - loss: 1.8320 - accuracy: 0.3805 - precision: 0.5760 - recall: 0.1299 - val_loss: 2.0524 - val_accuracy: 0.3445 - val_precision: 0.4573 - val_recall: 0.1520\n","Epoch 111/10000\n","185/185 [==============================] - 18s 98ms/step - loss: 1.8368 - accuracy: 0.3756 - precision: 0.5654 - recall: 0.1270 - val_loss: 2.0650 - val_accuracy: 0.3409 - val_precision: 0.4879 - val_recall: 0.1631\n","Epoch 112/10000\n","185/185 [==============================] - 17s 93ms/step - loss: 1.8410 - accuracy: 0.3717 - precision: 0.5397 - recall: 0.1149 - val_loss: 2.0552 - val_accuracy: 0.3394 - val_precision: 0.4559 - val_recall: 0.1439\n","Epoch 113/10000\n","185/185 [==============================] - 17s 93ms/step - loss: 1.8426 - accuracy: 0.3730 - precision: 0.5634 - recall: 0.1223 - val_loss: 2.1357 - val_accuracy: 0.3303 - val_precision: 0.4286 - val_recall: 0.1611\n","Epoch 114/10000\n","185/185 [==============================] - 19s 102ms/step - loss: 1.8275 - accuracy: 0.3766 - precision: 0.5643 - recall: 0.1267 - val_loss: 2.1382 - val_accuracy: 0.3303 - val_precision: 0.4257 - val_recall: 0.1626\n","Epoch 115/10000\n","185/185 [==============================] - 18s 97ms/step - loss: 1.8327 - accuracy: 0.3801 - precision: 0.5520 - recall: 0.1282 - val_loss: 2.0613 - val_accuracy: 0.3511 - val_precision: 0.4656 - val_recall: 0.1510\n","Epoch 116/10000\n","185/185 [==============================] - 17s 94ms/step - loss: 1.8165 - accuracy: 0.3874 - precision: 0.5464 - recall: 0.1254 - val_loss: 2.1780 - val_accuracy: 0.3146 - val_precision: 0.4057 - val_recall: 0.1667\n","Epoch 117/10000\n","185/185 [==============================] - 17s 92ms/step - loss: 1.8201 - accuracy: 0.3781 - precision: 0.5687 - recall: 0.1328 - val_loss: 2.1264 - val_accuracy: 0.3354 - val_precision: 0.4529 - val_recall: 0.1535\n","Epoch 118/10000\n","185/185 [==============================] - 17s 92ms/step - loss: 1.8316 - accuracy: 0.3702 - precision: 0.5560 - recall: 0.1299 - val_loss: 2.0701 - val_accuracy: 0.3470 - val_precision: 0.4648 - val_recall: 0.1505\n","Epoch 119/10000\n","185/185 [==============================] - 18s 100ms/step - loss: 1.8190 - accuracy: 0.3796 - precision: 0.5556 - recall: 0.1276 - val_loss: 2.1110 - val_accuracy: 0.3425 - val_precision: 0.4520 - val_recall: 0.1525\n","Epoch 120/10000\n","185/185 [==============================] - 17s 92ms/step - loss: 1.8180 - accuracy: 0.3803 - precision: 0.5655 - recall: 0.1335 - val_loss: 2.1522 - val_accuracy: 0.3161 - val_precision: 0.4190 - val_recall: 0.1560\n","Epoch 121/10000\n","185/185 [==============================] - 17s 93ms/step - loss: 1.8103 - accuracy: 0.3756 - precision: 0.5434 - recall: 0.1259 - val_loss: 2.0589 - val_accuracy: 0.3485 - val_precision: 0.4786 - val_recall: 0.1474\n","Epoch 122/10000\n","185/185 [==============================] - 17s 93ms/step - loss: 1.8103 - accuracy: 0.3776 - precision: 0.5564 - recall: 0.1284 - val_loss: 2.1257 - val_accuracy: 0.3278 - val_precision: 0.4478 - val_recall: 0.1565\n","Epoch 123/10000\n","185/185 [==============================] - 19s 101ms/step - loss: 1.8085 - accuracy: 0.3889 - precision: 0.5755 - recall: 0.1352 - val_loss: 2.1507 - val_accuracy: 0.3313 - val_precision: 0.4112 - val_recall: 0.1596\n","Epoch 124/10000\n","185/185 [==============================] - 17s 92ms/step - loss: 1.8161 - accuracy: 0.3842 - precision: 0.5758 - recall: 0.1380 - val_loss: 2.1353 - val_accuracy: 0.3217 - val_precision: 0.4268 - val_recall: 0.1596\n","Epoch 125/10000\n","185/185 [==============================] - 19s 101ms/step - loss: 1.8034 - accuracy: 0.3840 - precision: 0.5617 - recall: 0.1377 - val_loss: 2.0841 - val_accuracy: 0.3257 - val_precision: 0.4440 - val_recall: 0.1545\n","Epoch 126/10000\n","185/185 [==============================] - 17s 93ms/step - loss: 1.8173 - accuracy: 0.3789 - precision: 0.5744 - recall: 0.1291 - val_loss: 2.1594 - val_accuracy: 0.3222 - val_precision: 0.4325 - val_recall: 0.1672\n","Epoch 127/10000\n","185/185 [==============================] - 17s 92ms/step - loss: 1.7978 - accuracy: 0.3901 - precision: 0.5546 - recall: 0.1347 - val_loss: 2.0792 - val_accuracy: 0.3404 - val_precision: 0.4586 - val_recall: 0.1459\n","Epoch 128/10000\n","185/185 [==============================] - 19s 101ms/step - loss: 1.7865 - accuracy: 0.3979 - precision: 0.5740 - recall: 0.1480 - val_loss: 2.0909 - val_accuracy: 0.3536 - val_precision: 0.4391 - val_recall: 0.1697\n","Epoch 129/10000\n","185/185 [==============================] - 17s 94ms/step - loss: 1.7866 - accuracy: 0.3854 - precision: 0.5655 - recall: 0.1451 - val_loss: 2.1133 - val_accuracy: 0.3364 - val_precision: 0.4637 - val_recall: 0.1717\n","Epoch 130/10000\n","185/185 [==============================] - 17s 93ms/step - loss: 1.7840 - accuracy: 0.3948 - precision: 0.5833 - recall: 0.1414 - val_loss: 2.1336 - val_accuracy: 0.3303 - val_precision: 0.4322 - val_recall: 0.1743\n","Epoch 131/10000\n","185/185 [==============================] - 17s 93ms/step - loss: 1.7927 - accuracy: 0.3882 - precision: 0.5744 - recall: 0.1480 - val_loss: 2.0716 - val_accuracy: 0.3343 - val_precision: 0.4593 - val_recall: 0.1570\n","Epoch 132/10000\n","185/185 [==============================] - 18s 98ms/step - loss: 1.7846 - accuracy: 0.3874 - precision: 0.5845 - recall: 0.1466 - val_loss: 2.1630 - val_accuracy: 0.3121 - val_precision: 0.4279 - val_recall: 0.1788\n","Epoch 133/10000\n","185/185 [==============================] - 17s 94ms/step - loss: 1.7843 - accuracy: 0.3920 - precision: 0.5701 - recall: 0.1429 - val_loss: 2.0667 - val_accuracy: 0.3440 - val_precision: 0.4468 - val_recall: 0.1575\n","Epoch 134/10000\n","185/185 [==============================] - 17s 94ms/step - loss: 1.7729 - accuracy: 0.3916 - precision: 0.5744 - recall: 0.1526 - val_loss: 2.1083 - val_accuracy: 0.3389 - val_precision: 0.4558 - val_recall: 0.1697\n","Epoch 135/10000\n","185/185 [==============================] - 17s 94ms/step - loss: 1.7810 - accuracy: 0.3925 - precision: 0.5845 - recall: 0.1502 - val_loss: 2.1174 - val_accuracy: 0.3308 - val_precision: 0.4595 - val_recall: 0.1753\n","Epoch 136/10000\n","185/185 [==============================] - 19s 103ms/step - loss: 1.7766 - accuracy: 0.3992 - precision: 0.5768 - recall: 0.1439 - val_loss: 2.1467 - val_accuracy: 0.3425 - val_precision: 0.4549 - val_recall: 0.1738\n","Epoch 137/10000\n","185/185 [==============================] - 18s 100ms/step - loss: 1.7692 - accuracy: 0.3969 - precision: 0.5799 - recall: 0.1465 - val_loss: 2.1012 - val_accuracy: 0.3369 - val_precision: 0.4247 - val_recall: 0.1657\n","Epoch 138/10000\n","185/185 [==============================] - 17s 93ms/step - loss: 1.7712 - accuracy: 0.3953 - precision: 0.5738 - recall: 0.1510 - val_loss: 2.0756 - val_accuracy: 0.3303 - val_precision: 0.4738 - val_recall: 0.1560\n","Epoch 139/10000\n","185/185 [==============================] - 17s 93ms/step - loss: 1.7690 - accuracy: 0.3948 - precision: 0.5920 - recall: 0.1559 - val_loss: 2.0796 - val_accuracy: 0.3445 - val_precision: 0.4623 - val_recall: 0.1677\n","Epoch 140/10000\n","185/185 [==============================] - 17s 92ms/step - loss: 1.7631 - accuracy: 0.3989 - precision: 0.5616 - recall: 0.1509 - val_loss: 2.0810 - val_accuracy: 0.3637 - val_precision: 0.4733 - val_recall: 0.1707\n","Epoch 141/10000\n","185/185 [==============================] - 19s 100ms/step - loss: 1.7732 - accuracy: 0.4021 - precision: 0.5806 - recall: 0.1564 - val_loss: 2.0889 - val_accuracy: 0.3516 - val_precision: 0.4743 - val_recall: 0.1636\n","Epoch 142/10000\n","185/185 [==============================] - 17s 93ms/step - loss: 1.7540 - accuracy: 0.3938 - precision: 0.5914 - recall: 0.1602 - val_loss: 2.1909 - val_accuracy: 0.3227 - val_precision: 0.3963 - val_recall: 0.1743\n","Epoch 143/10000\n","185/185 [==============================] - 17s 94ms/step - loss: 1.7540 - accuracy: 0.3997 - precision: 0.5692 - recall: 0.1522 - val_loss: 2.1511 - val_accuracy: 0.3343 - val_precision: 0.4550 - val_recall: 0.1717\n","Epoch 144/10000\n","185/185 [==============================] - 17s 94ms/step - loss: 1.7502 - accuracy: 0.4004 - precision: 0.5858 - recall: 0.1608 - val_loss: 2.1542 - val_accuracy: 0.3374 - val_precision: 0.4318 - val_recall: 0.1667\n","Epoch 145/10000\n","185/185 [==============================] - 19s 101ms/step - loss: 1.7556 - accuracy: 0.4040 - precision: 0.5787 - recall: 0.1622 - val_loss: 2.1337 - val_accuracy: 0.3354 - val_precision: 0.4493 - val_recall: 0.1505\n","Epoch 146/10000\n","185/185 [==============================] - 19s 102ms/step - loss: 1.7445 - accuracy: 0.3991 - precision: 0.5682 - recall: 0.1521 - val_loss: 2.1162 - val_accuracy: 0.3384 - val_precision: 0.4621 - val_recall: 0.1758\n","Epoch 147/10000\n","185/185 [==============================] - 17s 93ms/step - loss: 1.7495 - accuracy: 0.4016 - precision: 0.5894 - recall: 0.1627 - val_loss: 2.0985 - val_accuracy: 0.3399 - val_precision: 0.4533 - val_recall: 0.1646\n","Epoch 148/10000\n","185/185 [==============================] - 17s 94ms/step - loss: 1.7625 - accuracy: 0.3987 - precision: 0.5716 - recall: 0.1537 - val_loss: 2.0830 - val_accuracy: 0.3480 - val_precision: 0.4584 - val_recall: 0.1758\n","Epoch 149/10000\n","185/185 [==============================] - 18s 100ms/step - loss: 1.7557 - accuracy: 0.3999 - precision: 0.5755 - recall: 0.1629 - val_loss: 2.0505 - val_accuracy: 0.3460 - val_precision: 0.4718 - val_recall: 0.1525\n","Epoch 150/10000\n","185/185 [==============================] - 18s 96ms/step - loss: 1.7372 - accuracy: 0.4063 - precision: 0.5876 - recall: 0.1649 - val_loss: 2.1495 - val_accuracy: 0.3262 - val_precision: 0.4453 - val_recall: 0.1692\n","Epoch 151/10000\n","185/185 [==============================] - 17s 92ms/step - loss: 1.7448 - accuracy: 0.4021 - precision: 0.5911 - recall: 0.1688 - val_loss: 2.0932 - val_accuracy: 0.3369 - val_precision: 0.4559 - val_recall: 0.1727\n","Epoch 152/10000\n","185/185 [==============================] - 17s 93ms/step - loss: 1.7307 - accuracy: 0.4060 - precision: 0.5847 - recall: 0.1656 - val_loss: 2.1631 - val_accuracy: 0.3283 - val_precision: 0.4186 - val_recall: 0.1575\n","Epoch 153/10000\n","185/185 [==============================] - 19s 103ms/step - loss: 1.7291 - accuracy: 0.4168 - precision: 0.5714 - recall: 0.1622 - val_loss: 2.2087 - val_accuracy: 0.3191 - val_precision: 0.3825 - val_recall: 0.1616\n","Epoch 154/10000\n","185/185 [==============================] - 18s 95ms/step - loss: 1.7290 - accuracy: 0.4094 - precision: 0.5862 - recall: 0.1671 - val_loss: 2.1778 - val_accuracy: 0.3237 - val_precision: 0.4388 - val_recall: 0.1707\n","Epoch 155/10000\n","185/185 [==============================] - 17s 94ms/step - loss: 1.7065 - accuracy: 0.4170 - precision: 0.6067 - recall: 0.1801 - val_loss: 2.1296 - val_accuracy: 0.3379 - val_precision: 0.4336 - val_recall: 0.1753\n","Epoch 156/10000\n","185/185 [==============================] - 17s 94ms/step - loss: 1.7114 - accuracy: 0.4132 - precision: 0.5845 - recall: 0.1759 - val_loss: 2.1474 - val_accuracy: 0.3364 - val_precision: 0.4163 - val_recall: 0.1763\n","Epoch 157/10000\n","185/185 [==============================] - 20s 108ms/step - loss: 1.7067 - accuracy: 0.4190 - precision: 0.5924 - recall: 0.1787 - val_loss: 2.1447 - val_accuracy: 0.3404 - val_precision: 0.4406 - val_recall: 0.1672\n","Epoch 158/10000\n","185/185 [==============================] - 17s 93ms/step - loss: 1.6994 - accuracy: 0.4212 - precision: 0.5942 - recall: 0.1769 - val_loss: 2.1318 - val_accuracy: 0.3409 - val_precision: 0.4339 - val_recall: 0.1712\n","Epoch 159/10000\n","185/185 [==============================] - 17s 93ms/step - loss: 1.7175 - accuracy: 0.4073 - precision: 0.5771 - recall: 0.1745 - val_loss: 2.1393 - val_accuracy: 0.3435 - val_precision: 0.4565 - val_recall: 0.1702\n","Epoch 160/10000\n","185/185 [==============================] - 17s 94ms/step - loss: 1.7042 - accuracy: 0.4158 - precision: 0.5997 - recall: 0.1814 - val_loss: 2.1566 - val_accuracy: 0.3369 - val_precision: 0.4402 - val_recall: 0.1753\n","Epoch 161/10000\n","185/185 [==============================] - 19s 101ms/step - loss: 1.7023 - accuracy: 0.4205 - precision: 0.6137 - recall: 0.1842 - val_loss: 2.1216 - val_accuracy: 0.3480 - val_precision: 0.4436 - val_recall: 0.1712\n","Epoch 162/10000\n","185/185 [==============================] - 17s 94ms/step - loss: 1.7215 - accuracy: 0.4134 - precision: 0.5955 - recall: 0.1801 - val_loss: 2.1301 - val_accuracy: 0.3298 - val_precision: 0.4364 - val_recall: 0.1581\n","Epoch 163/10000\n","185/185 [==============================] - 18s 96ms/step - loss: 1.7092 - accuracy: 0.4104 - precision: 0.5927 - recall: 0.1777 - val_loss: 2.1580 - val_accuracy: 0.3364 - val_precision: 0.4143 - val_recall: 0.1727\n","Epoch 164/10000\n","185/185 [==============================] - 18s 95ms/step - loss: 1.6871 - accuracy: 0.4281 - precision: 0.6047 - recall: 0.1923 - val_loss: 2.1325 - val_accuracy: 0.3338 - val_precision: 0.4301 - val_recall: 0.1651\n","Epoch 165/10000\n","185/185 [==============================] - 19s 102ms/step - loss: 1.7012 - accuracy: 0.4136 - precision: 0.6108 - recall: 0.1928 - val_loss: 2.1191 - val_accuracy: 0.3506 - val_precision: 0.4580 - val_recall: 0.1824\n","Epoch 166/10000\n","185/185 [==============================] - 18s 95ms/step - loss: 1.7107 - accuracy: 0.4187 - precision: 0.5988 - recall: 0.1869 - val_loss: 2.1674 - val_accuracy: 0.3445 - val_precision: 0.4249 - val_recall: 0.1763\n","Epoch 167/10000\n","185/185 [==============================] - 18s 97ms/step - loss: 1.7013 - accuracy: 0.4170 - precision: 0.6162 - recall: 0.1850 - val_loss: 2.1043 - val_accuracy: 0.3399 - val_precision: 0.4502 - val_recall: 0.1672\n","Epoch 168/10000\n","185/185 [==============================] - 19s 103ms/step - loss: 1.6799 - accuracy: 0.4357 - precision: 0.6107 - recall: 0.1967 - val_loss: 2.1114 - val_accuracy: 0.3364 - val_precision: 0.4411 - val_recall: 0.1707\n","Epoch 169/10000\n","185/185 [==============================] - 18s 98ms/step - loss: 1.7003 - accuracy: 0.4193 - precision: 0.5833 - recall: 0.1816 - val_loss: 2.1532 - val_accuracy: 0.3318 - val_precision: 0.4320 - val_recall: 0.1803\n","Epoch 170/10000\n","185/185 [==============================] - 18s 97ms/step - loss: 1.6813 - accuracy: 0.4264 - precision: 0.6034 - recall: 0.1928 - val_loss: 2.1277 - val_accuracy: 0.3531 - val_precision: 0.4406 - val_recall: 0.1915\n","Epoch 171/10000\n","185/185 [==============================] - 18s 96ms/step - loss: 1.6833 - accuracy: 0.4214 - precision: 0.6012 - recall: 0.1902 - val_loss: 2.2352 - val_accuracy: 0.3278 - val_precision: 0.4408 - val_recall: 0.1981\n","Epoch 172/10000\n","185/185 [==============================] - 19s 102ms/step - loss: 1.6854 - accuracy: 0.4187 - precision: 0.6153 - recall: 0.1978 - val_loss: 2.1232 - val_accuracy: 0.3425 - val_precision: 0.4476 - val_recall: 0.1753\n","Epoch 173/10000\n","185/185 [==============================] - 18s 97ms/step - loss: 1.6755 - accuracy: 0.4273 - precision: 0.6101 - recall: 0.1933 - val_loss: 2.2241 - val_accuracy: 0.3197 - val_precision: 0.4249 - val_recall: 0.1819\n","Epoch 174/10000\n","185/185 [==============================] - 18s 95ms/step - loss: 1.6802 - accuracy: 0.4210 - precision: 0.6136 - recall: 0.2007 - val_loss: 2.2342 - val_accuracy: 0.3126 - val_precision: 0.4200 - val_recall: 0.1955\n","Epoch 175/10000\n","185/185 [==============================] - 18s 96ms/step - loss: 1.6694 - accuracy: 0.4246 - precision: 0.6058 - recall: 0.1968 - val_loss: 2.1654 - val_accuracy: 0.3354 - val_precision: 0.4126 - val_recall: 0.1662\n","Epoch 176/10000\n","185/185 [==============================] - 19s 104ms/step - loss: 1.6797 - accuracy: 0.4315 - precision: 0.6020 - recall: 0.1975 - val_loss: 2.1760 - val_accuracy: 0.3430 - val_precision: 0.4400 - val_recall: 0.1819\n","Epoch 177/10000\n","185/185 [==============================] - 18s 97ms/step - loss: 1.6600 - accuracy: 0.4256 - precision: 0.6150 - recall: 0.1978 - val_loss: 2.1802 - val_accuracy: 0.3338 - val_precision: 0.4373 - val_recall: 0.1677\n","Epoch 178/10000\n","185/185 [==============================] - 19s 102ms/step - loss: 1.6644 - accuracy: 0.4313 - precision: 0.6015 - recall: 0.2002 - val_loss: 2.1645 - val_accuracy: 0.3440 - val_precision: 0.4511 - val_recall: 0.1798\n","Epoch 179/10000\n","185/185 [==============================] - 18s 98ms/step - loss: 1.6646 - accuracy: 0.4334 - precision: 0.6148 - recall: 0.2004 - val_loss: 2.1852 - val_accuracy: 0.3257 - val_precision: 0.4188 - val_recall: 0.1829\n","Epoch 180/10000\n","185/185 [==============================] - 19s 101ms/step - loss: 1.6527 - accuracy: 0.4345 - precision: 0.6244 - recall: 0.2120 - val_loss: 2.1955 - val_accuracy: 0.3247 - val_precision: 0.4366 - val_recall: 0.1606\n","Epoch 181/10000\n","185/185 [==============================] - 18s 99ms/step - loss: 1.6659 - accuracy: 0.4320 - precision: 0.5995 - recall: 0.2041 - val_loss: 2.1586 - val_accuracy: 0.3267 - val_precision: 0.4173 - val_recall: 0.1662\n","Epoch 182/10000\n","185/185 [==============================] - 18s 96ms/step - loss: 1.6536 - accuracy: 0.4340 - precision: 0.6018 - recall: 0.1968 - val_loss: 2.2007 - val_accuracy: 0.3308 - val_precision: 0.4122 - val_recall: 0.1819\n","Epoch 183/10000\n","185/185 [==============================] - 19s 102ms/step - loss: 1.6338 - accuracy: 0.4398 - precision: 0.6373 - recall: 0.2212 - val_loss: 2.2396 - val_accuracy: 0.3237 - val_precision: 0.4044 - val_recall: 0.1940\n","Epoch 184/10000\n","185/185 [==============================] - 18s 99ms/step - loss: 1.6519 - accuracy: 0.4318 - precision: 0.6063 - recall: 0.2048 - val_loss: 2.1425 - val_accuracy: 0.3435 - val_precision: 0.4528 - val_recall: 0.1798\n","Epoch 185/10000\n","185/185 [==============================] - 18s 96ms/step - loss: 1.6568 - accuracy: 0.4352 - precision: 0.6125 - recall: 0.2107 - val_loss: 2.1634 - val_accuracy: 0.3521 - val_precision: 0.4422 - val_recall: 0.1900\n","Epoch 186/10000\n","185/185 [==============================] - 18s 98ms/step - loss: 1.6546 - accuracy: 0.4313 - precision: 0.6187 - recall: 0.2100 - val_loss: 2.2043 - val_accuracy: 0.3389 - val_precision: 0.4347 - val_recall: 0.1905\n","Epoch 187/10000\n","185/185 [==============================] - 19s 104ms/step - loss: 1.6556 - accuracy: 0.4325 - precision: 0.6069 - recall: 0.2024 - val_loss: 2.2558 - val_accuracy: 0.3166 - val_precision: 0.4216 - val_recall: 0.1895\n","Epoch 188/10000\n","185/185 [==============================] - 19s 105ms/step - loss: 1.6400 - accuracy: 0.4413 - precision: 0.6304 - recall: 0.2184 - val_loss: 2.2257 - val_accuracy: 0.3116 - val_precision: 0.4243 - val_recall: 0.1788\n","Epoch 189/10000\n","185/185 [==============================] - 18s 97ms/step - loss: 1.6522 - accuracy: 0.4381 - precision: 0.6166 - recall: 0.2054 - val_loss: 2.1538 - val_accuracy: 0.3435 - val_precision: 0.4503 - val_recall: 0.1814\n","Epoch 190/10000\n","185/185 [==============================] - 18s 100ms/step - loss: 1.6378 - accuracy: 0.4384 - precision: 0.6155 - recall: 0.2152 - val_loss: 2.2015 - val_accuracy: 0.3303 - val_precision: 0.4344 - val_recall: 0.1793\n","Epoch 191/10000\n","185/185 [==============================] - 18s 97ms/step - loss: 1.6346 - accuracy: 0.4325 - precision: 0.6144 - recall: 0.2124 - val_loss: 2.1674 - val_accuracy: 0.3374 - val_precision: 0.4240 - val_recall: 0.1682\n","Epoch 192/10000\n","185/185 [==============================] - 17s 94ms/step - loss: 1.6284 - accuracy: 0.4489 - precision: 0.6216 - recall: 0.2193 - val_loss: 2.1927 - val_accuracy: 0.3308 - val_precision: 0.4187 - val_recall: 0.1773\n","Epoch 193/10000\n","185/185 [==============================] - 18s 95ms/step - loss: 1.6302 - accuracy: 0.4367 - precision: 0.6016 - recall: 0.2100 - val_loss: 2.1804 - val_accuracy: 0.3369 - val_precision: 0.4365 - val_recall: 0.1950\n","Epoch 194/10000\n","185/185 [==============================] - 19s 101ms/step - loss: 1.6223 - accuracy: 0.4496 - precision: 0.6282 - recall: 0.2310 - val_loss: 2.2081 - val_accuracy: 0.3303 - val_precision: 0.4318 - val_recall: 0.2036\n","Epoch 195/10000\n","185/185 [==============================] - 18s 97ms/step - loss: 1.6158 - accuracy: 0.4467 - precision: 0.6231 - recall: 0.2232 - val_loss: 2.2625 - val_accuracy: 0.3247 - val_precision: 0.4187 - val_recall: 0.1879\n","Epoch 196/10000\n","185/185 [==============================] - 18s 96ms/step - loss: 1.6290 - accuracy: 0.4393 - precision: 0.6298 - recall: 0.2282 - val_loss: 2.2197 - val_accuracy: 0.3267 - val_precision: 0.4302 - val_recall: 0.1890\n","Epoch 197/10000\n","185/185 [==============================] - 18s 95ms/step - loss: 1.6192 - accuracy: 0.4509 - precision: 0.6306 - recall: 0.2264 - val_loss: 2.2449 - val_accuracy: 0.3323 - val_precision: 0.4210 - val_recall: 0.1971\n","Epoch 198/10000\n","185/185 [==============================] - 20s 109ms/step - loss: 1.6171 - accuracy: 0.4408 - precision: 0.6173 - recall: 0.2272 - val_loss: 2.2490 - val_accuracy: 0.3085 - val_precision: 0.4286 - val_recall: 0.1824\n","Epoch 199/10000\n","185/185 [==============================] - 18s 96ms/step - loss: 1.6074 - accuracy: 0.4570 - precision: 0.6343 - recall: 0.2306 - val_loss: 2.1849 - val_accuracy: 0.3369 - val_precision: 0.4284 - val_recall: 0.1834\n","Epoch 200/10000\n","185/185 [==============================] - 17s 95ms/step - loss: 1.5952 - accuracy: 0.4611 - precision: 0.6394 - recall: 0.2379 - val_loss: 2.1830 - val_accuracy: 0.3338 - val_precision: 0.4337 - val_recall: 0.1940\n","Epoch 201/10000\n","185/185 [==============================] - 18s 95ms/step - loss: 1.6057 - accuracy: 0.4492 - precision: 0.6240 - recall: 0.2402 - val_loss: 2.1602 - val_accuracy: 0.3333 - val_precision: 0.4387 - val_recall: 0.1793\n","Epoch 202/10000\n","185/185 [==============================] - 19s 101ms/step - loss: 1.6066 - accuracy: 0.4575 - precision: 0.6276 - recall: 0.2310 - val_loss: 2.2837 - val_accuracy: 0.3136 - val_precision: 0.3792 - val_recall: 0.1758\n","Epoch 203/10000\n","185/185 [==============================] - 18s 97ms/step - loss: 1.5904 - accuracy: 0.4589 - precision: 0.6408 - recall: 0.2468 - val_loss: 2.1941 - val_accuracy: 0.3455 - val_precision: 0.4201 - val_recall: 0.1824\n","Epoch 204/10000\n","185/185 [==============================] - 18s 95ms/step - loss: 1.6085 - accuracy: 0.4479 - precision: 0.6274 - recall: 0.2296 - val_loss: 2.2201 - val_accuracy: 0.3121 - val_precision: 0.4357 - val_recall: 0.1991\n","Epoch 205/10000\n","185/185 [==============================] - 17s 94ms/step - loss: 1.5982 - accuracy: 0.4472 - precision: 0.6252 - recall: 0.2291 - val_loss: 2.2853 - val_accuracy: 0.3181 - val_precision: 0.4065 - val_recall: 0.1950\n","Epoch 206/10000\n","185/185 [==============================] - 19s 103ms/step - loss: 1.5766 - accuracy: 0.4543 - precision: 0.6491 - recall: 0.2500 - val_loss: 2.2567 - val_accuracy: 0.3242 - val_precision: 0.4100 - val_recall: 0.1707\n","Epoch 207/10000\n","185/185 [==============================] - 18s 96ms/step - loss: 1.5920 - accuracy: 0.4609 - precision: 0.6359 - recall: 0.2419 - val_loss: 2.2387 - val_accuracy: 0.3262 - val_precision: 0.4246 - val_recall: 0.1798\n","Epoch 208/10000\n","185/185 [==============================] - 17s 94ms/step - loss: 1.5897 - accuracy: 0.4604 - precision: 0.6436 - recall: 0.2419 - val_loss: 2.2052 - val_accuracy: 0.3480 - val_precision: 0.4368 - val_recall: 0.1925\n","Epoch 209/10000\n","185/185 [==============================] - 19s 102ms/step - loss: 1.5871 - accuracy: 0.4578 - precision: 0.6329 - recall: 0.2429 - val_loss: 2.2496 - val_accuracy: 0.3293 - val_precision: 0.4216 - val_recall: 0.2016\n","Epoch 210/10000\n","185/185 [==============================] - 19s 103ms/step - loss: 1.5867 - accuracy: 0.4563 - precision: 0.6383 - recall: 0.2424 - val_loss: 2.2339 - val_accuracy: 0.3349 - val_precision: 0.4327 - val_recall: 0.1905\n","Epoch 211/10000\n","185/185 [==============================] - 17s 94ms/step - loss: 1.5886 - accuracy: 0.4513 - precision: 0.6262 - recall: 0.2423 - val_loss: 2.1395 - val_accuracy: 0.3425 - val_precision: 0.4494 - val_recall: 0.1844\n","Epoch 212/10000\n","185/185 [==============================] - 18s 95ms/step - loss: 1.5880 - accuracy: 0.4597 - precision: 0.6287 - recall: 0.2443 - val_loss: 2.2371 - val_accuracy: 0.3343 - val_precision: 0.4324 - val_recall: 0.1945\n","Epoch 213/10000\n","185/185 [==============================] - 18s 96ms/step - loss: 1.5753 - accuracy: 0.4584 - precision: 0.6363 - recall: 0.2468 - val_loss: 2.1829 - val_accuracy: 0.3490 - val_precision: 0.4409 - val_recall: 0.1869\n","Epoch 214/10000\n","185/185 [==============================] - 19s 103ms/step - loss: 1.5770 - accuracy: 0.4655 - precision: 0.6472 - recall: 0.2455 - val_loss: 2.1682 - val_accuracy: 0.3425 - val_precision: 0.4392 - val_recall: 0.1758\n","Epoch 215/10000\n","185/185 [==============================] - 18s 95ms/step - loss: 1.5557 - accuracy: 0.4602 - precision: 0.6493 - recall: 0.2527 - val_loss: 2.2953 - val_accuracy: 0.3318 - val_precision: 0.4181 - val_recall: 0.2016\n","Epoch 216/10000\n","185/185 [==============================] - 18s 95ms/step - loss: 1.5773 - accuracy: 0.4676 - precision: 0.6297 - recall: 0.2482 - val_loss: 2.3119 - val_accuracy: 0.3181 - val_precision: 0.3608 - val_recall: 0.1773\n","Epoch 217/10000\n","185/185 [==============================] - 18s 95ms/step - loss: 1.5614 - accuracy: 0.4622 - precision: 0.6346 - recall: 0.2465 - val_loss: 2.3336 - val_accuracy: 0.3176 - val_precision: 0.4074 - val_recall: 0.2052\n","Epoch 218/10000\n","185/185 [==============================] - 19s 103ms/step - loss: 1.5667 - accuracy: 0.4599 - precision: 0.6377 - recall: 0.2531 - val_loss: 2.2333 - val_accuracy: 0.3349 - val_precision: 0.4086 - val_recall: 0.1925\n","Epoch 219/10000\n","185/185 [==============================] - 19s 103ms/step - loss: 1.5631 - accuracy: 0.4687 - precision: 0.6328 - recall: 0.2484 - val_loss: 2.2309 - val_accuracy: 0.3394 - val_precision: 0.4217 - val_recall: 0.2047\n","Epoch 220/10000\n","185/185 [==============================] - 18s 95ms/step - loss: 1.5779 - accuracy: 0.4599 - precision: 0.6445 - recall: 0.2505 - val_loss: 2.2928 - val_accuracy: 0.3323 - val_precision: 0.3980 - val_recall: 0.2026\n","Epoch 221/10000\n","185/185 [==============================] - 18s 97ms/step - loss: 1.5434 - accuracy: 0.4702 - precision: 0.6385 - recall: 0.2593 - val_loss: 2.3981 - val_accuracy: 0.3034 - val_precision: 0.3622 - val_recall: 0.1910\n","Epoch 222/10000\n","185/185 [==============================] - 19s 103ms/step - loss: 1.5646 - accuracy: 0.4633 - precision: 0.6287 - recall: 0.2500 - val_loss: 2.2711 - val_accuracy: 0.3161 - val_precision: 0.4233 - val_recall: 0.1971\n","Epoch 223/10000\n","185/185 [==============================] - 18s 96ms/step - loss: 1.5554 - accuracy: 0.4653 - precision: 0.6502 - recall: 0.2619 - val_loss: 2.2587 - val_accuracy: 0.3267 - val_precision: 0.3970 - val_recall: 0.1864\n","Epoch 224/10000\n","185/185 [==============================] - 18s 97ms/step - loss: 1.5728 - accuracy: 0.4614 - precision: 0.6361 - recall: 0.2516 - val_loss: 2.3209 - val_accuracy: 0.3090 - val_precision: 0.4032 - val_recall: 0.2057\n","Epoch 225/10000\n","185/185 [==============================] - 17s 95ms/step - loss: 1.5452 - accuracy: 0.4688 - precision: 0.6488 - recall: 0.2619 - val_loss: 2.3467 - val_accuracy: 0.3100 - val_precision: 0.3901 - val_recall: 0.1869\n","Epoch 226/10000\n","185/185 [==============================] - 19s 102ms/step - loss: 1.5434 - accuracy: 0.4710 - precision: 0.6482 - recall: 0.2593 - val_loss: 2.2530 - val_accuracy: 0.3343 - val_precision: 0.4193 - val_recall: 0.1895\n","Epoch 227/10000\n","185/185 [==============================] - 18s 96ms/step - loss: 1.5585 - accuracy: 0.4597 - precision: 0.6322 - recall: 0.2553 - val_loss: 2.2337 - val_accuracy: 0.3212 - val_precision: 0.4108 - val_recall: 0.1773\n","Epoch 228/10000\n","185/185 [==============================] - 18s 96ms/step - loss: 1.5449 - accuracy: 0.4702 - precision: 0.6390 - recall: 0.2548 - val_loss: 2.2255 - val_accuracy: 0.3349 - val_precision: 0.4239 - val_recall: 0.1905\n","Epoch 229/10000\n","185/185 [==============================] - 20s 108ms/step - loss: 1.5249 - accuracy: 0.4756 - precision: 0.6448 - recall: 0.2668 - val_loss: 2.2423 - val_accuracy: 0.3278 - val_precision: 0.4451 - val_recall: 0.1930\n","Epoch 230/10000\n","185/185 [==============================] - 18s 98ms/step - loss: 1.5235 - accuracy: 0.4749 - precision: 0.6374 - recall: 0.2708 - val_loss: 2.2798 - val_accuracy: 0.3273 - val_precision: 0.4076 - val_recall: 0.1945\n","Epoch 231/10000\n","185/185 [==============================] - 18s 96ms/step - loss: 1.5293 - accuracy: 0.4800 - precision: 0.6527 - recall: 0.2701 - val_loss: 2.2823 - val_accuracy: 0.3379 - val_precision: 0.4167 - val_recall: 0.1900\n","Epoch 232/10000\n","185/185 [==============================] - 18s 97ms/step - loss: 1.5153 - accuracy: 0.4790 - precision: 0.6462 - recall: 0.2737 - val_loss: 2.2411 - val_accuracy: 0.3232 - val_precision: 0.4341 - val_recall: 0.1869\n","Epoch 233/10000\n","185/185 [==============================] - 19s 103ms/step - loss: 1.5371 - accuracy: 0.4682 - precision: 0.6320 - recall: 0.2632 - val_loss: 2.2543 - val_accuracy: 0.3359 - val_precision: 0.4284 - val_recall: 0.1925\n","Epoch 234/10000\n","185/185 [==============================] - 18s 97ms/step - loss: 1.5210 - accuracy: 0.4854 - precision: 0.6543 - recall: 0.2744 - val_loss: 2.2734 - val_accuracy: 0.3186 - val_precision: 0.4097 - val_recall: 0.2057\n","Epoch 235/10000\n","185/185 [==============================] - 18s 97ms/step - loss: 1.5372 - accuracy: 0.4751 - precision: 0.6447 - recall: 0.2744 - val_loss: 2.2159 - val_accuracy: 0.3384 - val_precision: 0.4480 - val_recall: 0.1940\n","Epoch 236/10000\n","185/185 [==============================] - 18s 99ms/step - loss: 1.5142 - accuracy: 0.4832 - precision: 0.6536 - recall: 0.2761 - val_loss: 2.3437 - val_accuracy: 0.3121 - val_precision: 0.3948 - val_recall: 0.2006\n","Epoch 237/10000\n","185/185 [==============================] - 19s 105ms/step - loss: 1.5000 - accuracy: 0.4856 - precision: 0.6570 - recall: 0.2860 - val_loss: 2.3156 - val_accuracy: 0.3278 - val_precision: 0.3952 - val_recall: 0.1986\n","Epoch 238/10000\n","185/185 [==============================] - 18s 97ms/step - loss: 1.5186 - accuracy: 0.4746 - precision: 0.6507 - recall: 0.2747 - val_loss: 2.2910 - val_accuracy: 0.3222 - val_precision: 0.4123 - val_recall: 0.1895\n","Epoch 239/10000\n","185/185 [==============================] - 18s 98ms/step - loss: 1.5056 - accuracy: 0.4761 - precision: 0.6419 - recall: 0.2740 - val_loss: 2.3110 - val_accuracy: 0.3207 - val_precision: 0.4131 - val_recall: 0.1950\n","Epoch 240/10000\n","185/185 [==============================] - 20s 106ms/step - loss: 1.5035 - accuracy: 0.4852 - precision: 0.6490 - recall: 0.2874 - val_loss: 2.2975 - val_accuracy: 0.3176 - val_precision: 0.4241 - val_recall: 0.1910\n","Epoch 241/10000\n","185/185 [==============================] - 19s 103ms/step - loss: 1.5162 - accuracy: 0.4763 - precision: 0.6429 - recall: 0.2801 - val_loss: 2.4164 - val_accuracy: 0.3171 - val_precision: 0.3860 - val_recall: 0.1955\n","Epoch 242/10000\n","185/185 [==============================] - 18s 97ms/step - loss: 1.5109 - accuracy: 0.4837 - precision: 0.6386 - recall: 0.2806 - val_loss: 2.3554 - val_accuracy: 0.3151 - val_precision: 0.3862 - val_recall: 0.1986\n","Epoch 243/10000\n","185/185 [==============================] - 18s 96ms/step - loss: 1.5219 - accuracy: 0.4788 - precision: 0.6454 - recall: 0.2752 - val_loss: 2.3523 - val_accuracy: 0.3105 - val_precision: 0.3879 - val_recall: 0.1884\n","Epoch 244/10000\n","185/185 [==============================] - 19s 101ms/step - loss: 1.4935 - accuracy: 0.4883 - precision: 0.6571 - recall: 0.2813 - val_loss: 2.2726 - val_accuracy: 0.3308 - val_precision: 0.4051 - val_recall: 0.2001\n","Epoch 245/10000\n","185/185 [==============================] - 18s 98ms/step - loss: 1.4920 - accuracy: 0.4803 - precision: 0.6643 - recall: 0.2865 - val_loss: 2.2711 - val_accuracy: 0.3313 - val_precision: 0.4225 - val_recall: 0.1920\n","Epoch 246/10000\n","185/185 [==============================] - 18s 96ms/step - loss: 1.4890 - accuracy: 0.4871 - precision: 0.6560 - recall: 0.2867 - val_loss: 2.2558 - val_accuracy: 0.3409 - val_precision: 0.4339 - val_recall: 0.1930\n","Epoch 247/10000\n","185/185 [==============================] - 18s 97ms/step - loss: 1.5016 - accuracy: 0.4908 - precision: 0.6579 - recall: 0.2908 - val_loss: 2.2808 - val_accuracy: 0.3176 - val_precision: 0.4225 - val_recall: 0.2057\n","Epoch 248/10000\n","185/185 [==============================] - 19s 105ms/step - loss: 1.5038 - accuracy: 0.4780 - precision: 0.6494 - recall: 0.2791 - val_loss: 2.2892 - val_accuracy: 0.3191 - val_precision: 0.4004 - val_recall: 0.1844\n","Epoch 249/10000\n","185/185 [==============================] - 18s 100ms/step - loss: 1.4748 - accuracy: 0.4849 - precision: 0.6612 - recall: 0.2918 - val_loss: 2.3522 - val_accuracy: 0.3146 - val_precision: 0.3905 - val_recall: 0.2006\n","Epoch 250/10000\n","185/185 [==============================] - 19s 105ms/step - loss: 1.4719 - accuracy: 0.4905 - precision: 0.6648 - recall: 0.2945 - val_loss: 2.2979 - val_accuracy: 0.3217 - val_precision: 0.4132 - val_recall: 0.2026\n","Epoch 251/10000\n","185/185 [==============================] - 18s 99ms/step - loss: 1.4801 - accuracy: 0.4864 - precision: 0.6587 - recall: 0.2921 - val_loss: 2.3808 - val_accuracy: 0.3040 - val_precision: 0.3785 - val_recall: 0.1798\n","Epoch 252/10000\n","185/185 [==============================] - 19s 102ms/step - loss: 1.4738 - accuracy: 0.4910 - precision: 0.6592 - recall: 0.2935 - val_loss: 2.2253 - val_accuracy: 0.3328 - val_precision: 0.4121 - val_recall: 0.1900\n","Epoch 253/10000\n","185/185 [==============================] - 18s 99ms/step - loss: 1.4699 - accuracy: 0.5016 - precision: 0.6669 - recall: 0.3048 - val_loss: 2.3364 - val_accuracy: 0.3328 - val_precision: 0.4154 - val_recall: 0.2128\n","Epoch 254/10000\n","185/185 [==============================] - 18s 98ms/step - loss: 1.4528 - accuracy: 0.5109 - precision: 0.6739 - recall: 0.3100 - val_loss: 2.5171 - val_accuracy: 0.3090 - val_precision: 0.3996 - val_recall: 0.1925\n","Epoch 255/10000\n","185/185 [==============================] - 19s 104ms/step - loss: 1.4787 - accuracy: 0.4899 - precision: 0.6718 - recall: 0.3033 - val_loss: 2.3234 - val_accuracy: 0.3191 - val_precision: 0.3987 - val_recall: 0.1874\n","Epoch 256/10000\n","185/185 [==============================] - 18s 97ms/step - loss: 1.4795 - accuracy: 0.4928 - precision: 0.6581 - recall: 0.2926 - val_loss: 2.3524 - val_accuracy: 0.3186 - val_precision: 0.4082 - val_recall: 0.1960\n","Epoch 257/10000\n","185/185 [==============================] - 18s 96ms/step - loss: 1.4582 - accuracy: 0.5085 - precision: 0.6743 - recall: 0.2980 - val_loss: 2.4415 - val_accuracy: 0.3227 - val_precision: 0.3732 - val_recall: 0.2006\n","Epoch 258/10000\n","185/185 [==============================] - 18s 97ms/step - loss: 1.4645 - accuracy: 0.4994 - precision: 0.6637 - recall: 0.3044 - val_loss: 2.3384 - val_accuracy: 0.3181 - val_precision: 0.4202 - val_recall: 0.2026\n","Epoch 259/10000\n","185/185 [==============================] - 20s 106ms/step - loss: 1.4430 - accuracy: 0.5014 - precision: 0.6680 - recall: 0.3077 - val_loss: 2.3678 - val_accuracy: 0.3055 - val_precision: 0.3921 - val_recall: 0.1915\n","Epoch 260/10000\n","185/185 [==============================] - 19s 103ms/step - loss: 1.4724 - accuracy: 0.4896 - precision: 0.6483 - recall: 0.2955 - val_loss: 2.3704 - val_accuracy: 0.3217 - val_precision: 0.3975 - val_recall: 0.2092\n","Epoch 261/10000\n","185/185 [==============================] - 18s 96ms/step - loss: 1.4569 - accuracy: 0.5040 - precision: 0.6686 - recall: 0.3085 - val_loss: 2.2545 - val_accuracy: 0.3501 - val_precision: 0.4110 - val_recall: 0.2082\n","Epoch 262/10000\n","185/185 [==============================] - 19s 102ms/step - loss: 1.4536 - accuracy: 0.4987 - precision: 0.6661 - recall: 0.3120 - val_loss: 2.3496 - val_accuracy: 0.3323 - val_precision: 0.4067 - val_recall: 0.2143\n","Epoch 263/10000\n","185/185 [==============================] - 18s 98ms/step - loss: 1.4453 - accuracy: 0.4994 - precision: 0.6605 - recall: 0.3073 - val_loss: 2.4383 - val_accuracy: 0.3075 - val_precision: 0.3793 - val_recall: 0.2021\n","Epoch 264/10000\n","185/185 [==============================] - 18s 96ms/step - loss: 1.4586 - accuracy: 0.4896 - precision: 0.6638 - recall: 0.3033 - val_loss: 2.3807 - val_accuracy: 0.3212 - val_precision: 0.4002 - val_recall: 0.2062\n","Epoch 265/10000\n","185/185 [==============================] - 18s 96ms/step - loss: 1.4443 - accuracy: 0.5085 - precision: 0.6776 - recall: 0.3181 - val_loss: 2.4233 - val_accuracy: 0.3176 - val_precision: 0.3720 - val_recall: 0.1996\n","Epoch 266/10000\n","185/185 [==============================] - 19s 104ms/step - loss: 1.4199 - accuracy: 0.5079 - precision: 0.6731 - recall: 0.3159 - val_loss: 2.3478 - val_accuracy: 0.3298 - val_precision: 0.4079 - val_recall: 0.2254\n","Epoch 267/10000\n","185/185 [==============================] - 18s 98ms/step - loss: 1.4450 - accuracy: 0.5117 - precision: 0.6625 - recall: 0.3144 - val_loss: 2.3885 - val_accuracy: 0.3202 - val_precision: 0.3982 - val_recall: 0.2072\n","Epoch 268/10000\n","185/185 [==============================] - 18s 98ms/step - loss: 1.4265 - accuracy: 0.5114 - precision: 0.6814 - recall: 0.3212 - val_loss: 2.3664 - val_accuracy: 0.3349 - val_precision: 0.4100 - val_recall: 0.2158\n","Epoch 269/10000\n","185/185 [==============================] - 18s 100ms/step - loss: 1.4434 - accuracy: 0.5045 - precision: 0.6578 - recall: 0.3166 - val_loss: 2.3424 - val_accuracy: 0.3293 - val_precision: 0.3967 - val_recall: 0.1935\n","Epoch 270/10000\n","185/185 [==============================] - 21s 111ms/step - loss: 1.4366 - accuracy: 0.5052 - precision: 0.6721 - recall: 0.3144 - val_loss: 2.3445 - val_accuracy: 0.3267 - val_precision: 0.4139 - val_recall: 0.1960\n","Epoch 271/10000\n","185/185 [==============================] - 18s 98ms/step - loss: 1.4444 - accuracy: 0.5006 - precision: 0.6637 - recall: 0.3137 - val_loss: 2.3644 - val_accuracy: 0.3303 - val_precision: 0.4056 - val_recall: 0.2143\n","Epoch 272/10000\n","185/185 [==============================] - 18s 97ms/step - loss: 1.4258 - accuracy: 0.5160 - precision: 0.6857 - recall: 0.3269 - val_loss: 2.3564 - val_accuracy: 0.3318 - val_precision: 0.3971 - val_recall: 0.2102\n","Epoch 273/10000\n","185/185 [==============================] - 19s 105ms/step - loss: 1.4499 - accuracy: 0.4997 - precision: 0.6493 - recall: 0.3097 - val_loss: 2.4097 - val_accuracy: 0.3212 - val_precision: 0.3968 - val_recall: 0.1910\n","Epoch 274/10000\n","185/185 [==============================] - 18s 98ms/step - loss: 1.4219 - accuracy: 0.5207 - precision: 0.6770 - recall: 0.3289 - val_loss: 2.3921 - val_accuracy: 0.3121 - val_precision: 0.3790 - val_recall: 0.2087\n","Epoch 275/10000\n","185/185 [==============================] - 18s 97ms/step - loss: 1.4337 - accuracy: 0.5075 - precision: 0.6572 - recall: 0.3132 - val_loss: 2.2863 - val_accuracy: 0.3303 - val_precision: 0.4098 - val_recall: 0.1991\n","Epoch 276/10000\n","185/185 [==============================] - 19s 105ms/step - loss: 1.4011 - accuracy: 0.5215 - precision: 0.6775 - recall: 0.3354 - val_loss: 2.3940 - val_accuracy: 0.3060 - val_precision: 0.3804 - val_recall: 0.1991\n","Epoch 277/10000\n","185/185 [==============================] - 18s 99ms/step - loss: 1.4016 - accuracy: 0.5180 - precision: 0.6733 - recall: 0.3273 - val_loss: 2.4244 - val_accuracy: 0.3095 - val_precision: 0.3841 - val_recall: 0.1981\n","Epoch 278/10000\n","185/185 [==============================] - 18s 97ms/step - loss: 1.4109 - accuracy: 0.5138 - precision: 0.6777 - recall: 0.3289 - val_loss: 2.4264 - val_accuracy: 0.3146 - val_precision: 0.4053 - val_recall: 0.2102\n","Epoch 279/10000\n","185/185 [==============================] - 18s 96ms/step - loss: 1.4180 - accuracy: 0.5143 - precision: 0.6669 - recall: 0.3271 - val_loss: 2.5458 - val_accuracy: 0.2928 - val_precision: 0.3486 - val_recall: 0.1890\n","Epoch 280/10000\n","185/185 [==============================] - 20s 110ms/step - loss: 1.4052 - accuracy: 0.5188 - precision: 0.6779 - recall: 0.3286 - val_loss: 2.3624 - val_accuracy: 0.3237 - val_precision: 0.4072 - val_recall: 0.2112\n","Epoch 281/10000\n","185/185 [==============================] - 18s 97ms/step - loss: 1.4203 - accuracy: 0.5068 - precision: 0.6586 - recall: 0.3245 - val_loss: 2.3399 - val_accuracy: 0.3288 - val_precision: 0.4179 - val_recall: 0.2102\n","Epoch 282/10000\n","185/185 [==============================] - 18s 97ms/step - loss: 1.4186 - accuracy: 0.5150 - precision: 0.6740 - recall: 0.3245 - val_loss: 2.3501 - val_accuracy: 0.3181 - val_precision: 0.3800 - val_recall: 0.2036\n","Epoch 283/10000\n","185/185 [==============================] - 19s 100ms/step - loss: 1.4021 - accuracy: 0.5136 - precision: 0.6742 - recall: 0.3296 - val_loss: 2.5348 - val_accuracy: 0.3040 - val_precision: 0.3651 - val_recall: 0.2112\n","Epoch 284/10000\n","185/185 [==============================] - 19s 101ms/step - loss: 1.3814 - accuracy: 0.5232 - precision: 0.6788 - recall: 0.3316 - val_loss: 2.4333 - val_accuracy: 0.3267 - val_precision: 0.3993 - val_recall: 0.2270\n","Epoch 285/10000\n","185/185 [==============================] - 18s 97ms/step - loss: 1.3944 - accuracy: 0.5236 - precision: 0.6632 - recall: 0.3367 - val_loss: 2.3651 - val_accuracy: 0.3227 - val_precision: 0.3976 - val_recall: 0.2163\n","Epoch 286/10000\n","185/185 [==============================] - 18s 97ms/step - loss: 1.4003 - accuracy: 0.5197 - precision: 0.6631 - recall: 0.3308 - val_loss: 2.3483 - val_accuracy: 0.3409 - val_precision: 0.4120 - val_recall: 0.2290\n","Epoch 287/10000\n","185/185 [==============================] - 18s 99ms/step - loss: 1.3771 - accuracy: 0.5298 - precision: 0.6832 - recall: 0.3468 - val_loss: 2.4368 - val_accuracy: 0.3247 - val_precision: 0.3910 - val_recall: 0.2107\n","Epoch 288/10000\n","185/185 [==============================] - 19s 101ms/step - loss: 1.3810 - accuracy: 0.5268 - precision: 0.6816 - recall: 0.3408 - val_loss: 2.3746 - val_accuracy: 0.3242 - val_precision: 0.3898 - val_recall: 0.1971\n","Epoch 289/10000\n","185/185 [==============================] - 18s 100ms/step - loss: 1.4021 - accuracy: 0.5160 - precision: 0.6708 - recall: 0.3347 - val_loss: 2.3708 - val_accuracy: 0.3110 - val_precision: 0.4002 - val_recall: 0.2072\n","Epoch 290/10000\n","185/185 [==============================] - 20s 106ms/step - loss: 1.3941 - accuracy: 0.5212 - precision: 0.6828 - recall: 0.3401 - val_loss: 2.4517 - val_accuracy: 0.3045 - val_precision: 0.3873 - val_recall: 0.2072\n","Epoch 291/10000\n","185/185 [==============================] - 19s 105ms/step - loss: 1.3744 - accuracy: 0.5340 - precision: 0.6842 - recall: 0.3441 - val_loss: 2.4326 - val_accuracy: 0.3303 - val_precision: 0.4013 - val_recall: 0.2194\n","Epoch 292/10000\n","185/185 [==============================] - 18s 97ms/step - loss: 1.3816 - accuracy: 0.5273 - precision: 0.6788 - recall: 0.3477 - val_loss: 2.5059 - val_accuracy: 0.3110 - val_precision: 0.3821 - val_recall: 0.2183\n","Epoch 293/10000\n","185/185 [==============================] - 18s 99ms/step - loss: 1.3772 - accuracy: 0.5241 - precision: 0.6769 - recall: 0.3430 - val_loss: 2.4966 - val_accuracy: 0.3034 - val_precision: 0.3717 - val_recall: 0.2077\n","Epoch 294/10000\n","185/185 [==============================] - 19s 101ms/step - loss: 1.3606 - accuracy: 0.5281 - precision: 0.6843 - recall: 0.3425 - val_loss: 2.4845 - val_accuracy: 0.3121 - val_precision: 0.4022 - val_recall: 0.2209\n","Epoch 295/10000\n","185/185 [==============================] - 19s 101ms/step - loss: 1.3898 - accuracy: 0.5219 - precision: 0.6802 - recall: 0.3489 - val_loss: 2.3967 - val_accuracy: 0.3171 - val_precision: 0.3703 - val_recall: 0.2062\n","Epoch 296/10000\n","185/185 [==============================] - 18s 97ms/step - loss: 1.3596 - accuracy: 0.5334 - precision: 0.6876 - recall: 0.3555 - val_loss: 2.4510 - val_accuracy: 0.3217 - val_precision: 0.3850 - val_recall: 0.2052\n","Epoch 297/10000\n","185/185 [==============================] - 18s 97ms/step - loss: 1.3476 - accuracy: 0.5373 - precision: 0.6923 - recall: 0.3592 - val_loss: 2.5192 - val_accuracy: 0.3095 - val_precision: 0.3728 - val_recall: 0.2295\n","Epoch 298/10000\n","185/185 [==============================] - 19s 104ms/step - loss: 1.3803 - accuracy: 0.5305 - precision: 0.6738 - recall: 0.3504 - val_loss: 2.4441 - val_accuracy: 0.3095 - val_precision: 0.3918 - val_recall: 0.2036\n","Epoch 299/10000\n","185/185 [==============================] - 18s 97ms/step - loss: 1.3740 - accuracy: 0.5263 - precision: 0.6795 - recall: 0.3479 - val_loss: 2.4240 - val_accuracy: 0.3161 - val_precision: 0.3867 - val_recall: 0.2128\n","Epoch 300/10000\n","185/185 [==============================] - 20s 106ms/step - loss: 1.3352 - accuracy: 0.5366 - precision: 0.6928 - recall: 0.3573 - val_loss: 2.4967 - val_accuracy: 0.3100 - val_precision: 0.3865 - val_recall: 0.2123\n","Epoch 301/10000\n","185/185 [==============================] - 18s 97ms/step - loss: 1.3449 - accuracy: 0.5373 - precision: 0.6814 - recall: 0.3595 - val_loss: 2.5750 - val_accuracy: 0.3070 - val_precision: 0.3575 - val_recall: 0.2249\n","Epoch 302/10000\n","185/185 [==============================] - 18s 98ms/step - loss: 1.3867 - accuracy: 0.5187 - precision: 0.6720 - recall: 0.3419 - val_loss: 2.4140 - val_accuracy: 0.3308 - val_precision: 0.3788 - val_recall: 0.2138\n","Epoch 303/10000\n","185/185 [==============================] - 19s 104ms/step - loss: 1.3487 - accuracy: 0.5325 - precision: 0.6855 - recall: 0.3599 - val_loss: 2.4632 - val_accuracy: 0.3116 - val_precision: 0.3925 - val_recall: 0.2107\n","Epoch 304/10000\n","185/185 [==============================] - 18s 97ms/step - loss: 1.3535 - accuracy: 0.5349 - precision: 0.6834 - recall: 0.3588 - val_loss: 2.4952 - val_accuracy: 0.3293 - val_precision: 0.3840 - val_recall: 0.2290\n","Epoch 305/10000\n","185/185 [==============================] - 18s 97ms/step - loss: 1.3369 - accuracy: 0.5430 - precision: 0.7017 - recall: 0.3664 - val_loss: 2.6408 - val_accuracy: 0.2958 - val_precision: 0.3383 - val_recall: 0.2072\n","Epoch 306/10000\n","185/185 [==============================] - 18s 98ms/step - loss: 1.3382 - accuracy: 0.5481 - precision: 0.7047 - recall: 0.3742 - val_loss: 2.5951 - val_accuracy: 0.3186 - val_precision: 0.3800 - val_recall: 0.2270\n","Epoch 307/10000\n","185/185 [==============================] - 19s 103ms/step - loss: 1.3427 - accuracy: 0.5320 - precision: 0.6932 - recall: 0.3658 - val_loss: 2.4898 - val_accuracy: 0.3247 - val_precision: 0.3922 - val_recall: 0.2305\n","Epoch 308/10000\n","185/185 [==============================] - 18s 97ms/step - loss: 1.3543 - accuracy: 0.5379 - precision: 0.6867 - recall: 0.3670 - val_loss: 2.6228 - val_accuracy: 0.3045 - val_precision: 0.3679 - val_recall: 0.2087\n","Epoch 309/10000\n","185/185 [==============================] - 18s 97ms/step - loss: 1.3354 - accuracy: 0.5383 - precision: 0.6827 - recall: 0.3639 - val_loss: 2.4480 - val_accuracy: 0.3100 - val_precision: 0.3937 - val_recall: 0.2168\n","Epoch 310/10000\n","185/185 [==============================] - 20s 111ms/step - loss: 1.3159 - accuracy: 0.5440 - precision: 0.6893 - recall: 0.3673 - val_loss: 2.4591 - val_accuracy: 0.3171 - val_precision: 0.3872 - val_recall: 0.2173\n","Epoch 311/10000\n","185/185 [==============================] - 18s 98ms/step - loss: 1.3257 - accuracy: 0.5383 - precision: 0.6927 - recall: 0.3705 - val_loss: 2.5245 - val_accuracy: 0.3136 - val_precision: 0.3862 - val_recall: 0.2209\n","Epoch 312/10000\n","185/185 [==============================] - 18s 97ms/step - loss: 1.3201 - accuracy: 0.5482 - precision: 0.6914 - recall: 0.3778 - val_loss: 2.4783 - val_accuracy: 0.3257 - val_precision: 0.3969 - val_recall: 0.2320\n","Epoch 313/10000\n","185/185 [==============================] - 18s 96ms/step - loss: 1.3262 - accuracy: 0.5389 - precision: 0.6896 - recall: 0.3637 - val_loss: 2.5270 - val_accuracy: 0.3146 - val_precision: 0.3957 - val_recall: 0.2249\n","Epoch 314/10000\n","185/185 [==============================] - 19s 104ms/step - loss: 1.3322 - accuracy: 0.5405 - precision: 0.6843 - recall: 0.3710 - val_loss: 2.4390 - val_accuracy: 0.3237 - val_precision: 0.3951 - val_recall: 0.2214\n","Epoch 315/10000\n","185/185 [==============================] - 18s 97ms/step - loss: 1.3344 - accuracy: 0.5418 - precision: 0.6927 - recall: 0.3759 - val_loss: 2.5494 - val_accuracy: 0.2933 - val_precision: 0.3694 - val_recall: 0.2128\n","Epoch 316/10000\n","185/185 [==============================] - 18s 97ms/step - loss: 1.3291 - accuracy: 0.5443 - precision: 0.6925 - recall: 0.3740 - val_loss: 2.4850 - val_accuracy: 0.3283 - val_precision: 0.3790 - val_recall: 0.2102\n","Epoch 317/10000\n","185/185 [==============================] - 18s 97ms/step - loss: 1.3073 - accuracy: 0.5391 - precision: 0.6926 - recall: 0.3724 - val_loss: 2.4522 - val_accuracy: 0.3333 - val_precision: 0.3936 - val_recall: 0.2183\n","Epoch 318/10000\n","185/185 [==============================] - 19s 105ms/step - loss: 1.3146 - accuracy: 0.5467 - precision: 0.6953 - recall: 0.3793 - val_loss: 2.4369 - val_accuracy: 0.3308 - val_precision: 0.3995 - val_recall: 0.2335\n","Epoch 319/10000\n","185/185 [==============================] - 18s 98ms/step - loss: 1.3176 - accuracy: 0.5447 - precision: 0.6840 - recall: 0.3715 - val_loss: 2.5605 - val_accuracy: 0.2984 - val_precision: 0.3573 - val_recall: 0.2143\n","Epoch 320/10000\n","185/185 [==============================] - 20s 107ms/step - loss: 1.3062 - accuracy: 0.5471 - precision: 0.6894 - recall: 0.3751 - val_loss: 2.4765 - val_accuracy: 0.3202 - val_precision: 0.3843 - val_recall: 0.2163\n","Epoch 321/10000\n","185/185 [==============================] - 18s 97ms/step - loss: 1.3193 - accuracy: 0.5445 - precision: 0.7002 - recall: 0.3820 - val_loss: 2.4932 - val_accuracy: 0.3080 - val_precision: 0.3813 - val_recall: 0.2082\n","Epoch 322/10000\n","185/185 [==============================] - 19s 105ms/step - loss: 1.2948 - accuracy: 0.5487 - precision: 0.6986 - recall: 0.3818 - val_loss: 2.6991 - val_accuracy: 0.2842 - val_precision: 0.3336 - val_recall: 0.2087\n","Epoch 323/10000\n","185/185 [==============================] - 18s 98ms/step - loss: 1.2761 - accuracy: 0.5601 - precision: 0.6956 - recall: 0.3953 - val_loss: 2.6230 - val_accuracy: 0.3075 - val_precision: 0.3740 - val_recall: 0.2270\n","Epoch 324/10000\n","185/185 [==============================] - 18s 98ms/step - loss: 1.3034 - accuracy: 0.5440 - precision: 0.6924 - recall: 0.3876 - val_loss: 2.5640 - val_accuracy: 0.3085 - val_precision: 0.3891 - val_recall: 0.2204\n","Epoch 325/10000\n","185/185 [==============================] - 19s 101ms/step - loss: 1.3170 - accuracy: 0.5427 - precision: 0.6957 - recall: 0.3850 - val_loss: 2.5494 - val_accuracy: 0.3278 - val_precision: 0.3824 - val_recall: 0.2264\n","Epoch 326/10000\n","185/185 [==============================] - 19s 101ms/step - loss: 1.2981 - accuracy: 0.5618 - precision: 0.6959 - recall: 0.3882 - val_loss: 2.5201 - val_accuracy: 0.3121 - val_precision: 0.3807 - val_recall: 0.2143\n","Epoch 327/10000\n","185/185 [==============================] - 18s 98ms/step - loss: 1.2916 - accuracy: 0.5565 - precision: 0.7075 - recall: 0.3871 - val_loss: 2.5258 - val_accuracy: 0.3247 - val_precision: 0.3850 - val_recall: 0.2239\n","Epoch 328/10000\n","185/185 [==============================] - 18s 98ms/step - loss: 1.2826 - accuracy: 0.5599 - precision: 0.6971 - recall: 0.3915 - val_loss: 2.4852 - val_accuracy: 0.3273 - val_precision: 0.3890 - val_recall: 0.2290\n","Epoch 329/10000\n","185/185 [==============================] - 19s 104ms/step - loss: 1.2737 - accuracy: 0.5560 - precision: 0.7048 - recall: 0.4026 - val_loss: 2.4688 - val_accuracy: 0.3399 - val_precision: 0.4057 - val_recall: 0.2224\n","Epoch 330/10000\n","185/185 [==============================] - 20s 107ms/step - loss: 1.2947 - accuracy: 0.5528 - precision: 0.6993 - recall: 0.3877 - val_loss: 2.5475 - val_accuracy: 0.3105 - val_precision: 0.3775 - val_recall: 0.2239\n","Epoch 331/10000\n","185/185 [==============================] - 18s 98ms/step - loss: 1.2762 - accuracy: 0.5633 - precision: 0.6975 - recall: 0.3891 - val_loss: 2.5335 - val_accuracy: 0.3105 - val_precision: 0.3835 - val_recall: 0.2168\n","Epoch 332/10000\n","185/185 [==============================] - 18s 97ms/step - loss: 1.2790 - accuracy: 0.5616 - precision: 0.7112 - recall: 0.3969 - val_loss: 2.7223 - val_accuracy: 0.2908 - val_precision: 0.3445 - val_recall: 0.2143\n","Epoch 333/10000\n","185/185 [==============================] - 19s 105ms/step - loss: 1.2792 - accuracy: 0.5675 - precision: 0.6964 - recall: 0.4019 - val_loss: 2.5752 - val_accuracy: 0.3080 - val_precision: 0.3710 - val_recall: 0.2097\n","Epoch 334/10000\n","185/185 [==============================] - 18s 99ms/step - loss: 1.2795 - accuracy: 0.5590 - precision: 0.7022 - recall: 0.3972 - val_loss: 2.5536 - val_accuracy: 0.3156 - val_precision: 0.3854 - val_recall: 0.2239\n","Epoch 335/10000\n","185/185 [==============================] - 18s 97ms/step - loss: 1.2603 - accuracy: 0.5616 - precision: 0.7107 - recall: 0.4055 - val_loss: 2.5237 - val_accuracy: 0.3040 - val_precision: 0.3651 - val_recall: 0.1981\n","Epoch 336/10000\n","185/185 [==============================] - 18s 98ms/step - loss: 1.2838 - accuracy: 0.5492 - precision: 0.6857 - recall: 0.3943 - val_loss: 2.4623 - val_accuracy: 0.3116 - val_precision: 0.3904 - val_recall: 0.2138\n","Epoch 337/10000\n","185/185 [==============================] - 19s 105ms/step - loss: 1.2658 - accuracy: 0.5653 - precision: 0.7100 - recall: 0.4045 - val_loss: 2.6079 - val_accuracy: 0.3080 - val_precision: 0.3791 - val_recall: 0.2366\n","Epoch 338/10000\n","185/185 [==============================] - 18s 97ms/step - loss: 1.2488 - accuracy: 0.5717 - precision: 0.7017 - recall: 0.4077 - val_loss: 2.5402 - val_accuracy: 0.3181 - val_precision: 0.3842 - val_recall: 0.2335\n","Epoch 339/10000\n","185/185 [==============================] - 18s 98ms/step - loss: 1.2452 - accuracy: 0.5677 - precision: 0.7110 - recall: 0.4132 - val_loss: 2.6742 - val_accuracy: 0.2964 - val_precision: 0.3626 - val_recall: 0.2199\n","Epoch 340/10000\n","185/185 [==============================] - 21s 112ms/step - loss: 1.2532 - accuracy: 0.5697 - precision: 0.7123 - recall: 0.4087 - val_loss: 2.6444 - val_accuracy: 0.3040 - val_precision: 0.3522 - val_recall: 0.2239\n","Epoch 341/10000\n","185/185 [==============================] - 19s 101ms/step - loss: 1.2588 - accuracy: 0.5663 - precision: 0.7119 - recall: 0.4124 - val_loss: 2.5631 - val_accuracy: 0.3191 - val_precision: 0.3834 - val_recall: 0.2199\n","Epoch 342/10000\n","185/185 [==============================] - 18s 98ms/step - loss: 1.2699 - accuracy: 0.5612 - precision: 0.7062 - recall: 0.3980 - val_loss: 2.5424 - val_accuracy: 0.3257 - val_precision: 0.3770 - val_recall: 0.2275\n","Epoch 343/10000\n","185/185 [==============================] - 18s 98ms/step - loss: 1.2729 - accuracy: 0.5624 - precision: 0.7045 - recall: 0.4036 - val_loss: 2.5924 - val_accuracy: 0.2958 - val_precision: 0.3604 - val_recall: 0.2133\n","Epoch 344/10000\n","185/185 [==============================] - 19s 105ms/step - loss: 1.2479 - accuracy: 0.5673 - precision: 0.7110 - recall: 0.4127 - val_loss: 2.5625 - val_accuracy: 0.3034 - val_precision: 0.3796 - val_recall: 0.2133\n","Epoch 345/10000\n","185/185 [==============================] - 18s 98ms/step - loss: 1.2225 - accuracy: 0.5841 - precision: 0.7222 - recall: 0.4217 - val_loss: 2.5964 - val_accuracy: 0.3146 - val_precision: 0.3862 - val_recall: 0.2381\n","Epoch 346/10000\n","185/185 [==============================] - 18s 99ms/step - loss: 1.2345 - accuracy: 0.5685 - precision: 0.7050 - recall: 0.4122 - val_loss: 2.6354 - val_accuracy: 0.3141 - val_precision: 0.3736 - val_recall: 0.2239\n","Epoch 347/10000\n","185/185 [==============================] - 18s 100ms/step - loss: 1.2538 - accuracy: 0.5650 - precision: 0.7046 - recall: 0.4105 - val_loss: 2.6991 - val_accuracy: 0.3191 - val_precision: 0.3612 - val_recall: 0.2234\n","Epoch 348/10000\n","185/185 [==============================] - 19s 102ms/step - loss: 1.2403 - accuracy: 0.5732 - precision: 0.7154 - recall: 0.4144 - val_loss: 2.6089 - val_accuracy: 0.3019 - val_precision: 0.3655 - val_recall: 0.2092\n","Epoch 349/10000\n","185/185 [==============================] - 18s 98ms/step - loss: 1.2375 - accuracy: 0.5710 - precision: 0.7100 - recall: 0.4170 - val_loss: 2.6913 - val_accuracy: 0.2933 - val_precision: 0.3606 - val_recall: 0.2188\n","Epoch 350/10000\n","185/185 [==============================] - 19s 104ms/step - loss: 1.2407 - accuracy: 0.5646 - precision: 0.7054 - recall: 0.4102 - val_loss: 2.6575 - val_accuracy: 0.3191 - val_precision: 0.3791 - val_recall: 0.2310\n","Epoch 351/10000\n","185/185 [==============================] - 19s 105ms/step - loss: 1.2294 - accuracy: 0.5797 - precision: 0.7073 - recall: 0.4222 - val_loss: 2.6769 - val_accuracy: 0.3040 - val_precision: 0.3671 - val_recall: 0.2168\n","Epoch 352/10000\n","185/185 [==============================] - 18s 97ms/step - loss: 1.2101 - accuracy: 0.5819 - precision: 0.7233 - recall: 0.4377 - val_loss: 2.5618 - val_accuracy: 0.3131 - val_precision: 0.3727 - val_recall: 0.2254\n","Epoch 353/10000\n","185/185 [==============================] - 18s 97ms/step - loss: 1.2199 - accuracy: 0.5764 - precision: 0.7189 - recall: 0.4230 - val_loss: 2.7608 - val_accuracy: 0.3004 - val_precision: 0.3693 - val_recall: 0.2361\n","Epoch 354/10000\n","185/185 [==============================] - 18s 97ms/step - loss: 1.2019 - accuracy: 0.5873 - precision: 0.7225 - recall: 0.4455 - val_loss: 2.6878 - val_accuracy: 0.3191 - val_precision: 0.3744 - val_recall: 0.2249\n","Epoch 355/10000\n","185/185 [==============================] - 19s 105ms/step - loss: 1.2209 - accuracy: 0.5805 - precision: 0.7175 - recall: 0.4256 - val_loss: 2.7446 - val_accuracy: 0.3075 - val_precision: 0.3668 - val_recall: 0.2421\n","Epoch 356/10000\n","185/185 [==============================] - 18s 98ms/step - loss: 1.2060 - accuracy: 0.5798 - precision: 0.7190 - recall: 0.4293 - val_loss: 2.6093 - val_accuracy: 0.3212 - val_precision: 0.3796 - val_recall: 0.2204\n","Epoch 357/10000\n","185/185 [==============================] - 18s 97ms/step - loss: 1.2214 - accuracy: 0.5795 - precision: 0.7123 - recall: 0.4208 - val_loss: 2.8273 - val_accuracy: 0.2984 - val_precision: 0.3386 - val_recall: 0.2183\n","Epoch 358/10000\n","185/185 [==============================] - 18s 97ms/step - loss: 1.2234 - accuracy: 0.5795 - precision: 0.7146 - recall: 0.4298 - val_loss: 2.5557 - val_accuracy: 0.3222 - val_precision: 0.3828 - val_recall: 0.2406\n","Epoch 359/10000\n","185/185 [==============================] - 19s 105ms/step - loss: 1.2370 - accuracy: 0.5744 - precision: 0.7180 - recall: 0.4224 - val_loss: 2.6484 - val_accuracy: 0.3040 - val_precision: 0.3801 - val_recall: 0.2224\n","Epoch 360/10000\n","185/185 [==============================] - 19s 104ms/step - loss: 1.2048 - accuracy: 0.5893 - precision: 0.7254 - recall: 0.4355 - val_loss: 2.6681 - val_accuracy: 0.3191 - val_precision: 0.3903 - val_recall: 0.2452\n","Epoch 361/10000\n","185/185 [==============================] - 18s 99ms/step - loss: 1.2041 - accuracy: 0.5839 - precision: 0.7217 - recall: 0.4403 - val_loss: 2.6823 - val_accuracy: 0.3095 - val_precision: 0.3710 - val_recall: 0.2295\n","Epoch 362/10000\n","185/185 [==============================] - 19s 104ms/step - loss: 1.2152 - accuracy: 0.5771 - precision: 0.7139 - recall: 0.4296 - val_loss: 2.6654 - val_accuracy: 0.3075 - val_precision: 0.3723 - val_recall: 0.2305\n","Epoch 363/10000\n","185/185 [==============================] - 18s 100ms/step - loss: 1.2169 - accuracy: 0.5829 - precision: 0.7200 - recall: 0.4305 - val_loss: 2.6586 - val_accuracy: 0.3191 - val_precision: 0.3772 - val_recall: 0.2381\n","Epoch 364/10000\n","185/185 [==============================] - 18s 98ms/step - loss: 1.1959 - accuracy: 0.5857 - precision: 0.7222 - recall: 0.4404 - val_loss: 2.8404 - val_accuracy: 0.2867 - val_precision: 0.3331 - val_recall: 0.2168\n","Epoch 365/10000\n","185/185 [==============================] - 18s 98ms/step - loss: 1.2096 - accuracy: 0.5781 - precision: 0.7084 - recall: 0.4330 - val_loss: 2.6492 - val_accuracy: 0.3207 - val_precision: 0.3800 - val_recall: 0.2381\n","Epoch 366/10000\n","185/185 [==============================] - 20s 106ms/step - loss: 1.1890 - accuracy: 0.5886 - precision: 0.7167 - recall: 0.4350 - val_loss: 2.6214 - val_accuracy: 0.3197 - val_precision: 0.3839 - val_recall: 0.2411\n","Epoch 367/10000\n","185/185 [==============================] - 18s 99ms/step - loss: 1.1903 - accuracy: 0.5915 - precision: 0.7181 - recall: 0.4416 - val_loss: 2.8455 - val_accuracy: 0.2928 - val_precision: 0.3356 - val_recall: 0.2249\n","Epoch 368/10000\n","185/185 [==============================] - 18s 99ms/step - loss: 1.1799 - accuracy: 0.5971 - precision: 0.7345 - recall: 0.4426 - val_loss: 2.6657 - val_accuracy: 0.3298 - val_precision: 0.3718 - val_recall: 0.2315\n","Epoch 369/10000\n","185/185 [==============================] - 20s 107ms/step - loss: 1.1787 - accuracy: 0.5913 - precision: 0.7246 - recall: 0.4462 - val_loss: 2.7714 - val_accuracy: 0.3181 - val_precision: 0.3709 - val_recall: 0.2416\n","Epoch 370/10000\n","185/185 [==============================] - 20s 107ms/step - loss: 1.2011 - accuracy: 0.5788 - precision: 0.7129 - recall: 0.4396 - val_loss: 2.8031 - val_accuracy: 0.3126 - val_precision: 0.3692 - val_recall: 0.2366\n","Epoch 371/10000\n","185/185 [==============================] - 19s 101ms/step - loss: 1.1881 - accuracy: 0.5879 - precision: 0.7202 - recall: 0.4404 - val_loss: 2.7391 - val_accuracy: 0.3126 - val_precision: 0.3646 - val_recall: 0.2366\n","Epoch 372/10000\n","185/185 [==============================] - 19s 104ms/step - loss: 1.1838 - accuracy: 0.5947 - precision: 0.7225 - recall: 0.4465 - val_loss: 2.7939 - val_accuracy: 0.3045 - val_precision: 0.3612 - val_recall: 0.2320\n","Epoch 373/10000\n","185/185 [==============================] - 19s 105ms/step - loss: 1.1864 - accuracy: 0.5857 - precision: 0.7135 - recall: 0.4401 - val_loss: 2.8472 - val_accuracy: 0.2862 - val_precision: 0.3323 - val_recall: 0.2143\n","Epoch 374/10000\n","185/185 [==============================] - 18s 100ms/step - loss: 1.2043 - accuracy: 0.5878 - precision: 0.7092 - recall: 0.4359 - val_loss: 2.7633 - val_accuracy: 0.3055 - val_precision: 0.3637 - val_recall: 0.2386\n","Epoch 375/10000\n","185/185 [==============================] - 18s 99ms/step - loss: 1.1681 - accuracy: 0.5925 - precision: 0.7234 - recall: 0.4546 - val_loss: 2.7570 - val_accuracy: 0.3040 - val_precision: 0.3508 - val_recall: 0.2239\n","Epoch 376/10000\n","185/185 [==============================] - 20s 109ms/step - loss: 1.1840 - accuracy: 0.5888 - precision: 0.7157 - recall: 0.4431 - val_loss: 2.8175 - val_accuracy: 0.3136 - val_precision: 0.3696 - val_recall: 0.2376\n","Epoch 377/10000\n","185/185 [==============================] - 18s 100ms/step - loss: 1.1639 - accuracy: 0.5891 - precision: 0.7145 - recall: 0.4474 - val_loss: 2.6844 - val_accuracy: 0.3110 - val_precision: 0.3618 - val_recall: 0.2315\n","Epoch 378/10000\n","185/185 [==============================] - 19s 101ms/step - loss: 1.1637 - accuracy: 0.6082 - precision: 0.7280 - recall: 0.4553 - val_loss: 2.7390 - val_accuracy: 0.3146 - val_precision: 0.3648 - val_recall: 0.2467\n","Epoch 379/10000\n","185/185 [==============================] - 19s 103ms/step - loss: 1.1707 - accuracy: 0.5932 - precision: 0.7196 - recall: 0.4506 - val_loss: 2.7060 - val_accuracy: 0.3186 - val_precision: 0.3695 - val_recall: 0.2310\n","Epoch 380/10000\n","185/185 [==============================] - 21s 114ms/step - loss: 1.1408 - accuracy: 0.6052 - precision: 0.7245 - recall: 0.4599 - val_loss: 2.6422 - val_accuracy: 0.3090 - val_precision: 0.3594 - val_recall: 0.2188\n","Epoch 381/10000\n","185/185 [==============================] - 19s 101ms/step - loss: 1.1743 - accuracy: 0.5981 - precision: 0.7273 - recall: 0.4614 - val_loss: 2.8614 - val_accuracy: 0.3110 - val_precision: 0.3429 - val_recall: 0.2300\n","Epoch 382/10000\n","185/185 [==============================] - 18s 99ms/step - loss: 1.1363 - accuracy: 0.6048 - precision: 0.7367 - recall: 0.4627 - val_loss: 2.7987 - val_accuracy: 0.3141 - val_precision: 0.3588 - val_recall: 0.2310\n","Epoch 383/10000\n","185/185 [==============================] - 20s 106ms/step - loss: 1.1578 - accuracy: 0.5981 - precision: 0.7236 - recall: 0.4604 - val_loss: 2.7346 - val_accuracy: 0.3085 - val_precision: 0.3753 - val_recall: 0.2416\n","Epoch 384/10000\n","185/185 [==============================] - 18s 99ms/step - loss: 1.1408 - accuracy: 0.5939 - precision: 0.7219 - recall: 0.4584 - val_loss: 2.7990 - val_accuracy: 0.3232 - val_precision: 0.3675 - val_recall: 0.2467\n","Epoch 385/10000\n","185/185 [==============================] - 18s 98ms/step - loss: 1.1232 - accuracy: 0.6119 - precision: 0.7387 - recall: 0.4790 - val_loss: 2.9740 - val_accuracy: 0.2999 - val_precision: 0.3383 - val_recall: 0.2315\n","Epoch 386/10000\n","185/185 [==============================] - 18s 99ms/step - loss: 1.1374 - accuracy: 0.6028 - precision: 0.7273 - recall: 0.4641 - val_loss: 2.7115 - val_accuracy: 0.3100 - val_precision: 0.3588 - val_recall: 0.2209\n","Epoch 387/10000\n","185/185 [==============================] - 19s 104ms/step - loss: 1.1346 - accuracy: 0.6109 - precision: 0.7349 - recall: 0.4776 - val_loss: 2.7692 - val_accuracy: 0.3151 - val_precision: 0.3747 - val_recall: 0.2371\n","Epoch 388/10000\n","185/185 [==============================] - 18s 98ms/step - loss: 1.1612 - accuracy: 0.6008 - precision: 0.7234 - recall: 0.4587 - val_loss: 2.7166 - val_accuracy: 0.3191 - val_precision: 0.3820 - val_recall: 0.2492\n","Epoch 389/10000\n","185/185 [==============================] - 18s 98ms/step - loss: 1.1490 - accuracy: 0.6058 - precision: 0.7327 - recall: 0.4663 - val_loss: 2.8608 - val_accuracy: 0.3090 - val_precision: 0.3640 - val_recall: 0.2568\n","Epoch 390/10000\n","185/185 [==============================] - 19s 105ms/step - loss: 1.1427 - accuracy: 0.6050 - precision: 0.7281 - recall: 0.4673 - val_loss: 2.7931 - val_accuracy: 0.3141 - val_precision: 0.3604 - val_recall: 0.2335\n","Epoch 391/10000\n","185/185 [==============================] - 20s 109ms/step - loss: 1.1271 - accuracy: 0.6143 - precision: 0.7381 - recall: 0.4705 - val_loss: 2.8364 - val_accuracy: 0.2948 - val_precision: 0.3495 - val_recall: 0.2295\n","Epoch 392/10000\n","185/185 [==============================] - 18s 100ms/step - loss: 1.1331 - accuracy: 0.6031 - precision: 0.7275 - recall: 0.4692 - val_loss: 2.8155 - val_accuracy: 0.3040 - val_precision: 0.3655 - val_recall: 0.2244\n","Epoch 393/10000\n","185/185 [==============================] - 18s 99ms/step - loss: 1.1217 - accuracy: 0.6116 - precision: 0.7339 - recall: 0.4729 - val_loss: 2.8156 - val_accuracy: 0.2984 - val_precision: 0.3428 - val_recall: 0.2194\n","Epoch 394/10000\n","185/185 [==============================] - 20s 106ms/step - loss: 1.1194 - accuracy: 0.6121 - precision: 0.7334 - recall: 0.4805 - val_loss: 2.9547 - val_accuracy: 0.3004 - val_precision: 0.3494 - val_recall: 0.2427\n","Epoch 395/10000\n","185/185 [==============================] - 19s 100ms/step - loss: 1.1378 - accuracy: 0.5996 - precision: 0.7213 - recall: 0.4722 - val_loss: 2.9631 - val_accuracy: 0.2979 - val_precision: 0.3500 - val_recall: 0.2340\n","Epoch 396/10000\n","185/185 [==============================] - 18s 99ms/step - loss: 1.1276 - accuracy: 0.6141 - precision: 0.7320 - recall: 0.4731 - val_loss: 2.7889 - val_accuracy: 0.3146 - val_precision: 0.3714 - val_recall: 0.2553\n","Epoch 397/10000\n","185/185 [==============================] - 18s 100ms/step - loss: 1.1378 - accuracy: 0.6072 - precision: 0.7247 - recall: 0.4781 - val_loss: 2.8141 - val_accuracy: 0.3136 - val_precision: 0.3557 - val_recall: 0.2361\n","Epoch 398/10000\n","185/185 [==============================] - 20s 106ms/step - loss: 1.1135 - accuracy: 0.6146 - precision: 0.7399 - recall: 0.4768 - val_loss: 2.7603 - val_accuracy: 0.3110 - val_precision: 0.3614 - val_recall: 0.2345\n","Epoch 399/10000\n","185/185 [==============================] - 18s 98ms/step - loss: 1.1324 - accuracy: 0.6040 - precision: 0.7354 - recall: 0.4690 - val_loss: 2.7871 - val_accuracy: 0.3131 - val_precision: 0.3629 - val_recall: 0.2467\n","Epoch 400/10000\n","185/185 [==============================] - 18s 99ms/step - loss: 1.1200 - accuracy: 0.6129 - precision: 0.7281 - recall: 0.4756 - val_loss: 2.8165 - val_accuracy: 0.3034 - val_precision: 0.3473 - val_recall: 0.2315\n","Epoch 401/10000\n","185/185 [==============================] - 20s 108ms/step - loss: 1.1024 - accuracy: 0.6212 - precision: 0.7382 - recall: 0.4948 - val_loss: 2.9402 - val_accuracy: 0.2958 - val_precision: 0.3467 - val_recall: 0.2371\n","Epoch 402/10000\n","185/185 [==============================] - 18s 99ms/step - loss: 1.1138 - accuracy: 0.6151 - precision: 0.7335 - recall: 0.4800 - val_loss: 2.8987 - val_accuracy: 0.2994 - val_precision: 0.3490 - val_recall: 0.2330\n","Epoch 403/10000\n","185/185 [==============================] - 19s 105ms/step - loss: 1.0982 - accuracy: 0.6178 - precision: 0.7367 - recall: 0.4854 - val_loss: 2.7845 - val_accuracy: 0.3171 - val_precision: 0.3768 - val_recall: 0.2472\n","Epoch 404/10000\n","185/185 [==============================] - 18s 99ms/step - loss: 1.1046 - accuracy: 0.6204 - precision: 0.7369 - recall: 0.4854 - val_loss: 3.0201 - val_accuracy: 0.3019 - val_precision: 0.3435 - val_recall: 0.2340\n","Epoch 405/10000\n","185/185 [==============================] - 18s 98ms/step - loss: 1.1077 - accuracy: 0.6199 - precision: 0.7331 - recall: 0.4849 - val_loss: 2.9434 - val_accuracy: 0.2989 - val_precision: 0.3527 - val_recall: 0.2371\n","Epoch 406/10000\n","185/185 [==============================] - 19s 100ms/step - loss: 1.1128 - accuracy: 0.6096 - precision: 0.7340 - recall: 0.4774 - val_loss: 2.8673 - val_accuracy: 0.3090 - val_precision: 0.3532 - val_recall: 0.2492\n","Epoch 407/10000\n","185/185 [==============================] - 19s 104ms/step - loss: 1.0934 - accuracy: 0.6227 - precision: 0.7471 - recall: 0.4962 - val_loss: 2.8555 - val_accuracy: 0.3252 - val_precision: 0.3754 - val_recall: 0.2563\n","Epoch 408/10000\n","185/185 [==============================] - 18s 98ms/step - loss: 1.0835 - accuracy: 0.6241 - precision: 0.7418 - recall: 0.4947 - val_loss: 2.8471 - val_accuracy: 0.3075 - val_precision: 0.3594 - val_recall: 0.2401\n","Epoch 409/10000\n","185/185 [==============================] - 18s 98ms/step - loss: 1.0883 - accuracy: 0.6202 - precision: 0.7398 - recall: 0.4970 - val_loss: 3.0497 - val_accuracy: 0.2882 - val_precision: 0.3302 - val_recall: 0.2310\n","Epoch 410/10000\n","185/185 [==============================] - 19s 103ms/step - loss: 1.0900 - accuracy: 0.6263 - precision: 0.7475 - recall: 0.4965 - val_loss: 2.8998 - val_accuracy: 0.3141 - val_precision: 0.3652 - val_recall: 0.2538\n","Epoch 411/10000\n","185/185 [==============================] - 20s 109ms/step - loss: 1.0737 - accuracy: 0.6236 - precision: 0.7388 - recall: 0.4989 - val_loss: 2.9520 - val_accuracy: 0.3116 - val_precision: 0.3445 - val_recall: 0.2492\n","Epoch 412/10000\n","185/185 [==============================] - 18s 98ms/step - loss: 1.0889 - accuracy: 0.6214 - precision: 0.7385 - recall: 0.5006 - val_loss: 3.0207 - val_accuracy: 0.2979 - val_precision: 0.3373 - val_recall: 0.2442\n","Epoch 413/10000\n","185/185 [==============================] - 18s 98ms/step - loss: 1.1028 - accuracy: 0.6205 - precision: 0.7385 - recall: 0.4923 - val_loss: 2.8964 - val_accuracy: 0.3029 - val_precision: 0.3604 - val_recall: 0.2447\n","Epoch 414/10000\n","185/185 [==============================] - 20s 107ms/step - loss: 1.0734 - accuracy: 0.6292 - precision: 0.7419 - recall: 0.5016 - val_loss: 2.8585 - val_accuracy: 0.3040 - val_precision: 0.3623 - val_recall: 0.2432\n","Epoch 415/10000\n","185/185 [==============================] - 18s 98ms/step - loss: 1.0834 - accuracy: 0.6270 - precision: 0.7381 - recall: 0.4984 - val_loss: 2.8486 - val_accuracy: 0.3116 - val_precision: 0.3677 - val_recall: 0.2401\n","Epoch 416/10000\n","185/185 [==============================] - 18s 98ms/step - loss: 1.0451 - accuracy: 0.6342 - precision: 0.7523 - recall: 0.5058 - val_loss: 2.9148 - val_accuracy: 0.3055 - val_precision: 0.3599 - val_recall: 0.2401\n","Epoch 417/10000\n","185/185 [==============================] - 18s 99ms/step - loss: 1.0671 - accuracy: 0.6300 - precision: 0.7462 - recall: 0.5075 - val_loss: 2.9685 - val_accuracy: 0.2943 - val_precision: 0.3329 - val_recall: 0.2330\n","Epoch 418/10000\n","185/185 [==============================] - 20s 106ms/step - loss: 1.0672 - accuracy: 0.6261 - precision: 0.7424 - recall: 0.5040 - val_loss: 3.1992 - val_accuracy: 0.2877 - val_precision: 0.3275 - val_recall: 0.2371\n","Epoch 419/10000\n","185/185 [==============================] - 18s 99ms/step - loss: 1.0778 - accuracy: 0.6204 - precision: 0.7417 - recall: 0.5006 - val_loss: 2.8754 - val_accuracy: 0.3105 - val_precision: 0.3614 - val_recall: 0.2432\n","Epoch 420/10000\n","185/185 [==============================] - 18s 99ms/step - loss: 1.0470 - accuracy: 0.6346 - precision: 0.7527 - recall: 0.5117 - val_loss: 2.9921 - val_accuracy: 0.3024 - val_precision: 0.3518 - val_recall: 0.2381\n","Epoch 421/10000\n","185/185 [==============================] - 20s 106ms/step - loss: 1.0555 - accuracy: 0.6366 - precision: 0.7558 - recall: 0.5119 - val_loss: 2.9344 - val_accuracy: 0.3065 - val_precision: 0.3546 - val_recall: 0.2447\n","Epoch 422/10000\n","185/185 [==============================] - 19s 105ms/step - loss: 1.0658 - accuracy: 0.6381 - precision: 0.7424 - recall: 0.5102 - val_loss: 3.1425 - val_accuracy: 0.2877 - val_precision: 0.3362 - val_recall: 0.2406\n","Epoch 423/10000\n","185/185 [==============================] - 18s 99ms/step - loss: 1.0615 - accuracy: 0.6369 - precision: 0.7456 - recall: 0.5116 - val_loss: 2.8821 - val_accuracy: 0.3212 - val_precision: 0.3689 - val_recall: 0.2538\n","Epoch 424/10000\n","185/185 [==============================] - 18s 99ms/step - loss: 1.0483 - accuracy: 0.6417 - precision: 0.7524 - recall: 0.5200 - val_loss: 3.0215 - val_accuracy: 0.3040 - val_precision: 0.3566 - val_recall: 0.2584\n","Epoch 425/10000\n","185/185 [==============================] - 18s 98ms/step - loss: 1.0465 - accuracy: 0.6376 - precision: 0.7509 - recall: 0.5134 - val_loss: 3.1200 - val_accuracy: 0.2893 - val_precision: 0.3343 - val_recall: 0.2421\n","Epoch 426/10000\n","185/185 [==============================] - 20s 107ms/step - loss: 1.0588 - accuracy: 0.6280 - precision: 0.7427 - recall: 0.5080 - val_loss: 2.9820 - val_accuracy: 0.3070 - val_precision: 0.3478 - val_recall: 0.2437\n","Epoch 427/10000\n","185/185 [==============================] - 18s 99ms/step - loss: 1.0577 - accuracy: 0.6369 - precision: 0.7458 - recall: 0.5139 - val_loss: 3.1207 - val_accuracy: 0.2908 - val_precision: 0.3324 - val_recall: 0.2391\n","Epoch 428/10000\n","185/185 [==============================] - 18s 99ms/step - loss: 1.0462 - accuracy: 0.6462 - precision: 0.7492 - recall: 0.5148 - val_loss: 3.0464 - val_accuracy: 0.3040 - val_precision: 0.3414 - val_recall: 0.2568\n","Epoch 429/10000\n","185/185 [==============================] - 18s 100ms/step - loss: 1.0399 - accuracy: 0.6308 - precision: 0.7430 - recall: 0.5095 - val_loss: 3.0236 - val_accuracy: 0.3085 - val_precision: 0.3551 - val_recall: 0.2538\n","Epoch 430/10000\n","185/185 [==============================] - 20s 108ms/step - loss: 1.0309 - accuracy: 0.6403 - precision: 0.7473 - recall: 0.5202 - val_loss: 3.0164 - val_accuracy: 0.3131 - val_precision: 0.3542 - val_recall: 0.2528\n","Epoch 431/10000\n","185/185 [==============================] - 20s 108ms/step - loss: 1.0514 - accuracy: 0.6361 - precision: 0.7472 - recall: 0.5163 - val_loss: 3.0978 - val_accuracy: 0.3065 - val_precision: 0.3489 - val_recall: 0.2573\n","Epoch 432/10000\n","185/185 [==============================] - 18s 100ms/step - loss: 1.0449 - accuracy: 0.6312 - precision: 0.7474 - recall: 0.5148 - val_loss: 3.0391 - val_accuracy: 0.2958 - val_precision: 0.3366 - val_recall: 0.2472\n","Epoch 433/10000\n","185/185 [==============================] - 20s 107ms/step - loss: 1.0372 - accuracy: 0.6425 - precision: 0.7556 - recall: 0.5175 - val_loss: 3.0429 - val_accuracy: 0.2933 - val_precision: 0.3448 - val_recall: 0.2432\n","Epoch 434/10000\n","185/185 [==============================] - 18s 99ms/step - loss: 1.0227 - accuracy: 0.6430 - precision: 0.7540 - recall: 0.5286 - val_loss: 3.0665 - val_accuracy: 0.3095 - val_precision: 0.3437 - val_recall: 0.2518\n","Epoch 435/10000\n","185/185 [==============================] - 18s 99ms/step - loss: 1.0317 - accuracy: 0.6379 - precision: 0.7518 - recall: 0.5193 - val_loss: 3.1428 - val_accuracy: 0.2882 - val_precision: 0.3396 - val_recall: 0.2391\n","Epoch 436/10000\n","185/185 [==============================] - 18s 100ms/step - loss: 1.0077 - accuracy: 0.6521 - precision: 0.7575 - recall: 0.5320 - val_loss: 2.9923 - val_accuracy: 0.3085 - val_precision: 0.3532 - val_recall: 0.2518\n","Epoch 437/10000\n","185/185 [==============================] - 19s 105ms/step - loss: 1.0208 - accuracy: 0.6449 - precision: 0.7507 - recall: 0.5259 - val_loss: 3.1438 - val_accuracy: 0.3019 - val_precision: 0.3488 - val_recall: 0.2518\n","Epoch 438/10000\n","185/185 [==============================] - 18s 99ms/step - loss: 1.0297 - accuracy: 0.6467 - precision: 0.7533 - recall: 0.5303 - val_loss: 3.1157 - val_accuracy: 0.2938 - val_precision: 0.3368 - val_recall: 0.2427\n","Epoch 439/10000\n","185/185 [==============================] - 18s 100ms/step - loss: 1.0361 - accuracy: 0.6462 - precision: 0.7513 - recall: 0.5266 - val_loss: 3.1127 - val_accuracy: 0.3055 - val_precision: 0.3570 - val_recall: 0.2518\n","Epoch 440/10000\n","185/185 [==============================] - 19s 103ms/step - loss: 1.0270 - accuracy: 0.6440 - precision: 0.7473 - recall: 0.5171 - val_loss: 3.1728 - val_accuracy: 0.3045 - val_precision: 0.3434 - val_recall: 0.2543\n","Epoch 441/10000\n","185/185 [==============================] - 21s 112ms/step - loss: 1.0094 - accuracy: 0.6483 - precision: 0.7568 - recall: 0.5298 - val_loss: 2.9617 - val_accuracy: 0.3075 - val_precision: 0.3552 - val_recall: 0.2472\n","Epoch 442/10000\n","185/185 [==============================] - 18s 100ms/step - loss: 1.0057 - accuracy: 0.6550 - precision: 0.7635 - recall: 0.5313 - val_loss: 3.2023 - val_accuracy: 0.3116 - val_precision: 0.3410 - val_recall: 0.2568\n","Epoch 443/10000\n","185/185 [==============================] - 19s 101ms/step - loss: 0.9900 - accuracy: 0.6638 - precision: 0.7650 - recall: 0.5450 - val_loss: 3.0747 - val_accuracy: 0.3014 - val_precision: 0.3416 - val_recall: 0.2376\n","Epoch 444/10000\n","185/185 [==============================] - 20s 106ms/step - loss: 1.0175 - accuracy: 0.6450 - precision: 0.7525 - recall: 0.5305 - val_loss: 3.0547 - val_accuracy: 0.3014 - val_precision: 0.3400 - val_recall: 0.2492\n","Epoch 445/10000\n","185/185 [==============================] - 19s 103ms/step - loss: 1.0212 - accuracy: 0.6401 - precision: 0.7479 - recall: 0.5291 - val_loss: 3.3064 - val_accuracy: 0.2943 - val_precision: 0.3322 - val_recall: 0.2548\n","Epoch 446/10000\n","185/185 [==============================] - 19s 102ms/step - loss: 1.0109 - accuracy: 0.6467 - precision: 0.7606 - recall: 0.5379 - val_loss: 3.1121 - val_accuracy: 0.3014 - val_precision: 0.3418 - val_recall: 0.2518\n","Epoch 447/10000\n","185/185 [==============================] - 19s 101ms/step - loss: 0.9908 - accuracy: 0.6515 - precision: 0.7583 - recall: 0.5374 - val_loss: 3.1462 - val_accuracy: 0.2888 - val_precision: 0.3239 - val_recall: 0.2442\n","Epoch 448/10000\n","185/185 [==============================] - 20s 109ms/step - loss: 0.9824 - accuracy: 0.6616 - precision: 0.7668 - recall: 0.5445 - val_loss: 3.2800 - val_accuracy: 0.2893 - val_precision: 0.3349 - val_recall: 0.2533\n","Epoch 449/10000\n","185/185 [==============================] - 19s 100ms/step - loss: 0.9859 - accuracy: 0.6560 - precision: 0.7641 - recall: 0.5430 - val_loss: 3.3204 - val_accuracy: 0.3024 - val_precision: 0.3349 - val_recall: 0.2558\n","Epoch 450/10000\n","185/185 [==============================] - 20s 107ms/step - loss: 0.9899 - accuracy: 0.6601 - precision: 0.7692 - recall: 0.5511 - val_loss: 3.1748 - val_accuracy: 0.2958 - val_precision: 0.3324 - val_recall: 0.2523\n","Epoch 451/10000\n","185/185 [==============================] - 20s 108ms/step - loss: 0.9687 - accuracy: 0.6668 - precision: 0.7696 - recall: 0.5575 - val_loss: 3.3313 - val_accuracy: 0.2953 - val_precision: 0.3309 - val_recall: 0.2528\n","Epoch 452/10000\n","185/185 [==============================] - 19s 101ms/step - loss: 0.9895 - accuracy: 0.6520 - precision: 0.7518 - recall: 0.5394 - val_loss: 3.0909 - val_accuracy: 0.3242 - val_precision: 0.3615 - val_recall: 0.2644\n","Epoch 453/10000\n","185/185 [==============================] - 19s 101ms/step - loss: 0.9811 - accuracy: 0.6626 - precision: 0.7684 - recall: 0.5567 - val_loss: 3.2212 - val_accuracy: 0.3116 - val_precision: 0.3512 - val_recall: 0.2589\n","Epoch 454/10000\n","185/185 [==============================] - 19s 102ms/step - loss: 0.9656 - accuracy: 0.6635 - precision: 0.7681 - recall: 0.5612 - val_loss: 3.2480 - val_accuracy: 0.3080 - val_precision: 0.3503 - val_recall: 0.2614\n","Epoch 455/10000\n","185/185 [==============================] - 20s 106ms/step - loss: 0.9846 - accuracy: 0.6584 - precision: 0.7605 - recall: 0.5585 - val_loss: 3.2642 - val_accuracy: 0.3014 - val_precision: 0.3455 - val_recall: 0.2548\n","Epoch 456/10000\n","185/185 [==============================] - 18s 100ms/step - loss: 0.9770 - accuracy: 0.6611 - precision: 0.7675 - recall: 0.5560 - val_loss: 3.4520 - val_accuracy: 0.2852 - val_precision: 0.3257 - val_recall: 0.2518\n","Epoch 457/10000\n","185/185 [==============================] - 18s 100ms/step - loss: 0.9931 - accuracy: 0.6515 - precision: 0.7602 - recall: 0.5351 - val_loss: 3.2457 - val_accuracy: 0.2953 - val_precision: 0.3361 - val_recall: 0.2503\n","Epoch 458/10000\n","185/185 [==============================] - 19s 105ms/step - loss: 0.9683 - accuracy: 0.6645 - precision: 0.7651 - recall: 0.5518 - val_loss: 3.1694 - val_accuracy: 0.2999 - val_precision: 0.3426 - val_recall: 0.2447\n","Epoch 459/10000\n","185/185 [==============================] - 19s 101ms/step - loss: 0.9855 - accuracy: 0.6596 - precision: 0.7546 - recall: 0.5465 - val_loss: 3.2785 - val_accuracy: 0.2938 - val_precision: 0.3229 - val_recall: 0.2447\n","Epoch 460/10000\n","185/185 [==============================] - 20s 107ms/step - loss: 0.9989 - accuracy: 0.6621 - precision: 0.7620 - recall: 0.5506 - val_loss: 3.2790 - val_accuracy: 0.3029 - val_precision: 0.3317 - val_recall: 0.2427\n","Epoch 461/10000\n","185/185 [==============================] - 18s 100ms/step - loss: 0.9739 - accuracy: 0.6640 - precision: 0.7603 - recall: 0.5596 - val_loss: 3.1527 - val_accuracy: 0.3110 - val_precision: 0.3450 - val_recall: 0.2503\n","Epoch 462/10000\n","185/185 [==============================] - 19s 100ms/step - loss: 0.9334 - accuracy: 0.6775 - precision: 0.7760 - recall: 0.5678 - val_loss: 3.2788 - val_accuracy: 0.3171 - val_precision: 0.3529 - val_recall: 0.2675\n","Epoch 463/10000\n","185/185 [==============================] - 20s 106ms/step - loss: 0.9553 - accuracy: 0.6646 - precision: 0.7699 - recall: 0.5670 - val_loss: 3.2587 - val_accuracy: 0.3110 - val_precision: 0.3491 - val_recall: 0.2579\n","Epoch 464/10000\n","185/185 [==============================] - 19s 100ms/step - loss: 0.9624 - accuracy: 0.6646 - precision: 0.7639 - recall: 0.5602 - val_loss: 3.1077 - val_accuracy: 0.3100 - val_precision: 0.3538 - val_recall: 0.2604\n","Epoch 465/10000\n","185/185 [==============================] - 18s 100ms/step - loss: 0.9820 - accuracy: 0.6606 - precision: 0.7580 - recall: 0.5569 - val_loss: 3.2180 - val_accuracy: 0.2974 - val_precision: 0.3459 - val_recall: 0.2508\n","Epoch 466/10000\n","185/185 [==============================] - 19s 104ms/step - loss: 0.9596 - accuracy: 0.6646 - precision: 0.7625 - recall: 0.5585 - val_loss: 3.2014 - val_accuracy: 0.3060 - val_precision: 0.3429 - val_recall: 0.2594\n","Epoch 467/10000\n","185/185 [==============================] - 19s 103ms/step - loss: 0.9403 - accuracy: 0.6768 - precision: 0.7742 - recall: 0.5712 - val_loss: 3.2391 - val_accuracy: 0.3065 - val_precision: 0.3380 - val_recall: 0.2584\n","Epoch 468/10000\n","185/185 [==============================] - 19s 101ms/step - loss: 0.9566 - accuracy: 0.6707 - precision: 0.7670 - recall: 0.5683 - val_loss: 3.2258 - val_accuracy: 0.3019 - val_precision: 0.3407 - val_recall: 0.2513\n","Epoch 469/10000\n","185/185 [==============================] - 19s 102ms/step - loss: 0.9451 - accuracy: 0.6711 - precision: 0.7744 - recall: 0.5614 - val_loss: 3.2524 - val_accuracy: 0.3060 - val_precision: 0.3459 - val_recall: 0.2558\n","Epoch 470/10000\n","185/185 [==============================] - 20s 110ms/step - loss: 0.9277 - accuracy: 0.6746 - precision: 0.7776 - recall: 0.5729 - val_loss: 3.2676 - val_accuracy: 0.3009 - val_precision: 0.3361 - val_recall: 0.2452\n","Epoch 471/10000\n","185/185 [==============================] - 20s 109ms/step - loss: 0.9218 - accuracy: 0.6770 - precision: 0.7853 - recall: 0.5776 - val_loss: 3.3975 - val_accuracy: 0.2872 - val_precision: 0.3191 - val_recall: 0.2427\n","Epoch 472/10000\n","185/185 [==============================] - 19s 101ms/step - loss: 0.9274 - accuracy: 0.6842 - precision: 0.7734 - recall: 0.5773 - val_loss: 3.3028 - val_accuracy: 0.3060 - val_precision: 0.3381 - val_recall: 0.2644\n","Epoch 473/10000\n","185/185 [==============================] - 20s 107ms/step - loss: 0.9371 - accuracy: 0.6722 - precision: 0.7669 - recall: 0.5753 - val_loss: 3.3185 - val_accuracy: 0.3034 - val_precision: 0.3471 - val_recall: 0.2563\n","Epoch 474/10000\n","185/185 [==============================] - 19s 104ms/step - loss: 0.9442 - accuracy: 0.6734 - precision: 0.7728 - recall: 0.5717 - val_loss: 3.2987 - val_accuracy: 0.3095 - val_precision: 0.3451 - val_recall: 0.2629\n","Epoch 475/10000\n","185/185 [==============================] - 19s 101ms/step - loss: 0.9471 - accuracy: 0.6672 - precision: 0.7668 - recall: 0.5626 - val_loss: 3.3574 - val_accuracy: 0.3055 - val_precision: 0.3412 - val_recall: 0.2710\n","Epoch 476/10000\n","185/185 [==============================] - 19s 101ms/step - loss: 0.9611 - accuracy: 0.6658 - precision: 0.7543 - recall: 0.5623 - val_loss: 3.3085 - val_accuracy: 0.3116 - val_precision: 0.3490 - val_recall: 0.2634\n","Epoch 477/10000\n","185/185 [==============================] - 20s 108ms/step - loss: 0.9312 - accuracy: 0.6704 - precision: 0.7654 - recall: 0.5651 - val_loss: 3.3498 - val_accuracy: 0.2964 - val_precision: 0.3354 - val_recall: 0.2487\n","Epoch 478/10000\n","185/185 [==============================] - 19s 100ms/step - loss: 0.9541 - accuracy: 0.6670 - precision: 0.7653 - recall: 0.5700 - val_loss: 3.4066 - val_accuracy: 0.3060 - val_precision: 0.3424 - val_recall: 0.2665\n","Epoch 479/10000\n","185/185 [==============================] - 19s 100ms/step - loss: 0.9273 - accuracy: 0.6753 - precision: 0.7769 - recall: 0.5748 - val_loss: 3.3069 - val_accuracy: 0.3004 - val_precision: 0.3362 - val_recall: 0.2558\n","Epoch 480/10000\n","185/185 [==============================] - 20s 111ms/step - loss: 0.9333 - accuracy: 0.6751 - precision: 0.7685 - recall: 0.5778 - val_loss: 3.2521 - val_accuracy: 0.3116 - val_precision: 0.3515 - val_recall: 0.2649\n","Epoch 481/10000\n","185/185 [==============================] - 20s 106ms/step - loss: 0.9327 - accuracy: 0.6805 - precision: 0.7791 - recall: 0.5798 - val_loss: 3.3168 - val_accuracy: 0.3014 - val_precision: 0.3258 - val_recall: 0.2401\n","Epoch 482/10000\n","185/185 [==============================] - 19s 101ms/step - loss: 0.9283 - accuracy: 0.6782 - precision: 0.7774 - recall: 0.5743 - val_loss: 3.3469 - val_accuracy: 0.3065 - val_precision: 0.3310 - val_recall: 0.2614\n","Epoch 483/10000\n","185/185 [==============================] - 19s 100ms/step - loss: 0.9057 - accuracy: 0.6881 - precision: 0.7777 - recall: 0.5857 - val_loss: 3.4228 - val_accuracy: 0.2928 - val_precision: 0.3239 - val_recall: 0.2487\n","Epoch 484/10000\n","185/185 [==============================] - 19s 105ms/step - loss: 0.9238 - accuracy: 0.6739 - precision: 0.7734 - recall: 0.5754 - val_loss: 3.3826 - val_accuracy: 0.3045 - val_precision: 0.3484 - val_recall: 0.2624\n","Epoch 485/10000\n","185/185 [==============================] - 19s 101ms/step - loss: 0.9193 - accuracy: 0.6788 - precision: 0.7740 - recall: 0.5786 - val_loss: 3.4763 - val_accuracy: 0.2953 - val_precision: 0.3288 - val_recall: 0.2573\n","Epoch 486/10000\n","185/185 [==============================] - 19s 100ms/step - loss: 0.9185 - accuracy: 0.6831 - precision: 0.7760 - recall: 0.5888 - val_loss: 3.2693 - val_accuracy: 0.3034 - val_precision: 0.3437 - val_recall: 0.2568\n","Epoch 487/10000\n","185/185 [==============================] - 19s 103ms/step - loss: 0.8827 - accuracy: 0.6915 - precision: 0.7883 - recall: 0.5964 - val_loss: 3.4837 - val_accuracy: 0.3024 - val_precision: 0.3344 - val_recall: 0.2624\n","Epoch 488/10000\n","185/185 [==============================] - 20s 108ms/step - loss: 0.8869 - accuracy: 0.6932 - precision: 0.7800 - recall: 0.5959 - val_loss: 3.3997 - val_accuracy: 0.3024 - val_precision: 0.3465 - val_recall: 0.2487\n","Epoch 489/10000\n","185/185 [==============================] - 18s 100ms/step - loss: 0.8751 - accuracy: 0.6964 - precision: 0.7939 - recall: 0.6021 - val_loss: 3.2714 - val_accuracy: 0.2928 - val_precision: 0.3275 - val_recall: 0.2447\n","Epoch 490/10000\n","185/185 [==============================] - 21s 114ms/step - loss: 0.9078 - accuracy: 0.6907 - precision: 0.7788 - recall: 0.5906 - val_loss: 3.3743 - val_accuracy: 0.2984 - val_precision: 0.3293 - val_recall: 0.2594\n","Epoch 491/10000\n","185/185 [==============================] - 20s 108ms/step - loss: 0.9106 - accuracy: 0.6864 - precision: 0.7829 - recall: 0.5935 - val_loss: 3.4807 - val_accuracy: 0.2964 - val_precision: 0.3353 - val_recall: 0.2538\n","Epoch 492/10000\n","185/185 [==============================] - 20s 106ms/step - loss: 0.9012 - accuracy: 0.6893 - precision: 0.7763 - recall: 0.5962 - val_loss: 3.6175 - val_accuracy: 0.2974 - val_precision: 0.3220 - val_recall: 0.2599\n","Epoch 493/10000\n","185/185 [==============================] - 20s 107ms/step - loss: 0.8999 - accuracy: 0.6839 - precision: 0.7742 - recall: 0.5890 - val_loss: 3.4551 - val_accuracy: 0.3009 - val_precision: 0.3287 - val_recall: 0.2513\n","Epoch 494/10000\n","185/185 [==============================] - 20s 108ms/step - loss: 0.8938 - accuracy: 0.6893 - precision: 0.7794 - recall: 0.5957 - val_loss: 3.3909 - val_accuracy: 0.3090 - val_precision: 0.3384 - val_recall: 0.2609\n","Epoch 495/10000\n","185/185 [==============================] - 19s 100ms/step - loss: 0.8971 - accuracy: 0.6959 - precision: 0.7736 - recall: 0.5945 - val_loss: 3.3259 - val_accuracy: 0.3029 - val_precision: 0.3344 - val_recall: 0.2584\n","Epoch 496/10000\n","185/185 [==============================] - 19s 100ms/step - loss: 0.9012 - accuracy: 0.6810 - precision: 0.7776 - recall: 0.5883 - val_loss: 3.5778 - val_accuracy: 0.2943 - val_precision: 0.3229 - val_recall: 0.2573\n","Epoch 497/10000\n","185/185 [==============================] - 19s 104ms/step - loss: 0.8957 - accuracy: 0.6895 - precision: 0.7819 - recall: 0.5967 - val_loss: 3.4173 - val_accuracy: 0.3024 - val_precision: 0.3387 - val_recall: 0.2649\n","Epoch 498/10000\n","185/185 [==============================] - 19s 105ms/step - loss: 0.8831 - accuracy: 0.6940 - precision: 0.7802 - recall: 0.5937 - val_loss: 3.4134 - val_accuracy: 0.2837 - val_precision: 0.3241 - val_recall: 0.2432\n","Epoch 499/10000\n","185/185 [==============================] - 19s 102ms/step - loss: 0.8779 - accuracy: 0.6999 - precision: 0.7934 - recall: 0.6053 - val_loss: 3.4979 - val_accuracy: 0.2913 - val_precision: 0.3244 - val_recall: 0.2523\n","Epoch 500/10000\n","185/185 [==============================] - 20s 107ms/step - loss: 0.8933 - accuracy: 0.6896 - precision: 0.7776 - recall: 0.5960 - val_loss: 3.5533 - val_accuracy: 0.3095 - val_precision: 0.3327 - val_recall: 0.2649\n","Epoch 501/10000\n","185/185 [==============================] - 20s 109ms/step - loss: 0.8892 - accuracy: 0.6886 - precision: 0.7773 - recall: 0.5974 - val_loss: 3.5153 - val_accuracy: 0.3116 - val_precision: 0.3329 - val_recall: 0.2756\n","Epoch 502/10000\n","185/185 [==============================] - 19s 102ms/step - loss: 0.8836 - accuracy: 0.6935 - precision: 0.7833 - recall: 0.5972 - val_loss: 3.4214 - val_accuracy: 0.3019 - val_precision: 0.3367 - val_recall: 0.2553\n","Epoch 503/10000\n","185/185 [==============================] - 19s 101ms/step - loss: 0.8750 - accuracy: 0.6908 - precision: 0.7852 - recall: 0.6008 - val_loss: 3.6681 - val_accuracy: 0.2812 - val_precision: 0.3149 - val_recall: 0.2477\n","Epoch 504/10000\n","185/185 [==============================] - 19s 103ms/step - loss: 0.8939 - accuracy: 0.6935 - precision: 0.7779 - recall: 0.5981 - val_loss: 3.4488 - val_accuracy: 0.2964 - val_precision: 0.3325 - val_recall: 0.2614\n","Epoch 505/10000\n","185/185 [==============================] - 19s 105ms/step - loss: 0.8689 - accuracy: 0.6954 - precision: 0.7912 - recall: 0.6016 - val_loss: 3.6279 - val_accuracy: 0.2938 - val_precision: 0.3236 - val_recall: 0.2538\n","Epoch 506/10000\n","185/185 [==============================] - 18s 100ms/step - loss: 0.8808 - accuracy: 0.6908 - precision: 0.7765 - recall: 0.5998 - val_loss: 3.2620 - val_accuracy: 0.3075 - val_precision: 0.3405 - val_recall: 0.2639\n","Epoch 507/10000\n","185/185 [==============================] - 19s 101ms/step - loss: 0.8432 - accuracy: 0.7057 - precision: 0.7882 - recall: 0.6160 - val_loss: 3.5632 - val_accuracy: 0.2943 - val_precision: 0.3175 - val_recall: 0.2533\n","Epoch 508/10000\n","185/185 [==============================] - 20s 108ms/step - loss: 0.8669 - accuracy: 0.6961 - precision: 0.7818 - recall: 0.6009 - val_loss: 3.3995 - val_accuracy: 0.3065 - val_precision: 0.3381 - val_recall: 0.2639\n","Epoch 509/10000\n","185/185 [==============================] - 19s 101ms/step - loss: 0.8818 - accuracy: 0.6898 - precision: 0.7738 - recall: 0.6033 - val_loss: 3.6149 - val_accuracy: 0.2974 - val_precision: 0.3191 - val_recall: 0.2528\n","Epoch 510/10000\n","185/185 [==============================] - 20s 109ms/step - loss: 0.8435 - accuracy: 0.7013 - precision: 0.7937 - recall: 0.6116 - val_loss: 3.4168 - val_accuracy: 0.2989 - val_precision: 0.3325 - val_recall: 0.2614\n","Epoch 511/10000\n","185/185 [==============================] - 19s 101ms/step - loss: 0.8509 - accuracy: 0.7040 - precision: 0.7871 - recall: 0.6107 - val_loss: 3.4817 - val_accuracy: 0.2979 - val_precision: 0.3291 - val_recall: 0.2604\n","Epoch 512/10000\n","185/185 [==============================] - 20s 108ms/step - loss: 0.8709 - accuracy: 0.6888 - precision: 0.7810 - recall: 0.6055 - val_loss: 3.6118 - val_accuracy: 0.3146 - val_precision: 0.3426 - val_recall: 0.2751\n","Epoch 513/10000\n","185/185 [==============================] - 19s 103ms/step - loss: 0.8569 - accuracy: 0.7030 - precision: 0.7851 - recall: 0.6140 - val_loss: 3.6548 - val_accuracy: 0.3040 - val_precision: 0.3348 - val_recall: 0.2655\n","Epoch 514/10000\n","185/185 [==============================] - 19s 102ms/step - loss: 0.8438 - accuracy: 0.7016 - precision: 0.7902 - recall: 0.6178 - val_loss: 3.5307 - val_accuracy: 0.3191 - val_precision: 0.3397 - val_recall: 0.2720\n","Epoch 515/10000\n","185/185 [==============================] - 19s 102ms/step - loss: 0.8595 - accuracy: 0.6993 - precision: 0.7797 - recall: 0.6074 - val_loss: 3.6303 - val_accuracy: 0.2877 - val_precision: 0.3168 - val_recall: 0.2487\n","Epoch 516/10000\n","185/185 [==============================] - 20s 110ms/step - loss: 0.8490 - accuracy: 0.7128 - precision: 0.7972 - recall: 0.6195 - val_loss: 3.5749 - val_accuracy: 0.3019 - val_precision: 0.3353 - val_recall: 0.2543\n","Epoch 517/10000\n","185/185 [==============================] - 19s 101ms/step - loss: 0.8426 - accuracy: 0.7062 - precision: 0.7908 - recall: 0.6200 - val_loss: 3.6615 - val_accuracy: 0.2877 - val_precision: 0.3068 - val_recall: 0.2523\n","Epoch 518/10000\n","185/185 [==============================] - 19s 101ms/step - loss: 0.8535 - accuracy: 0.6989 - precision: 0.7899 - recall: 0.6136 - val_loss: 3.5603 - val_accuracy: 0.3136 - val_precision: 0.3420 - val_recall: 0.2660\n","Epoch 519/10000\n","185/185 [==============================] - 20s 107ms/step - loss: 0.8732 - accuracy: 0.6891 - precision: 0.7760 - recall: 0.6023 - val_loss: 3.6841 - val_accuracy: 0.3171 - val_precision: 0.3367 - val_recall: 0.2665\n","Epoch 520/10000\n","185/185 [==============================] - 20s 110ms/step - loss: 0.8643 - accuracy: 0.6950 - precision: 0.7846 - recall: 0.6045 - val_loss: 3.6042 - val_accuracy: 0.2943 - val_precision: 0.3253 - val_recall: 0.2528\n","Epoch 521/10000\n","185/185 [==============================] - 19s 101ms/step - loss: 0.8433 - accuracy: 0.7048 - precision: 0.7930 - recall: 0.6199 - val_loss: 3.5556 - val_accuracy: 0.2928 - val_precision: 0.3227 - val_recall: 0.2513\n","Epoch 522/10000\n","185/185 [==============================] - 20s 107ms/step - loss: 0.8390 - accuracy: 0.7081 - precision: 0.7855 - recall: 0.6200 - val_loss: 3.6444 - val_accuracy: 0.2893 - val_precision: 0.3249 - val_recall: 0.2594\n","Epoch 523/10000\n","185/185 [==============================] - 19s 104ms/step - loss: 0.8468 - accuracy: 0.7037 - precision: 0.7862 - recall: 0.6168 - val_loss: 3.6787 - val_accuracy: 0.3040 - val_precision: 0.3348 - val_recall: 0.2720\n","Epoch 524/10000\n","185/185 [==============================] - 19s 102ms/step - loss: 0.8174 - accuracy: 0.7135 - precision: 0.7972 - recall: 0.6297 - val_loss: 3.5107 - val_accuracy: 0.3050 - val_precision: 0.3364 - val_recall: 0.2619\n","Epoch 525/10000\n","185/185 [==============================] - 19s 102ms/step - loss: 0.8146 - accuracy: 0.7202 - precision: 0.7993 - recall: 0.6312 - val_loss: 3.6742 - val_accuracy: 0.3024 - val_precision: 0.3259 - val_recall: 0.2660\n","Epoch 526/10000\n","185/185 [==============================] - 20s 109ms/step - loss: 0.8457 - accuracy: 0.7008 - precision: 0.7918 - recall: 0.6199 - val_loss: 3.4905 - val_accuracy: 0.3070 - val_precision: 0.3407 - val_recall: 0.2670\n","Epoch 527/10000\n","185/185 [==============================] - 19s 101ms/step - loss: 0.8206 - accuracy: 0.7167 - precision: 0.8045 - recall: 0.6293 - val_loss: 3.7181 - val_accuracy: 0.3014 - val_precision: 0.3268 - val_recall: 0.2604\n","Epoch 528/10000\n","185/185 [==============================] - 19s 101ms/step - loss: 0.8233 - accuracy: 0.7128 - precision: 0.7987 - recall: 0.6254 - val_loss: 3.4840 - val_accuracy: 0.3131 - val_precision: 0.3437 - val_recall: 0.2690\n","Epoch 529/10000\n","185/185 [==============================] - 20s 107ms/step - loss: 0.8018 - accuracy: 0.7217 - precision: 0.8087 - recall: 0.6405 - val_loss: 3.4773 - val_accuracy: 0.2984 - val_precision: 0.3331 - val_recall: 0.2665\n","Epoch 530/10000\n","185/185 [==============================] - 20s 111ms/step - loss: 0.7978 - accuracy: 0.7187 - precision: 0.7960 - recall: 0.6347 - val_loss: 3.6293 - val_accuracy: 0.2994 - val_precision: 0.3282 - val_recall: 0.2568\n","Epoch 531/10000\n","185/185 [==============================] - 19s 101ms/step - loss: 0.8242 - accuracy: 0.7150 - precision: 0.7917 - recall: 0.6339 - val_loss: 3.4902 - val_accuracy: 0.3090 - val_precision: 0.3325 - val_recall: 0.2690\n","Epoch 532/10000\n","185/185 [==============================] - 20s 106ms/step - loss: 0.8150 - accuracy: 0.7170 - precision: 0.7948 - recall: 0.6320 - val_loss: 3.6697 - val_accuracy: 0.2994 - val_precision: 0.3263 - val_recall: 0.2503\n","Epoch 533/10000\n","185/185 [==============================] - 19s 105ms/step - loss: 0.8247 - accuracy: 0.7207 - precision: 0.8006 - recall: 0.6327 - val_loss: 3.6413 - val_accuracy: 0.2964 - val_precision: 0.3241 - val_recall: 0.2553\n","Epoch 534/10000\n","185/185 [==============================] - 19s 102ms/step - loss: 0.8084 - accuracy: 0.7189 - precision: 0.7938 - recall: 0.6310 - val_loss: 3.7051 - val_accuracy: 0.3100 - val_precision: 0.3377 - val_recall: 0.2751\n","Epoch 535/10000\n","185/185 [==============================] - 19s 101ms/step - loss: 0.8093 - accuracy: 0.7202 - precision: 0.7994 - recall: 0.6369 - val_loss: 3.7445 - val_accuracy: 0.2822 - val_precision: 0.3021 - val_recall: 0.2447\n","Epoch 536/10000\n","185/185 [==============================] - 20s 109ms/step - loss: 0.7849 - accuracy: 0.7211 - precision: 0.7998 - recall: 0.6420 - val_loss: 3.6516 - val_accuracy: 0.3034 - val_precision: 0.3296 - val_recall: 0.2670\n","Epoch 537/10000\n","185/185 [==============================] - 19s 102ms/step - loss: 0.8022 - accuracy: 0.7228 - precision: 0.7954 - recall: 0.6428 - val_loss: 3.8713 - val_accuracy: 0.2862 - val_precision: 0.3079 - val_recall: 0.2513\n","Epoch 538/10000\n","185/185 [==============================] - 19s 103ms/step - loss: 0.8188 - accuracy: 0.7111 - precision: 0.7853 - recall: 0.6283 - val_loss: 3.5841 - val_accuracy: 0.3024 - val_precision: 0.3331 - val_recall: 0.2644\n","Epoch 539/10000\n","185/185 [==============================] - 19s 102ms/step - loss: 0.7958 - accuracy: 0.7201 - precision: 0.7949 - recall: 0.6469 - val_loss: 3.7574 - val_accuracy: 0.2933 - val_precision: 0.3229 - val_recall: 0.2573\n","Epoch 540/10000\n","185/185 [==============================] - 21s 116ms/step - loss: 0.7986 - accuracy: 0.7221 - precision: 0.7997 - recall: 0.6447 - val_loss: 3.7003 - val_accuracy: 0.2979 - val_precision: 0.3248 - val_recall: 0.2584\n","Epoch 541/10000\n","185/185 [==============================] - 19s 102ms/step - loss: 0.7896 - accuracy: 0.7239 - precision: 0.7993 - recall: 0.6385 - val_loss: 3.6468 - val_accuracy: 0.2882 - val_precision: 0.3211 - val_recall: 0.2563\n","Epoch 542/10000\n","185/185 [==============================] - 19s 102ms/step - loss: 0.8130 - accuracy: 0.7174 - precision: 0.7945 - recall: 0.6435 - val_loss: 3.7020 - val_accuracy: 0.3055 - val_precision: 0.3280 - val_recall: 0.2680\n","Epoch 543/10000\n","185/185 [==============================] - 19s 101ms/step - loss: 0.8114 - accuracy: 0.7172 - precision: 0.8004 - recall: 0.6396 - val_loss: 3.6838 - val_accuracy: 0.3004 - val_precision: 0.3333 - val_recall: 0.2660\n","Epoch 544/10000\n","185/185 [==============================] - 20s 109ms/step - loss: 0.7848 - accuracy: 0.7246 - precision: 0.8046 - recall: 0.6437 - val_loss: 3.7140 - val_accuracy: 0.2837 - val_precision: 0.3112 - val_recall: 0.2492\n","Epoch 545/10000\n","185/185 [==============================] - 19s 101ms/step - loss: 0.8000 - accuracy: 0.7180 - precision: 0.7936 - recall: 0.6391 - val_loss: 3.5061 - val_accuracy: 0.3075 - val_precision: 0.3349 - val_recall: 0.2568\n","Epoch 546/10000\n","185/185 [==============================] - 19s 101ms/step - loss: 0.8169 - accuracy: 0.7170 - precision: 0.7939 - recall: 0.6351 - val_loss: 3.7150 - val_accuracy: 0.2979 - val_precision: 0.3258 - val_recall: 0.2573\n","Epoch 547/10000\n","185/185 [==============================] - 19s 105ms/step - loss: 0.7832 - accuracy: 0.7246 - precision: 0.8017 - recall: 0.6415 - val_loss: 3.6259 - val_accuracy: 0.3029 - val_precision: 0.3223 - val_recall: 0.2609\n","Epoch 548/10000\n","185/185 [==============================] - 20s 107ms/step - loss: 0.8131 - accuracy: 0.7187 - precision: 0.7944 - recall: 0.6357 - val_loss: 3.7457 - val_accuracy: 0.3009 - val_precision: 0.3325 - val_recall: 0.2720\n","Epoch 549/10000\n","185/185 [==============================] - 20s 107ms/step - loss: 0.7843 - accuracy: 0.7280 - precision: 0.8033 - recall: 0.6466 - val_loss: 3.5171 - val_accuracy: 0.3110 - val_precision: 0.3414 - val_recall: 0.2660\n","Epoch 550/10000\n","185/185 [==============================] - 19s 104ms/step - loss: 0.7774 - accuracy: 0.7251 - precision: 0.8022 - recall: 0.6467 - val_loss: 3.7021 - val_accuracy: 0.3014 - val_precision: 0.3230 - val_recall: 0.2629\n","Epoch 551/10000\n","185/185 [==============================] - 20s 109ms/step - loss: 0.7761 - accuracy: 0.7332 - precision: 0.8106 - recall: 0.6535 - val_loss: 3.7800 - val_accuracy: 0.2948 - val_precision: 0.3198 - val_recall: 0.2634\n","Epoch 552/10000\n","185/185 [==============================] - 19s 101ms/step - loss: 0.7909 - accuracy: 0.7244 - precision: 0.8031 - recall: 0.6457 - val_loss: 3.7841 - val_accuracy: 0.2857 - val_precision: 0.3117 - val_recall: 0.2528\n","Epoch 553/10000\n","185/185 [==============================] - 19s 101ms/step - loss: 0.7617 - accuracy: 0.7388 - precision: 0.8126 - recall: 0.6624 - val_loss: 3.6739 - val_accuracy: 0.3004 - val_precision: 0.3275 - val_recall: 0.2649\n","Epoch 554/10000\n","185/185 [==============================] - 19s 104ms/step - loss: 0.7669 - accuracy: 0.7354 - precision: 0.8090 - recall: 0.6525 - val_loss: 3.7152 - val_accuracy: 0.2969 - val_precision: 0.3210 - val_recall: 0.2594\n","Epoch 555/10000\n","185/185 [==============================] - 19s 105ms/step - loss: 0.7704 - accuracy: 0.7243 - precision: 0.7979 - recall: 0.6518 - val_loss: 3.9925 - val_accuracy: 0.2812 - val_precision: 0.2986 - val_recall: 0.2467\n","Epoch 556/10000\n","185/185 [==============================] - 19s 101ms/step - loss: 0.7787 - accuracy: 0.7314 - precision: 0.8131 - recall: 0.6520 - val_loss: 3.5786 - val_accuracy: 0.3034 - val_precision: 0.3342 - val_recall: 0.2619\n","Epoch 557/10000\n","185/185 [==============================] - 19s 102ms/step - loss: 0.7806 - accuracy: 0.7299 - precision: 0.8024 - recall: 0.6565 - val_loss: 3.6267 - val_accuracy: 0.3186 - val_precision: 0.3413 - val_recall: 0.2832\n","Epoch 558/10000\n","185/185 [==============================] - 19s 105ms/step - loss: 0.7725 - accuracy: 0.7290 - precision: 0.8053 - recall: 0.6521 - val_loss: 3.8054 - val_accuracy: 0.2847 - val_precision: 0.3143 - val_recall: 0.2508\n","Epoch 559/10000\n","185/185 [==============================] - 21s 114ms/step - loss: 0.7905 - accuracy: 0.7233 - precision: 0.8052 - recall: 0.6508 - val_loss: 3.8164 - val_accuracy: 0.2893 - val_precision: 0.3096 - val_recall: 0.2528\n","Epoch 560/10000\n","185/185 [==============================] - 19s 101ms/step - loss: 0.7656 - accuracy: 0.7331 - precision: 0.8070 - recall: 0.6513 - val_loss: 3.6867 - val_accuracy: 0.2989 - val_precision: 0.3284 - val_recall: 0.2589\n","Epoch 561/10000\n","185/185 [==============================] - 19s 102ms/step - loss: 0.7554 - accuracy: 0.7353 - precision: 0.8141 - recall: 0.6631 - val_loss: 3.6951 - val_accuracy: 0.2994 - val_precision: 0.3303 - val_recall: 0.2604\n","Epoch 562/10000\n","185/185 [==============================] - 19s 105ms/step - loss: 0.7562 - accuracy: 0.7369 - precision: 0.8116 - recall: 0.6665 - val_loss: 3.8785 - val_accuracy: 0.2969 - val_precision: 0.3277 - val_recall: 0.2670\n","Epoch 563/10000\n","185/185 [==============================] - 19s 105ms/step - loss: 0.7417 - accuracy: 0.7363 - precision: 0.8088 - recall: 0.6619 - val_loss: 3.6192 - val_accuracy: 0.2979 - val_precision: 0.3282 - val_recall: 0.2614\n","Epoch 564/10000\n","185/185 [==============================] - 19s 102ms/step - loss: 0.7577 - accuracy: 0.7327 - precision: 0.8043 - recall: 0.6575 - val_loss: 3.6345 - val_accuracy: 0.2928 - val_precision: 0.3245 - val_recall: 0.2619\n","Epoch 565/10000\n","185/185 [==============================] - 19s 103ms/step - loss: 0.7559 - accuracy: 0.7342 - precision: 0.8148 - recall: 0.6662 - val_loss: 3.7954 - val_accuracy: 0.2943 - val_precision: 0.3285 - val_recall: 0.2629\n","Epoch 566/10000\n","185/185 [==============================] - 21s 111ms/step - loss: 0.7555 - accuracy: 0.7375 - precision: 0.8054 - recall: 0.6663 - val_loss: 3.8830 - val_accuracy: 0.2979 - val_precision: 0.3264 - val_recall: 0.2639\n","Epoch 567/10000\n","185/185 [==============================] - 19s 103ms/step - loss: 0.7815 - accuracy: 0.7256 - precision: 0.8019 - recall: 0.6565 - val_loss: 3.8656 - val_accuracy: 0.3019 - val_precision: 0.3254 - val_recall: 0.2700\n","Epoch 568/10000\n","185/185 [==============================] - 19s 103ms/step - loss: 0.7605 - accuracy: 0.7400 - precision: 0.8078 - recall: 0.6611 - val_loss: 3.7767 - val_accuracy: 0.2888 - val_precision: 0.3218 - val_recall: 0.2548\n","Epoch 569/10000\n","185/185 [==============================] - 22s 117ms/step - loss: 0.7399 - accuracy: 0.7351 - precision: 0.8062 - recall: 0.6628 - val_loss: 3.9448 - val_accuracy: 0.2827 - val_precision: 0.3094 - val_recall: 0.2447\n","Epoch 570/10000\n","185/185 [==============================] - 19s 104ms/step - loss: 0.7299 - accuracy: 0.7403 - precision: 0.8132 - recall: 0.6621 - val_loss: 3.6699 - val_accuracy: 0.2969 - val_precision: 0.3277 - val_recall: 0.2553\n","Epoch 571/10000\n","185/185 [==============================] - 19s 104ms/step - loss: 0.7566 - accuracy: 0.7366 - precision: 0.8088 - recall: 0.6616 - val_loss: 3.7439 - val_accuracy: 0.3004 - val_precision: 0.3291 - val_recall: 0.2649\n","Epoch 572/10000\n","185/185 [==============================] - 19s 105ms/step - loss: 0.7515 - accuracy: 0.7375 - precision: 0.8171 - recall: 0.6658 - val_loss: 3.8364 - val_accuracy: 0.2852 - val_precision: 0.3103 - val_recall: 0.2523\n","Epoch 573/10000\n","185/185 [==============================] - 20s 106ms/step - loss: 0.7328 - accuracy: 0.7483 - precision: 0.8127 - recall: 0.6736 - val_loss: 3.8969 - val_accuracy: 0.3055 - val_precision: 0.3294 - val_recall: 0.2685\n","Epoch 574/10000\n","185/185 [==============================] - 19s 101ms/step - loss: 0.7199 - accuracy: 0.7555 - precision: 0.8223 - recall: 0.6815 - val_loss: 4.0213 - val_accuracy: 0.2898 - val_precision: 0.3145 - val_recall: 0.2599\n","Epoch 575/10000\n","185/185 [==============================] - 19s 102ms/step - loss: 0.7457 - accuracy: 0.7375 - precision: 0.8049 - recall: 0.6641 - val_loss: 3.9682 - val_accuracy: 0.3045 - val_precision: 0.3226 - val_recall: 0.2639\n","Epoch 576/10000\n","185/185 [==============================] - 20s 109ms/step - loss: 0.7272 - accuracy: 0.7481 - precision: 0.8169 - recall: 0.6722 - val_loss: 3.9818 - val_accuracy: 0.2974 - val_precision: 0.3206 - val_recall: 0.2685\n","Epoch 577/10000\n","185/185 [==============================] - 21s 111ms/step - loss: 0.7123 - accuracy: 0.7466 - precision: 0.8198 - recall: 0.6809 - val_loss: 3.8580 - val_accuracy: 0.2953 - val_precision: 0.3171 - val_recall: 0.2568\n","Epoch 578/10000\n","185/185 [==============================] - 19s 105ms/step - loss: 0.7441 - accuracy: 0.7369 - precision: 0.8024 - recall: 0.6650 - val_loss: 3.8629 - val_accuracy: 0.2994 - val_precision: 0.3275 - val_recall: 0.2665\n","Epoch 579/10000\n","185/185 [==============================] - 21s 113ms/step - loss: 0.7469 - accuracy: 0.7444 - precision: 0.8061 - recall: 0.6699 - val_loss: 3.8359 - val_accuracy: 0.2857 - val_precision: 0.3121 - val_recall: 0.2508\n","Epoch 580/10000\n","185/185 [==============================] - 21s 111ms/step - loss: 0.7245 - accuracy: 0.7405 - precision: 0.8134 - recall: 0.6783 - val_loss: 3.8395 - val_accuracy: 0.2953 - val_precision: 0.3225 - val_recall: 0.2609\n","Epoch 581/10000\n","185/185 [==============================] - 19s 104ms/step - loss: 0.7320 - accuracy: 0.7503 - precision: 0.8173 - recall: 0.6749 - val_loss: 3.9892 - val_accuracy: 0.3040 - val_precision: 0.3309 - val_recall: 0.2791\n","Epoch 582/10000\n","185/185 [==============================] - 19s 105ms/step - loss: 0.7120 - accuracy: 0.7469 - precision: 0.8149 - recall: 0.6814 - val_loss: 3.8306 - val_accuracy: 0.3014 - val_precision: 0.3276 - val_recall: 0.2695\n","Epoch 583/10000\n","185/185 [==============================] - 20s 109ms/step - loss: 0.7066 - accuracy: 0.7479 - precision: 0.8233 - recall: 0.6881 - val_loss: 3.8717 - val_accuracy: 0.3146 - val_precision: 0.3391 - val_recall: 0.2791\n","Epoch 584/10000\n","185/185 [==============================] - 19s 103ms/step - loss: 0.7256 - accuracy: 0.7486 - precision: 0.8102 - recall: 0.6839 - val_loss: 3.7867 - val_accuracy: 0.3040 - val_precision: 0.3275 - val_recall: 0.2746\n","Epoch 585/10000\n","185/185 [==============================] - 19s 103ms/step - loss: 0.7246 - accuracy: 0.7473 - precision: 0.8167 - recall: 0.6797 - val_loss: 4.0112 - val_accuracy: 0.2882 - val_precision: 0.3146 - val_recall: 0.2528\n","Epoch 586/10000\n","185/185 [==============================] - 19s 103ms/step - loss: 0.7255 - accuracy: 0.7496 - precision: 0.8216 - recall: 0.6771 - val_loss: 3.7625 - val_accuracy: 0.3070 - val_precision: 0.3367 - val_recall: 0.2715\n","Epoch 587/10000\n","185/185 [==============================] - 20s 110ms/step - loss: 0.7425 - accuracy: 0.7376 - precision: 0.8053 - recall: 0.6687 - val_loss: 3.9017 - val_accuracy: 0.2989 - val_precision: 0.3177 - val_recall: 0.2609\n","Epoch 588/10000\n","185/185 [==============================] - 20s 110ms/step - loss: 0.7294 - accuracy: 0.7447 - precision: 0.8081 - recall: 0.6753 - val_loss: 3.9998 - val_accuracy: 0.2882 - val_precision: 0.3074 - val_recall: 0.2604\n","Epoch 589/10000\n","185/185 [==============================] - 19s 103ms/step - loss: 0.7234 - accuracy: 0.7464 - precision: 0.8134 - recall: 0.6716 - val_loss: 3.8966 - val_accuracy: 0.3060 - val_precision: 0.3319 - val_recall: 0.2746\n","Epoch 590/10000\n","185/185 [==============================] - 20s 110ms/step - loss: 0.7131 - accuracy: 0.7506 - precision: 0.8226 - recall: 0.6825 - val_loss: 3.8709 - val_accuracy: 0.3050 - val_precision: 0.3266 - val_recall: 0.2700\n","Epoch 591/10000\n","185/185 [==============================] - 19s 103ms/step - loss: 0.7161 - accuracy: 0.7501 - precision: 0.8199 - recall: 0.6820 - val_loss: 3.8853 - val_accuracy: 0.3034 - val_precision: 0.3317 - val_recall: 0.2730\n","Epoch 592/10000\n","185/185 [==============================] - 19s 103ms/step - loss: 0.7292 - accuracy: 0.7493 - precision: 0.8182 - recall: 0.6820 - val_loss: 3.6714 - val_accuracy: 0.3181 - val_precision: 0.3447 - val_recall: 0.2806\n","Epoch 593/10000\n","185/185 [==============================] - 20s 108ms/step - loss: 0.7212 - accuracy: 0.7461 - precision: 0.8105 - recall: 0.6837 - val_loss: 3.9502 - val_accuracy: 0.3004 - val_precision: 0.3214 - val_recall: 0.2690\n","Epoch 594/10000\n","185/185 [==============================] - 20s 105ms/step - loss: 0.7115 - accuracy: 0.7525 - precision: 0.8167 - recall: 0.6825 - val_loss: 3.7708 - val_accuracy: 0.2903 - val_precision: 0.3182 - val_recall: 0.2563\n","Epoch 595/10000\n","185/185 [==============================] - 19s 103ms/step - loss: 0.6841 - accuracy: 0.7616 - precision: 0.8260 - recall: 0.6920 - val_loss: 3.8005 - val_accuracy: 0.3095 - val_precision: 0.3354 - val_recall: 0.2781\n","Epoch 596/10000\n","185/185 [==============================] - 19s 102ms/step - loss: 0.7299 - accuracy: 0.7491 - precision: 0.8179 - recall: 0.6861 - val_loss: 4.0065 - val_accuracy: 0.2812 - val_precision: 0.3022 - val_recall: 0.2538\n","Epoch 597/10000\n","185/185 [==============================] - 20s 110ms/step - loss: 0.7190 - accuracy: 0.7511 - precision: 0.8133 - recall: 0.6831 - val_loss: 4.0934 - val_accuracy: 0.2847 - val_precision: 0.3073 - val_recall: 0.2508\n","Epoch 598/10000\n","185/185 [==============================] - 21s 111ms/step - loss: 0.7412 - accuracy: 0.7473 - precision: 0.8076 - recall: 0.6780 - val_loss: 3.9861 - val_accuracy: 0.3070 - val_precision: 0.3388 - val_recall: 0.2741\n","Epoch 599/10000\n","185/185 [==============================] - 19s 102ms/step - loss: 0.6926 - accuracy: 0.7635 - precision: 0.8242 - recall: 0.6956 - val_loss: 3.9029 - val_accuracy: 0.3055 - val_precision: 0.3311 - val_recall: 0.2746\n","Epoch 600/10000\n","185/185 [==============================] - 19s 103ms/step - loss: 0.6837 - accuracy: 0.7608 - precision: 0.8273 - recall: 0.6991 - val_loss: 3.8714 - val_accuracy: 0.3075 - val_precision: 0.3305 - val_recall: 0.2720\n","Epoch 601/10000\n","185/185 [==============================] - 20s 110ms/step - loss: 0.6825 - accuracy: 0.7670 - precision: 0.8281 - recall: 0.6976 - val_loss: 3.9253 - val_accuracy: 0.2984 - val_precision: 0.3198 - val_recall: 0.2639\n","Epoch 602/10000\n","185/185 [==============================] - 19s 103ms/step - loss: 0.7038 - accuracy: 0.7483 - precision: 0.8195 - recall: 0.6832 - val_loss: 3.9260 - val_accuracy: 0.2908 - val_precision: 0.3168 - val_recall: 0.2629\n","Epoch 603/10000\n","185/185 [==============================] - 19s 102ms/step - loss: 0.6974 - accuracy: 0.7554 - precision: 0.8194 - recall: 0.6893 - val_loss: 4.0882 - val_accuracy: 0.3171 - val_precision: 0.3367 - val_recall: 0.2847\n","Epoch 604/10000\n","185/185 [==============================] - 19s 102ms/step - loss: 0.7042 - accuracy: 0.7582 - precision: 0.8216 - recall: 0.6918 - val_loss: 3.8260 - val_accuracy: 0.3024 - val_precision: 0.3287 - val_recall: 0.2741\n","Epoch 605/10000\n","185/185 [==============================] - 20s 110ms/step - loss: 0.6858 - accuracy: 0.7609 - precision: 0.8268 - recall: 0.6944 - val_loss: 3.8502 - val_accuracy: 0.3090 - val_precision: 0.3380 - val_recall: 0.2710\n","Epoch 606/10000\n","185/185 [==============================] - 19s 102ms/step - loss: 0.6670 - accuracy: 0.7701 - precision: 0.8337 - recall: 0.7020 - val_loss: 4.1044 - val_accuracy: 0.3029 - val_precision: 0.3208 - val_recall: 0.2720\n","Epoch 607/10000\n","185/185 [==============================] - 19s 103ms/step - loss: 0.6834 - accuracy: 0.7628 - precision: 0.8276 - recall: 0.6989 - val_loss: 4.1748 - val_accuracy: 0.2898 - val_precision: 0.3018 - val_recall: 0.2568\n","Epoch 608/10000\n","185/185 [==============================] - 21s 115ms/step - loss: 0.6814 - accuracy: 0.7587 - precision: 0.8267 - recall: 0.6971 - val_loss: 3.9261 - val_accuracy: 0.2964 - val_precision: 0.3179 - val_recall: 0.2614\n","Epoch 609/10000\n","185/185 [==============================] - 20s 108ms/step - loss: 0.6730 - accuracy: 0.7674 - precision: 0.8328 - recall: 0.6991 - val_loss: 3.9693 - val_accuracy: 0.2913 - val_precision: 0.3085 - val_recall: 0.2538\n","Epoch 610/10000\n","185/185 [==============================] - 19s 103ms/step - loss: 0.6932 - accuracy: 0.7576 - precision: 0.8212 - recall: 0.6966 - val_loss: 3.8757 - val_accuracy: 0.2994 - val_precision: 0.3265 - val_recall: 0.2655\n","Epoch 611/10000\n","185/185 [==============================] - 19s 102ms/step - loss: 0.6709 - accuracy: 0.7616 - precision: 0.8247 - recall: 0.7001 - val_loss: 3.8987 - val_accuracy: 0.2999 - val_precision: 0.3250 - val_recall: 0.2685\n","Epoch 612/10000\n","185/185 [==============================] - 20s 110ms/step - loss: 0.7027 - accuracy: 0.7528 - precision: 0.8183 - recall: 0.6893 - val_loss: 3.9378 - val_accuracy: 0.3055 - val_precision: 0.3223 - val_recall: 0.2675\n","Epoch 613/10000\n","185/185 [==============================] - 19s 104ms/step - loss: 0.6861 - accuracy: 0.7631 - precision: 0.8258 - recall: 0.6961 - val_loss: 3.9237 - val_accuracy: 0.3060 - val_precision: 0.3315 - val_recall: 0.2690\n","Epoch 614/10000\n","185/185 [==============================] - 19s 103ms/step - loss: 0.6779 - accuracy: 0.7623 - precision: 0.8211 - recall: 0.6947 - val_loss: 4.1432 - val_accuracy: 0.2989 - val_precision: 0.3134 - val_recall: 0.2649\n","Epoch 615/10000\n","185/185 [==============================] - 20s 108ms/step - loss: 0.6795 - accuracy: 0.7574 - precision: 0.8187 - recall: 0.6949 - val_loss: 3.9801 - val_accuracy: 0.3055 - val_precision: 0.3265 - val_recall: 0.2730\n","Epoch 616/10000\n","185/185 [==============================] - 20s 106ms/step - loss: 0.6779 - accuracy: 0.7657 - precision: 0.8222 - recall: 0.6976 - val_loss: 3.9370 - val_accuracy: 0.2938 - val_precision: 0.3150 - val_recall: 0.2589\n","Epoch 617/10000\n","185/185 [==============================] - 20s 110ms/step - loss: 0.6481 - accuracy: 0.7797 - precision: 0.8403 - recall: 0.7185 - val_loss: 4.0178 - val_accuracy: 0.3034 - val_precision: 0.3281 - val_recall: 0.2741\n","Epoch 618/10000\n","185/185 [==============================] - 20s 105ms/step - loss: 0.6713 - accuracy: 0.7672 - precision: 0.8277 - recall: 0.7011 - val_loss: 4.0636 - val_accuracy: 0.2958 - val_precision: 0.3202 - val_recall: 0.2644\n","Epoch 619/10000\n","185/185 [==============================] - 21s 111ms/step - loss: 0.6421 - accuracy: 0.7761 - precision: 0.8377 - recall: 0.7194 - val_loss: 3.8883 - val_accuracy: 0.2989 - val_precision: 0.3222 - val_recall: 0.2644\n","Epoch 620/10000\n","185/185 [==============================] - 19s 103ms/step - loss: 0.6708 - accuracy: 0.7672 - precision: 0.8274 - recall: 0.7096 - val_loss: 4.1775 - val_accuracy: 0.2928 - val_precision: 0.3093 - val_recall: 0.2655\n","Epoch 621/10000\n","185/185 [==============================] - 19s 104ms/step - loss: 0.6722 - accuracy: 0.7653 - precision: 0.8238 - recall: 0.7008 - val_loss: 3.9423 - val_accuracy: 0.3105 - val_precision: 0.3314 - val_recall: 0.2822\n","Epoch 622/10000\n","185/185 [==============================] - 21s 111ms/step - loss: 0.6511 - accuracy: 0.7709 - precision: 0.8328 - recall: 0.7096 - val_loss: 4.1553 - val_accuracy: 0.2893 - val_precision: 0.3116 - val_recall: 0.2614\n","Epoch 623/10000\n","185/185 [==============================] - 19s 105ms/step - loss: 0.6599 - accuracy: 0.7739 - precision: 0.8299 - recall: 0.7165 - val_loss: 4.1432 - val_accuracy: 0.3040 - val_precision: 0.3247 - val_recall: 0.2806\n","Epoch 624/10000\n","185/185 [==============================] - 19s 103ms/step - loss: 0.6733 - accuracy: 0.7712 - precision: 0.8256 - recall: 0.6998 - val_loss: 3.8965 - val_accuracy: 0.3024 - val_precision: 0.3307 - val_recall: 0.2730\n","Epoch 625/10000\n","185/185 [==============================] - 20s 109ms/step - loss: 0.6547 - accuracy: 0.7682 - precision: 0.8261 - recall: 0.7104 - val_loss: 4.0034 - val_accuracy: 0.2948 - val_precision: 0.3145 - val_recall: 0.2599\n","Epoch 626/10000\n","185/185 [==============================] - 19s 105ms/step - loss: 0.6659 - accuracy: 0.7689 - precision: 0.8279 - recall: 0.7077 - val_loss: 3.9983 - val_accuracy: 0.3050 - val_precision: 0.3261 - val_recall: 0.2746\n","Epoch 627/10000\n","185/185 [==============================] - 20s 110ms/step - loss: 0.6783 - accuracy: 0.7652 - precision: 0.8262 - recall: 0.7067 - val_loss: 4.0901 - val_accuracy: 0.2923 - val_precision: 0.3091 - val_recall: 0.2538\n","Epoch 628/10000\n","185/185 [==============================] - 19s 103ms/step - loss: 0.6595 - accuracy: 0.7685 - precision: 0.8260 - recall: 0.7082 - val_loss: 4.0266 - val_accuracy: 0.2877 - val_precision: 0.3133 - val_recall: 0.2584\n","Epoch 629/10000\n","185/185 [==============================] - 20s 111ms/step - loss: 0.6668 - accuracy: 0.7613 - precision: 0.8223 - recall: 0.7035 - val_loss: 3.9708 - val_accuracy: 0.3014 - val_precision: 0.3298 - val_recall: 0.2710\n","Epoch 630/10000\n","185/185 [==============================] - 19s 105ms/step - loss: 0.6313 - accuracy: 0.7809 - precision: 0.8404 - recall: 0.7207 - val_loss: 4.2380 - val_accuracy: 0.2989 - val_precision: 0.3176 - val_recall: 0.2685\n","Epoch 631/10000\n","185/185 [==============================] - 19s 105ms/step - loss: 0.6236 - accuracy: 0.7778 - precision: 0.8388 - recall: 0.7233 - val_loss: 4.0726 - val_accuracy: 0.2953 - val_precision: 0.3140 - val_recall: 0.2634\n","Epoch 632/10000\n","185/185 [==============================] - 20s 108ms/step - loss: 0.6402 - accuracy: 0.7765 - precision: 0.8294 - recall: 0.7194 - val_loss: 4.0736 - val_accuracy: 0.2989 - val_precision: 0.3184 - val_recall: 0.2665\n","Epoch 633/10000\n","185/185 [==============================] - 20s 105ms/step - loss: 0.6633 - accuracy: 0.7704 - precision: 0.8297 - recall: 0.7089 - val_loss: 3.8811 - val_accuracy: 0.2903 - val_precision: 0.3128 - val_recall: 0.2543\n","Epoch 634/10000\n","185/185 [==============================] - 19s 103ms/step - loss: 0.6279 - accuracy: 0.7767 - precision: 0.8334 - recall: 0.7192 - val_loss: 4.2776 - val_accuracy: 0.2928 - val_precision: 0.3160 - val_recall: 0.2675\n","Epoch 635/10000\n","185/185 [==============================] - 19s 102ms/step - loss: 0.6449 - accuracy: 0.7756 - precision: 0.8333 - recall: 0.7206 - val_loss: 4.1455 - val_accuracy: 0.2953 - val_precision: 0.3158 - val_recall: 0.2639\n","Epoch 636/10000\n","185/185 [==============================] - 20s 110ms/step - loss: 0.6224 - accuracy: 0.7849 - precision: 0.8420 - recall: 0.7268 - val_loss: 4.1593 - val_accuracy: 0.3085 - val_precision: 0.3306 - val_recall: 0.2812\n","Epoch 637/10000\n","185/185 [==============================] - 20s 109ms/step - loss: 0.6276 - accuracy: 0.7848 - precision: 0.8370 - recall: 0.7314 - val_loss: 4.1079 - val_accuracy: 0.3040 - val_precision: 0.3245 - val_recall: 0.2791\n","Epoch 638/10000\n","185/185 [==============================] - 19s 102ms/step - loss: 0.6379 - accuracy: 0.7800 - precision: 0.8362 - recall: 0.7260 - val_loss: 4.1390 - val_accuracy: 0.2999 - val_precision: 0.3187 - val_recall: 0.2644\n","Epoch 639/10000\n","185/185 [==============================] - 20s 108ms/step - loss: 0.6333 - accuracy: 0.7750 - precision: 0.8291 - recall: 0.7182 - val_loss: 4.1900 - val_accuracy: 0.2984 - val_precision: 0.3163 - val_recall: 0.2670\n","Epoch 640/10000\n","185/185 [==============================] - 20s 105ms/step - loss: 0.6400 - accuracy: 0.7736 - precision: 0.8303 - recall: 0.7152 - val_loss: 4.3473 - val_accuracy: 0.2806 - val_precision: 0.3013 - val_recall: 0.2543\n","Epoch 641/10000\n","185/185 [==============================] - 19s 103ms/step - loss: 0.6395 - accuracy: 0.7758 - precision: 0.8349 - recall: 0.7194 - val_loss: 4.0004 - val_accuracy: 0.3070 - val_precision: 0.3329 - val_recall: 0.2781\n","Epoch 642/10000\n","185/185 [==============================] - 19s 103ms/step - loss: 0.6342 - accuracy: 0.7824 - precision: 0.8386 - recall: 0.7239 - val_loss: 4.5487 - val_accuracy: 0.2751 - val_precision: 0.2934 - val_recall: 0.2553\n","Epoch 643/10000\n","185/185 [==============================] - 20s 110ms/step - loss: 0.6570 - accuracy: 0.7760 - precision: 0.8292 - recall: 0.7241 - val_loss: 4.0514 - val_accuracy: 0.2948 - val_precision: 0.3167 - val_recall: 0.2634\n","Epoch 644/10000\n","185/185 [==============================] - 19s 102ms/step - loss: 0.6262 - accuracy: 0.7831 - precision: 0.8379 - recall: 0.7282 - val_loss: 4.2475 - val_accuracy: 0.2857 - val_precision: 0.3120 - val_recall: 0.2639\n","Epoch 645/10000\n","185/185 [==============================] - 19s 101ms/step - loss: 0.6368 - accuracy: 0.7750 - precision: 0.8327 - recall: 0.7234 - val_loss: 3.8979 - val_accuracy: 0.3105 - val_precision: 0.3271 - val_recall: 0.2751\n","Epoch 646/10000\n","185/185 [==============================] - 19s 104ms/step - loss: 0.6249 - accuracy: 0.7868 - precision: 0.8443 - recall: 0.7277 - val_loss: 4.0896 - val_accuracy: 0.2938 - val_precision: 0.3112 - val_recall: 0.2665\n","Epoch 647/10000\n","185/185 [==============================] - 22s 120ms/step - loss: 0.6368 - accuracy: 0.7814 - precision: 0.8381 - recall: 0.7250 - val_loss: 4.1280 - val_accuracy: 0.2913 - val_precision: 0.3147 - val_recall: 0.2629\n","Epoch 648/10000\n","185/185 [==============================] - 19s 102ms/step - loss: 0.6438 - accuracy: 0.7800 - precision: 0.8384 - recall: 0.7256 - val_loss: 4.0145 - val_accuracy: 0.3156 - val_precision: 0.3314 - val_recall: 0.2822\n","Epoch 649/10000\n","185/185 [==============================] - 19s 103ms/step - loss: 0.6459 - accuracy: 0.7758 - precision: 0.8357 - recall: 0.7221 - val_loss: 4.3894 - val_accuracy: 0.2974 - val_precision: 0.3140 - val_recall: 0.2660\n","Epoch 650/10000\n","185/185 [==============================] - 20s 109ms/step - loss: 0.6292 - accuracy: 0.7817 - precision: 0.8315 - recall: 0.7261 - val_loss: 3.9489 - val_accuracy: 0.3019 - val_precision: 0.3204 - val_recall: 0.2634\n","Epoch 651/10000\n","185/185 [==============================] - 19s 105ms/step - loss: 0.6562 - accuracy: 0.7718 - precision: 0.8329 - recall: 0.7140 - val_loss: 3.9754 - val_accuracy: 0.2989 - val_precision: 0.3237 - val_recall: 0.2680\n","Epoch 652/10000\n","185/185 [==============================] - 19s 103ms/step - loss: 0.6331 - accuracy: 0.7822 - precision: 0.8353 - recall: 0.7268 - val_loss: 4.2895 - val_accuracy: 0.2994 - val_precision: 0.3223 - val_recall: 0.2715\n","Epoch 653/10000\n","185/185 [==============================] - 19s 103ms/step - loss: 0.6312 - accuracy: 0.7763 - precision: 0.8318 - recall: 0.7211 - val_loss: 4.1150 - val_accuracy: 0.2903 - val_precision: 0.3201 - val_recall: 0.2649\n","Epoch 654/10000\n","185/185 [==============================] - 20s 111ms/step - loss: 0.6386 - accuracy: 0.7768 - precision: 0.8323 - recall: 0.7229 - val_loss: 4.1452 - val_accuracy: 0.2969 - val_precision: 0.3191 - val_recall: 0.2695\n","Epoch 655/10000\n","185/185 [==============================] - 19s 103ms/step - loss: 0.6126 - accuracy: 0.7853 - precision: 0.8430 - recall: 0.7319 - val_loss: 4.1633 - val_accuracy: 0.3009 - val_precision: 0.3234 - val_recall: 0.2705\n","Epoch 656/10000\n","185/185 [==============================] - 20s 110ms/step - loss: 0.5789 - accuracy: 0.7973 - precision: 0.8520 - recall: 0.7418 - val_loss: 4.1512 - val_accuracy: 0.2958 - val_precision: 0.3147 - val_recall: 0.2705\n","Epoch 657/10000\n","185/185 [==============================] - 21s 111ms/step - loss: 0.6191 - accuracy: 0.7881 - precision: 0.8412 - recall: 0.7368 - val_loss: 4.0687 - val_accuracy: 0.3121 - val_precision: 0.3291 - val_recall: 0.2756\n","Epoch 658/10000\n","185/185 [==============================] - 19s 104ms/step - loss: 0.5941 - accuracy: 0.7890 - precision: 0.8432 - recall: 0.7361 - val_loss: 4.1901 - val_accuracy: 0.2938 - val_precision: 0.3153 - val_recall: 0.2685\n","Epoch 659/10000\n","185/185 [==============================] - 19s 102ms/step - loss: 0.6033 - accuracy: 0.7912 - precision: 0.8453 - recall: 0.7378 - val_loss: 4.4500 - val_accuracy: 0.2842 - val_precision: 0.3012 - val_recall: 0.2584\n","Epoch 660/10000\n","185/185 [==============================] - 19s 103ms/step - loss: 0.5981 - accuracy: 0.7880 - precision: 0.8412 - recall: 0.7373 - val_loss: 4.2183 - val_accuracy: 0.3009 - val_precision: 0.3198 - val_recall: 0.2715\n","Epoch 661/10000\n","185/185 [==============================] - 20s 110ms/step - loss: 0.6060 - accuracy: 0.7895 - precision: 0.8404 - recall: 0.7368 - val_loss: 4.2750 - val_accuracy: 0.2903 - val_precision: 0.3144 - val_recall: 0.2634\n","Epoch 662/10000\n","185/185 [==============================] - 19s 103ms/step - loss: 0.6187 - accuracy: 0.7856 - precision: 0.8377 - recall: 0.7324 - val_loss: 4.1964 - val_accuracy: 0.3080 - val_precision: 0.3247 - val_recall: 0.2786\n","Epoch 663/10000\n","185/185 [==============================] - 19s 103ms/step - loss: 0.6027 - accuracy: 0.7895 - precision: 0.8442 - recall: 0.7376 - val_loss: 4.2675 - val_accuracy: 0.2872 - val_precision: 0.3096 - val_recall: 0.2619\n","Epoch 664/10000\n","185/185 [==============================] - 20s 109ms/step - loss: 0.5929 - accuracy: 0.7922 - precision: 0.8503 - recall: 0.7420 - val_loss: 4.4193 - val_accuracy: 0.2913 - val_precision: 0.3101 - val_recall: 0.2680\n","Epoch 665/10000\n","185/185 [==============================] - 19s 105ms/step - loss: 0.6099 - accuracy: 0.7832 - precision: 0.8335 - recall: 0.7315 - val_loss: 4.1540 - val_accuracy: 0.3065 - val_precision: 0.3265 - val_recall: 0.2746\n","Epoch 666/10000\n","185/185 [==============================] - 20s 111ms/step - loss: 0.6009 - accuracy: 0.7900 - precision: 0.8430 - recall: 0.7376 - val_loss: 4.1952 - val_accuracy: 0.3004 - val_precision: 0.3285 - val_recall: 0.2736\n","Epoch 667/10000\n","185/185 [==============================] - 19s 103ms/step - loss: 0.6192 - accuracy: 0.7851 - precision: 0.8381 - recall: 0.7354 - val_loss: 4.1345 - val_accuracy: 0.2943 - val_precision: 0.3228 - val_recall: 0.2690\n","Epoch 668/10000\n","185/185 [==============================] - 19s 104ms/step - loss: 0.5769 - accuracy: 0.8001 - precision: 0.8543 - recall: 0.7506 - val_loss: 4.1504 - val_accuracy: 0.2918 - val_precision: 0.3146 - val_recall: 0.2634\n","Epoch 669/10000\n","185/185 [==============================] - 20s 111ms/step - loss: 0.5954 - accuracy: 0.7998 - precision: 0.8448 - recall: 0.7486 - val_loss: 4.2957 - val_accuracy: 0.2979 - val_precision: 0.3215 - val_recall: 0.2715\n","Epoch 670/10000\n","185/185 [==============================] - 19s 104ms/step - loss: 0.5753 - accuracy: 0.8022 - precision: 0.8539 - recall: 0.7476 - val_loss: 4.2402 - val_accuracy: 0.2933 - val_precision: 0.3173 - val_recall: 0.2675\n","Epoch 671/10000\n","185/185 [==============================] - 19s 104ms/step - loss: 0.5820 - accuracy: 0.7984 - precision: 0.8531 - recall: 0.7506 - val_loss: 4.4064 - val_accuracy: 0.2923 - val_precision: 0.3160 - val_recall: 0.2715\n","Epoch 672/10000\n","185/185 [==============================] - 20s 110ms/step - loss: 0.6081 - accuracy: 0.7905 - precision: 0.8398 - recall: 0.7397 - val_loss: 4.1088 - val_accuracy: 0.3029 - val_precision: 0.3227 - val_recall: 0.2771\n","Epoch 673/10000\n","185/185 [==============================] - 19s 105ms/step - loss: 0.5757 - accuracy: 0.7981 - precision: 0.8508 - recall: 0.7486 - val_loss: 4.2243 - val_accuracy: 0.3050 - val_precision: 0.3245 - val_recall: 0.2741\n","Epoch 674/10000\n","185/185 [==============================] - 19s 104ms/step - loss: 0.5696 - accuracy: 0.7974 - precision: 0.8502 - recall: 0.7481 - val_loss: 4.0989 - val_accuracy: 0.3024 - val_precision: 0.3244 - val_recall: 0.2746\n","Epoch 675/10000\n","185/185 [==============================] - 19s 104ms/step - loss: 0.5787 - accuracy: 0.7979 - precision: 0.8504 - recall: 0.7513 - val_loss: 4.1401 - val_accuracy: 0.2969 - val_precision: 0.3242 - val_recall: 0.2746\n","Epoch 676/10000\n","185/185 [==============================] - 22s 121ms/step - loss: 0.5858 - accuracy: 0.7885 - precision: 0.8422 - recall: 0.7429 - val_loss: 4.3624 - val_accuracy: 0.2867 - val_precision: 0.3000 - val_recall: 0.2553\n","Epoch 677/10000\n","185/185 [==============================] - 19s 105ms/step - loss: 0.5737 - accuracy: 0.8018 - precision: 0.8506 - recall: 0.7549 - val_loss: 4.2558 - val_accuracy: 0.3019 - val_precision: 0.3197 - val_recall: 0.2685\n","Epoch 678/10000\n","185/185 [==============================] - 19s 104ms/step - loss: 0.5775 - accuracy: 0.8005 - precision: 0.8518 - recall: 0.7528 - val_loss: 4.2095 - val_accuracy: 0.3050 - val_precision: 0.3280 - val_recall: 0.2781\n","Epoch 679/10000\n","185/185 [==============================] - 20s 110ms/step - loss: 0.5811 - accuracy: 0.7971 - precision: 0.8485 - recall: 0.7503 - val_loss: 4.3164 - val_accuracy: 0.3009 - val_precision: 0.3233 - val_recall: 0.2766\n","Epoch 680/10000\n","185/185 [==============================] - 20s 108ms/step - loss: 0.5651 - accuracy: 0.8059 - precision: 0.8571 - recall: 0.7589 - val_loss: 4.2691 - val_accuracy: 0.3090 - val_precision: 0.3278 - val_recall: 0.2822\n","Epoch 681/10000\n","185/185 [==============================] - 19s 104ms/step - loss: 0.5850 - accuracy: 0.7998 - precision: 0.8504 - recall: 0.7498 - val_loss: 4.4333 - val_accuracy: 0.2918 - val_precision: 0.3084 - val_recall: 0.2649\n","Epoch 682/10000\n","185/185 [==============================] - 19s 105ms/step - loss: 0.5934 - accuracy: 0.7947 - precision: 0.8459 - recall: 0.7456 - val_loss: 4.3645 - val_accuracy: 0.2918 - val_precision: 0.3111 - val_recall: 0.2690\n","Epoch 683/10000\n","185/185 [==============================] - 21s 111ms/step - loss: 0.5913 - accuracy: 0.7983 - precision: 0.8409 - recall: 0.7474 - val_loss: 4.1902 - val_accuracy: 0.2969 - val_precision: 0.3179 - val_recall: 0.2649\n","Epoch 684/10000\n","185/185 [==============================] - 19s 104ms/step - loss: 0.5714 - accuracy: 0.7962 - precision: 0.8465 - recall: 0.7481 - val_loss: 4.3662 - val_accuracy: 0.2943 - val_precision: 0.3171 - val_recall: 0.2700\n","Epoch 685/10000\n","185/185 [==============================] - 21s 111ms/step - loss: 0.5803 - accuracy: 0.7974 - precision: 0.8441 - recall: 0.7501 - val_loss: 4.2555 - val_accuracy: 0.3050 - val_precision: 0.3292 - val_recall: 0.2842\n","Epoch 686/10000\n","185/185 [==============================] - 21s 112ms/step - loss: 0.5982 - accuracy: 0.7876 - precision: 0.8384 - recall: 0.7407 - val_loss: 4.2757 - val_accuracy: 0.2994 - val_precision: 0.3177 - val_recall: 0.2680\n","Epoch 687/10000\n","185/185 [==============================] - 19s 104ms/step - loss: 0.5634 - accuracy: 0.8084 - precision: 0.8577 - recall: 0.7628 - val_loss: 4.3471 - val_accuracy: 0.2943 - val_precision: 0.3092 - val_recall: 0.2634\n","Epoch 688/10000\n","185/185 [==============================] - 19s 104ms/step - loss: 0.5871 - accuracy: 0.8023 - precision: 0.8469 - recall: 0.7532 - val_loss: 4.2161 - val_accuracy: 0.3105 - val_precision: 0.3286 - val_recall: 0.2822\n","Epoch 689/10000\n","185/185 [==============================] - 20s 109ms/step - loss: 0.5721 - accuracy: 0.7986 - precision: 0.8429 - recall: 0.7503 - val_loss: 4.2982 - val_accuracy: 0.3019 - val_precision: 0.3179 - val_recall: 0.2741\n","Epoch 690/10000\n","185/185 [==============================] - 20s 106ms/step - loss: 0.5856 - accuracy: 0.7927 - precision: 0.8410 - recall: 0.7459 - val_loss: 4.2334 - val_accuracy: 0.2938 - val_precision: 0.3129 - val_recall: 0.2670\n","Epoch 691/10000\n","185/185 [==============================] - 19s 104ms/step - loss: 0.5839 - accuracy: 0.7996 - precision: 0.8485 - recall: 0.7503 - val_loss: 4.2224 - val_accuracy: 0.3045 - val_precision: 0.3246 - val_recall: 0.2776\n","Epoch 692/10000\n","185/185 [==============================] - 19s 104ms/step - loss: 0.5691 - accuracy: 0.7995 - precision: 0.8488 - recall: 0.7511 - val_loss: 4.2632 - val_accuracy: 0.2958 - val_precision: 0.3185 - val_recall: 0.2690\n","Epoch 693/10000\n","185/185 [==============================] - 20s 109ms/step - loss: 0.5650 - accuracy: 0.8040 - precision: 0.8466 - recall: 0.7535 - val_loss: 4.2576 - val_accuracy: 0.3080 - val_precision: 0.3278 - val_recall: 0.2817\n","Epoch 694/10000\n","185/185 [==============================] - 19s 104ms/step - loss: 0.5528 - accuracy: 0.8099 - precision: 0.8599 - recall: 0.7609 - val_loss: 4.2313 - val_accuracy: 0.2958 - val_precision: 0.3144 - val_recall: 0.2670\n","Epoch 695/10000\n","185/185 [==============================] - 21s 113ms/step - loss: 0.5711 - accuracy: 0.8040 - precision: 0.8491 - recall: 0.7528 - val_loss: 4.3588 - val_accuracy: 0.2903 - val_precision: 0.3145 - val_recall: 0.2680\n","Epoch 696/10000\n","185/185 [==============================] - 19s 104ms/step - loss: 0.5806 - accuracy: 0.7973 - precision: 0.8464 - recall: 0.7544 - val_loss: 4.2661 - val_accuracy: 0.3040 - val_precision: 0.3206 - val_recall: 0.2761\n","Epoch 697/10000\n","185/185 [==============================] - 20s 106ms/step - loss: 0.5543 - accuracy: 0.8069 - precision: 0.8500 - recall: 0.7576 - val_loss: 4.3061 - val_accuracy: 0.2979 - val_precision: 0.3180 - val_recall: 0.2705\n","Epoch 698/10000\n","185/185 [==============================] - 20s 108ms/step - loss: 0.5627 - accuracy: 0.8020 - precision: 0.8531 - recall: 0.7564 - val_loss: 4.4371 - val_accuracy: 0.2862 - val_precision: 0.3077 - val_recall: 0.2680\n","Epoch 699/10000\n","185/185 [==============================] - 19s 104ms/step - loss: 0.5729 - accuracy: 0.8050 - precision: 0.8543 - recall: 0.7576 - val_loss: 4.4348 - val_accuracy: 0.2969 - val_precision: 0.3141 - val_recall: 0.2725\n","Epoch 700/10000\n","185/185 [==============================] - 19s 103ms/step - loss: 0.5624 - accuracy: 0.8050 - precision: 0.8495 - recall: 0.7601 - val_loss: 4.2138 - val_accuracy: 0.2923 - val_precision: 0.3097 - val_recall: 0.2594\n","Epoch 701/10000\n","185/185 [==============================] - 21s 111ms/step - loss: 0.5886 - accuracy: 0.7932 - precision: 0.8445 - recall: 0.7452 - val_loss: 4.1311 - val_accuracy: 0.3014 - val_precision: 0.3202 - val_recall: 0.2725\n","Epoch 702/10000\n","185/185 [==============================] - 19s 103ms/step - loss: 0.5705 - accuracy: 0.7978 - precision: 0.8455 - recall: 0.7533 - val_loss: 4.4269 - val_accuracy: 0.2979 - val_precision: 0.3132 - val_recall: 0.2680\n","Epoch 703/10000\n","185/185 [==============================] - 19s 104ms/step - loss: 0.5377 - accuracy: 0.8162 - precision: 0.8633 - recall: 0.7701 - val_loss: 4.3644 - val_accuracy: 0.2908 - val_precision: 0.3063 - val_recall: 0.2655\n","Epoch 704/10000\n","185/185 [==============================] - 20s 109ms/step - loss: 0.5452 - accuracy: 0.8072 - precision: 0.8568 - recall: 0.7633 - val_loss: 4.1850 - val_accuracy: 0.2928 - val_precision: 0.3131 - val_recall: 0.2609\n","Epoch 705/10000\n","185/185 [==============================] - 21s 113ms/step - loss: 0.5463 - accuracy: 0.8099 - precision: 0.8575 - recall: 0.7679 - val_loss: 4.3617 - val_accuracy: 0.3085 - val_precision: 0.3260 - val_recall: 0.2781\n","Epoch 706/10000\n","185/185 [==============================] - 19s 104ms/step - loss: 0.5697 - accuracy: 0.8015 - precision: 0.8510 - recall: 0.7565 - val_loss: 4.2648 - val_accuracy: 0.2938 - val_precision: 0.3176 - val_recall: 0.2736\n","Epoch 707/10000\n","185/185 [==============================] - 20s 108ms/step - loss: 0.5491 - accuracy: 0.8032 - precision: 0.8513 - recall: 0.7584 - val_loss: 4.4903 - val_accuracy: 0.2974 - val_precision: 0.3129 - val_recall: 0.2685\n","Epoch 708/10000\n","185/185 [==============================] - 21s 111ms/step - loss: 0.5525 - accuracy: 0.8111 - precision: 0.8540 - recall: 0.7669 - val_loss: 4.4684 - val_accuracy: 0.2974 - val_precision: 0.3148 - val_recall: 0.2700\n","Epoch 709/10000\n","185/185 [==============================] - 19s 105ms/step - loss: 0.5444 - accuracy: 0.8108 - precision: 0.8590 - recall: 0.7665 - val_loss: 4.2333 - val_accuracy: 0.2984 - val_precision: 0.3164 - val_recall: 0.2720\n","Epoch 710/10000\n","185/185 [==============================] - 19s 105ms/step - loss: 0.5558 - accuracy: 0.8079 - precision: 0.8521 - recall: 0.7611 - val_loss: 4.3490 - val_accuracy: 0.3009 - val_precision: 0.3232 - val_recall: 0.2746\n","Epoch 711/10000\n","185/185 [==============================] - 21s 112ms/step - loss: 0.5551 - accuracy: 0.8005 - precision: 0.8446 - recall: 0.7565 - val_loss: 4.2422 - val_accuracy: 0.3024 - val_precision: 0.3208 - val_recall: 0.2812\n","Epoch 712/10000\n","185/185 [==============================] - 20s 106ms/step - loss: 0.5532 - accuracy: 0.8066 - precision: 0.8521 - recall: 0.7623 - val_loss: 4.4382 - val_accuracy: 0.3040 - val_precision: 0.3197 - val_recall: 0.2812\n","Epoch 713/10000\n","185/185 [==============================] - 20s 107ms/step - loss: 0.5430 - accuracy: 0.8130 - precision: 0.8582 - recall: 0.7692 - val_loss: 4.2399 - val_accuracy: 0.2943 - val_precision: 0.3104 - val_recall: 0.2680\n","Epoch 714/10000\n","185/185 [==============================] - 21s 115ms/step - loss: 0.5493 - accuracy: 0.8067 - precision: 0.8542 - recall: 0.7633 - val_loss: 4.5541 - val_accuracy: 0.2893 - val_precision: 0.3048 - val_recall: 0.2634\n","Epoch 715/10000\n","185/185 [==============================] - 21s 114ms/step - loss: 0.5189 - accuracy: 0.8186 - precision: 0.8643 - recall: 0.7756 - val_loss: 4.4489 - val_accuracy: 0.2918 - val_precision: 0.3087 - val_recall: 0.2649\n","Epoch 716/10000\n","185/185 [==============================] - 19s 105ms/step - loss: 0.5217 - accuracy: 0.8180 - precision: 0.8648 - recall: 0.7738 - val_loss: 4.4384 - val_accuracy: 0.3100 - val_precision: 0.3308 - val_recall: 0.2852\n","Epoch 717/10000\n","185/185 [==============================] - 19s 104ms/step - loss: 0.5209 - accuracy: 0.8201 - precision: 0.8619 - recall: 0.7780 - val_loss: 4.2849 - val_accuracy: 0.2984 - val_precision: 0.3181 - val_recall: 0.2685\n","Epoch 718/10000\n","185/185 [==============================] - 21s 111ms/step - loss: 0.5239 - accuracy: 0.8157 - precision: 0.8627 - recall: 0.7675 - val_loss: 4.6756 - val_accuracy: 0.2918 - val_precision: 0.3117 - val_recall: 0.2700\n","Epoch 719/10000\n","185/185 [==============================] - 19s 105ms/step - loss: 0.5453 - accuracy: 0.8072 - precision: 0.8567 - recall: 0.7645 - val_loss: 4.3444 - val_accuracy: 0.2948 - val_precision: 0.3171 - val_recall: 0.2705\n","Epoch 720/10000\n","185/185 [==============================] - 19s 104ms/step - loss: 0.5424 - accuracy: 0.8104 - precision: 0.8571 - recall: 0.7679 - val_loss: 4.6124 - val_accuracy: 0.2791 - val_precision: 0.2932 - val_recall: 0.2492\n","Epoch 721/10000\n","185/185 [==============================] - 20s 106ms/step - loss: 0.5233 - accuracy: 0.8197 - precision: 0.8615 - recall: 0.7785 - val_loss: 4.3996 - val_accuracy: 0.3004 - val_precision: 0.3163 - val_recall: 0.2761\n","Epoch 722/10000\n","185/185 [==============================] - 21s 113ms/step - loss: 0.5236 - accuracy: 0.8138 - precision: 0.8568 - recall: 0.7716 - val_loss: 4.5640 - val_accuracy: 0.2817 - val_precision: 0.3021 - val_recall: 0.2584\n","Epoch 723/10000\n","185/185 [==============================] - 20s 106ms/step - loss: 0.5130 - accuracy: 0.8229 - precision: 0.8655 - recall: 0.7848 - val_loss: 4.4121 - val_accuracy: 0.2837 - val_precision: 0.3013 - val_recall: 0.2609\n","Epoch 724/10000\n","185/185 [==============================] - 20s 111ms/step - loss: 0.5102 - accuracy: 0.8158 - precision: 0.8583 - recall: 0.7800 - val_loss: 4.3121 - val_accuracy: 0.2943 - val_precision: 0.3205 - val_recall: 0.2690\n","Epoch 725/10000\n","185/185 [==============================] - 21s 113ms/step - loss: 0.5316 - accuracy: 0.8172 - precision: 0.8623 - recall: 0.7746 - val_loss: 4.6773 - val_accuracy: 0.2888 - val_precision: 0.3076 - val_recall: 0.2639\n","Epoch 726/10000\n","185/185 [==============================] - 19s 105ms/step - loss: 0.5403 - accuracy: 0.8128 - precision: 0.8547 - recall: 0.7714 - val_loss: 4.4101 - val_accuracy: 0.3029 - val_precision: 0.3166 - val_recall: 0.2710\n","Epoch 727/10000\n","185/185 [==============================] - 19s 104ms/step - loss: 0.5493 - accuracy: 0.8147 - precision: 0.8548 - recall: 0.7709 - val_loss: 4.4508 - val_accuracy: 0.3040 - val_precision: 0.3173 - val_recall: 0.2771\n","Epoch 728/10000\n","185/185 [==============================] - 21s 112ms/step - loss: 0.5419 - accuracy: 0.8093 - precision: 0.8504 - recall: 0.7657 - val_loss: 4.4857 - val_accuracy: 0.3034 - val_precision: 0.3182 - val_recall: 0.2761\n","Epoch 729/10000\n","185/185 [==============================] - 20s 106ms/step - loss: 0.5260 - accuracy: 0.8207 - precision: 0.8664 - recall: 0.7756 - val_loss: 4.4072 - val_accuracy: 0.2882 - val_precision: 0.3060 - val_recall: 0.2609\n","Epoch 730/10000\n","185/185 [==============================] - 19s 105ms/step - loss: 0.5397 - accuracy: 0.8104 - precision: 0.8561 - recall: 0.7701 - val_loss: 4.6467 - val_accuracy: 0.2832 - val_precision: 0.3033 - val_recall: 0.2639\n","Epoch 731/10000\n","185/185 [==============================] - 20s 106ms/step - loss: 0.5422 - accuracy: 0.8116 - precision: 0.8561 - recall: 0.7718 - val_loss: 4.6123 - val_accuracy: 0.2958 - val_precision: 0.3093 - val_recall: 0.2649\n","Epoch 732/10000\n","185/185 [==============================] - 21s 112ms/step - loss: 0.5274 - accuracy: 0.8135 - precision: 0.8555 - recall: 0.7729 - val_loss: 4.4282 - val_accuracy: 0.2877 - val_precision: 0.3046 - val_recall: 0.2629\n","Epoch 733/10000\n","185/185 [==============================] - 19s 104ms/step - loss: 0.5392 - accuracy: 0.8108 - precision: 0.8535 - recall: 0.7677 - val_loss: 4.4421 - val_accuracy: 0.2877 - val_precision: 0.3071 - val_recall: 0.2573\n","Epoch 734/10000\n","185/185 [==============================] - 21s 113ms/step - loss: 0.5120 - accuracy: 0.8243 - precision: 0.8665 - recall: 0.7805 - val_loss: 4.4543 - val_accuracy: 0.2974 - val_precision: 0.3167 - val_recall: 0.2730\n","Epoch 735/10000\n","185/185 [==============================] - 19s 105ms/step - loss: 0.5321 - accuracy: 0.8140 - precision: 0.8573 - recall: 0.7745 - val_loss: 4.2896 - val_accuracy: 0.2847 - val_precision: 0.3033 - val_recall: 0.2579\n","Epoch 736/10000\n","185/185 [==============================] - 21s 112ms/step - loss: 0.5332 - accuracy: 0.8160 - precision: 0.8584 - recall: 0.7714 - val_loss: 4.4407 - val_accuracy: 0.2974 - val_precision: 0.3127 - val_recall: 0.2690\n","Epoch 737/10000\n","185/185 [==============================] - 19s 104ms/step - loss: 0.5119 - accuracy: 0.8226 - precision: 0.8665 - recall: 0.7839 - val_loss: 4.4746 - val_accuracy: 0.2933 - val_precision: 0.3071 - val_recall: 0.2690\n","Epoch 738/10000\n","185/185 [==============================] - 19s 104ms/step - loss: 0.5261 - accuracy: 0.8126 - precision: 0.8601 - recall: 0.7738 - val_loss: 4.4423 - val_accuracy: 0.3060 - val_precision: 0.3220 - val_recall: 0.2786\n","Epoch 739/10000\n","185/185 [==============================] - 20s 109ms/step - loss: 0.5344 - accuracy: 0.8186 - precision: 0.8574 - recall: 0.7707 - val_loss: 4.5749 - val_accuracy: 0.2923 - val_precision: 0.3106 - val_recall: 0.2695\n","Epoch 740/10000\n","185/185 [==============================] - 20s 108ms/step - loss: 0.5080 - accuracy: 0.8253 - precision: 0.8682 - recall: 0.7858 - val_loss: 4.3591 - val_accuracy: 0.3110 - val_precision: 0.3314 - val_recall: 0.2888\n","Epoch 741/10000\n","185/185 [==============================] - 19s 103ms/step - loss: 0.5011 - accuracy: 0.8231 - precision: 0.8649 - recall: 0.7800 - val_loss: 4.5687 - val_accuracy: 0.2928 - val_precision: 0.3124 - val_recall: 0.2670\n","Epoch 742/10000\n","185/185 [==============================] - 19s 104ms/step - loss: 0.4938 - accuracy: 0.8253 - precision: 0.8655 - recall: 0.7831 - val_loss: 4.3768 - val_accuracy: 0.3070 - val_precision: 0.3259 - val_recall: 0.2817\n","Epoch 743/10000\n","185/185 [==============================] - 20s 110ms/step - loss: 0.4859 - accuracy: 0.8321 - precision: 0.8720 - recall: 0.7941 - val_loss: 4.5490 - val_accuracy: 0.2953 - val_precision: 0.3157 - val_recall: 0.2751\n","Epoch 744/10000\n","185/185 [==============================] - 21s 115ms/step - loss: 0.5192 - accuracy: 0.8206 - precision: 0.8621 - recall: 0.7782 - val_loss: 4.6813 - val_accuracy: 0.2994 - val_precision: 0.3151 - val_recall: 0.2736\n","Epoch 745/10000\n","185/185 [==============================] - 19s 104ms/step - loss: 0.4822 - accuracy: 0.8312 - precision: 0.8716 - recall: 0.7905 - val_loss: 4.6280 - val_accuracy: 0.2928 - val_precision: 0.3087 - val_recall: 0.2690\n","Epoch 746/10000\n","185/185 [==============================] - 19s 103ms/step - loss: 0.5213 - accuracy: 0.8179 - precision: 0.8591 - recall: 0.7770 - val_loss: 4.3868 - val_accuracy: 0.3095 - val_precision: 0.3290 - val_recall: 0.2827\n","Epoch 747/10000\n","185/185 [==============================] - 21s 112ms/step - loss: 0.4833 - accuracy: 0.8343 - precision: 0.8778 - recall: 0.7976 - val_loss: 4.6152 - val_accuracy: 0.2953 - val_precision: 0.3062 - val_recall: 0.2665\n","Epoch 748/10000\n","185/185 [==============================] - 20s 105ms/step - loss: 0.5181 - accuracy: 0.8115 - precision: 0.8542 - recall: 0.7748 - val_loss: 4.5017 - val_accuracy: 0.2974 - val_precision: 0.3132 - val_recall: 0.2710\n","Epoch 749/10000\n","185/185 [==============================] - 19s 104ms/step - loss: 0.5220 - accuracy: 0.8240 - precision: 0.8625 - recall: 0.7843 - val_loss: 4.5193 - val_accuracy: 0.2928 - val_precision: 0.3114 - val_recall: 0.2639\n","Epoch 750/10000\n","185/185 [==============================] - 19s 104ms/step - loss: 0.5313 - accuracy: 0.8096 - precision: 0.8515 - recall: 0.7743 - val_loss: 4.4778 - val_accuracy: 0.2923 - val_precision: 0.3062 - val_recall: 0.2690\n","Epoch 751/10000\n","185/185 [==============================] - 21s 113ms/step - loss: 0.5141 - accuracy: 0.8187 - precision: 0.8659 - recall: 0.7809 - val_loss: 4.6829 - val_accuracy: 0.2933 - val_precision: 0.3101 - val_recall: 0.2710\n","Epoch 752/10000\n","185/185 [==============================] - 19s 105ms/step - loss: 0.5324 - accuracy: 0.8138 - precision: 0.8543 - recall: 0.7775 - val_loss: 4.5298 - val_accuracy: 0.2872 - val_precision: 0.3103 - val_recall: 0.2639\n","Epoch 753/10000\n","185/185 [==============================] - 21s 112ms/step - loss: 0.4895 - accuracy: 0.8273 - precision: 0.8701 - recall: 0.7878 - val_loss: 4.5078 - val_accuracy: 0.3004 - val_precision: 0.3151 - val_recall: 0.2746\n","Epoch 754/10000\n","185/185 [==============================] - 21s 111ms/step - loss: 0.4955 - accuracy: 0.8283 - precision: 0.8681 - recall: 0.7886 - val_loss: 4.6133 - val_accuracy: 0.2852 - val_precision: 0.3002 - val_recall: 0.2573\n","Epoch 755/10000\n","185/185 [==============================] - 19s 105ms/step - loss: 0.4972 - accuracy: 0.8189 - precision: 0.8617 - recall: 0.7831 - val_loss: 4.5147 - val_accuracy: 0.2979 - val_precision: 0.3120 - val_recall: 0.2736\n","Epoch 756/10000\n","185/185 [==============================] - 19s 103ms/step - loss: 0.4997 - accuracy: 0.8299 - precision: 0.8686 - recall: 0.7886 - val_loss: 4.3990 - val_accuracy: 0.3009 - val_precision: 0.3276 - val_recall: 0.2817\n","Epoch 757/10000\n","185/185 [==============================] - 19s 105ms/step - loss: 0.5218 - accuracy: 0.8164 - precision: 0.8588 - recall: 0.7768 - val_loss: 4.4509 - val_accuracy: 0.3075 - val_precision: 0.3276 - val_recall: 0.2812\n","Epoch 758/10000\n","185/185 [==============================] - 21s 111ms/step - loss: 0.4915 - accuracy: 0.8305 - precision: 0.8679 - recall: 0.7905 - val_loss: 4.5827 - val_accuracy: 0.3085 - val_precision: 0.3197 - val_recall: 0.2817\n","Epoch 759/10000\n","185/185 [==============================] - 19s 104ms/step - loss: 0.5055 - accuracy: 0.8280 - precision: 0.8661 - recall: 0.7881 - val_loss: 4.5112 - val_accuracy: 0.2979 - val_precision: 0.3093 - val_recall: 0.2695\n","Epoch 760/10000\n","185/185 [==============================] - 19s 105ms/step - loss: 0.4802 - accuracy: 0.8334 - precision: 0.8719 - recall: 0.7956 - val_loss: 4.4615 - val_accuracy: 0.3014 - val_precision: 0.3191 - val_recall: 0.2736\n","Epoch 761/10000\n","185/185 [==============================] - 21s 113ms/step - loss: 0.5021 - accuracy: 0.8204 - precision: 0.8586 - recall: 0.7856 - val_loss: 4.5574 - val_accuracy: 0.2979 - val_precision: 0.3176 - val_recall: 0.2786\n","Epoch 762/10000\n","185/185 [==============================] - 20s 106ms/step - loss: 0.4806 - accuracy: 0.8275 - precision: 0.8685 - recall: 0.7942 - val_loss: 4.5865 - val_accuracy: 0.2974 - val_precision: 0.3126 - val_recall: 0.2730\n","Epoch 763/10000\n","185/185 [==============================] - 21s 113ms/step - loss: 0.4924 - accuracy: 0.8277 - precision: 0.8657 - recall: 0.7925 - val_loss: 4.4962 - val_accuracy: 0.2994 - val_precision: 0.3192 - val_recall: 0.2776\n","Epoch 764/10000\n","185/185 [==============================] - 19s 104ms/step - loss: 0.4873 - accuracy: 0.8251 - precision: 0.8609 - recall: 0.7897 - val_loss: 4.4011 - val_accuracy: 0.3075 - val_precision: 0.3265 - val_recall: 0.2827\n","Epoch 765/10000\n","185/185 [==============================] - 20s 110ms/step - loss: 0.4914 - accuracy: 0.8321 - precision: 0.8688 - recall: 0.7920 - val_loss: 4.4898 - val_accuracy: 0.2943 - val_precision: 0.3109 - val_recall: 0.2720\n","Epoch 766/10000\n","185/185 [==============================] - 20s 108ms/step - loss: 0.5078 - accuracy: 0.8216 - precision: 0.8613 - recall: 0.7892 - val_loss: 4.5609 - val_accuracy: 0.3034 - val_precision: 0.3221 - val_recall: 0.2801\n","Epoch 767/10000\n","185/185 [==============================] - 20s 106ms/step - loss: 0.5039 - accuracy: 0.8165 - precision: 0.8603 - recall: 0.7802 - val_loss: 4.5500 - val_accuracy: 0.3070 - val_precision: 0.3197 - val_recall: 0.2822\n","Epoch 768/10000\n","185/185 [==============================] - 19s 105ms/step - loss: 0.4932 - accuracy: 0.8273 - precision: 0.8687 - recall: 0.7902 - val_loss: 4.4953 - val_accuracy: 0.3009 - val_precision: 0.3186 - val_recall: 0.2776\n","Epoch 769/10000\n","185/185 [==============================] - 21s 113ms/step - loss: 0.4852 - accuracy: 0.8297 - precision: 0.8673 - recall: 0.7925 - val_loss: 4.5673 - val_accuracy: 0.2989 - val_precision: 0.3163 - val_recall: 0.2761\n","Epoch 770/10000\n","185/185 [==============================] - 19s 105ms/step - loss: 0.4743 - accuracy: 0.8302 - precision: 0.8708 - recall: 0.7957 - val_loss: 4.4738 - val_accuracy: 0.3034 - val_precision: 0.3246 - val_recall: 0.2766\n","Epoch 771/10000\n","185/185 [==============================] - 19s 104ms/step - loss: 0.4837 - accuracy: 0.8331 - precision: 0.8667 - recall: 0.7995 - val_loss: 4.5568 - val_accuracy: 0.2999 - val_precision: 0.3133 - val_recall: 0.2725\n","Epoch 772/10000\n","185/185 [==============================] - 20s 110ms/step - loss: 0.4769 - accuracy: 0.8324 - precision: 0.8711 - recall: 0.7971 - val_loss: 4.6782 - val_accuracy: 0.3090 - val_precision: 0.3272 - val_recall: 0.2862\n","Epoch 773/10000\n","185/185 [==============================] - 21s 116ms/step - loss: 0.4907 - accuracy: 0.8353 - precision: 0.8702 - recall: 0.7986 - val_loss: 4.4898 - val_accuracy: 0.2984 - val_precision: 0.3155 - val_recall: 0.2720\n","Epoch 774/10000\n","185/185 [==============================] - 19s 105ms/step - loss: 0.4898 - accuracy: 0.8305 - precision: 0.8696 - recall: 0.7962 - val_loss: 4.6908 - val_accuracy: 0.2979 - val_precision: 0.3148 - val_recall: 0.2725\n","Epoch 775/10000\n","185/185 [==============================] - 19s 104ms/step - loss: 0.4983 - accuracy: 0.8272 - precision: 0.8648 - recall: 0.7900 - val_loss: 4.3353 - val_accuracy: 0.3146 - val_precision: 0.3280 - val_recall: 0.2882\n","Epoch 776/10000\n","185/185 [==============================] - 21s 111ms/step - loss: 0.4826 - accuracy: 0.8307 - precision: 0.8685 - recall: 0.7932 - val_loss: 4.4144 - val_accuracy: 0.3110 - val_precision: 0.3223 - val_recall: 0.2806\n","Epoch 777/10000\n","185/185 [==============================] - 20s 108ms/step - loss: 0.4733 - accuracy: 0.8349 - precision: 0.8699 - recall: 0.7973 - val_loss: 4.5179 - val_accuracy: 0.3019 - val_precision: 0.3161 - val_recall: 0.2781\n","Epoch 778/10000\n","185/185 [==============================] - 19s 105ms/step - loss: 0.4758 - accuracy: 0.8300 - precision: 0.8682 - recall: 0.7971 - val_loss: 4.6712 - val_accuracy: 0.2994 - val_precision: 0.3113 - val_recall: 0.2700\n","Epoch 779/10000\n","185/185 [==============================] - 20s 106ms/step - loss: 0.4808 - accuracy: 0.8314 - precision: 0.8691 - recall: 0.7995 - val_loss: 4.8590 - val_accuracy: 0.2898 - val_precision: 0.3057 - val_recall: 0.2649\n","Epoch 780/10000\n","185/185 [==============================] - 21s 112ms/step - loss: 0.5005 - accuracy: 0.8223 - precision: 0.8571 - recall: 0.7873 - val_loss: 4.5646 - val_accuracy: 0.3146 - val_precision: 0.3308 - val_recall: 0.2918\n","Epoch 781/10000\n","185/185 [==============================] - 19s 105ms/step - loss: 0.4721 - accuracy: 0.8346 - precision: 0.8735 - recall: 0.7993 - val_loss: 4.6490 - val_accuracy: 0.2979 - val_precision: 0.3223 - val_recall: 0.2771\n","Epoch 782/10000\n","185/185 [==============================] - 21s 112ms/step - loss: 0.4603 - accuracy: 0.8376 - precision: 0.8710 - recall: 0.8006 - val_loss: 4.8495 - val_accuracy: 0.2933 - val_precision: 0.3104 - val_recall: 0.2761\n","Epoch 783/10000\n","185/185 [==============================] - 19s 104ms/step - loss: 0.4753 - accuracy: 0.8339 - precision: 0.8743 - recall: 0.7988 - val_loss: 4.5541 - val_accuracy: 0.2984 - val_precision: 0.3212 - val_recall: 0.2720\n","Epoch 784/10000\n","185/185 [==============================] - 21s 112ms/step - loss: 0.4564 - accuracy: 0.8407 - precision: 0.8746 - recall: 0.8059 - val_loss: 4.7417 - val_accuracy: 0.2867 - val_precision: 0.3024 - val_recall: 0.2660\n","Epoch 785/10000\n","185/185 [==============================] - 19s 105ms/step - loss: 0.4562 - accuracy: 0.8405 - precision: 0.8809 - recall: 0.8069 - val_loss: 4.5974 - val_accuracy: 0.3060 - val_precision: 0.3248 - val_recall: 0.2837\n","Epoch 786/10000\n","185/185 [==============================] - 19s 105ms/step - loss: 0.4412 - accuracy: 0.8414 - precision: 0.8747 - recall: 0.8116 - val_loss: 4.8162 - val_accuracy: 0.2847 - val_precision: 0.2987 - val_recall: 0.2624\n","Epoch 787/10000\n","185/185 [==============================] - 20s 109ms/step - loss: 0.4839 - accuracy: 0.8297 - precision: 0.8658 - recall: 0.7976 - val_loss: 4.5658 - val_accuracy: 0.2898 - val_precision: 0.3112 - val_recall: 0.2710\n","Epoch 788/10000\n","185/185 [==============================] - 20s 108ms/step - loss: 0.4446 - accuracy: 0.8458 - precision: 0.8792 - recall: 0.8079 - val_loss: 4.7491 - val_accuracy: 0.2898 - val_precision: 0.3094 - val_recall: 0.2685\n","Epoch 789/10000\n","185/185 [==============================] - 19s 105ms/step - loss: 0.4683 - accuracy: 0.8375 - precision: 0.8716 - recall: 0.8039 - val_loss: 4.5363 - val_accuracy: 0.2969 - val_precision: 0.3155 - val_recall: 0.2715\n","Epoch 790/10000\n","185/185 [==============================] - 19s 105ms/step - loss: 0.4891 - accuracy: 0.8324 - precision: 0.8668 - recall: 0.7993 - val_loss: 4.6756 - val_accuracy: 0.2877 - val_precision: 0.3082 - val_recall: 0.2655\n","Epoch 791/10000\n","185/185 [==============================] - 21s 111ms/step - loss: 0.4831 - accuracy: 0.8322 - precision: 0.8691 - recall: 0.7973 - val_loss: 4.6283 - val_accuracy: 0.3004 - val_precision: 0.3123 - val_recall: 0.2756\n","Epoch 792/10000\n","185/185 [==============================] - 21s 113ms/step - loss: 0.4950 - accuracy: 0.8329 - precision: 0.8684 - recall: 0.7973 - val_loss: 4.8449 - val_accuracy: 0.2857 - val_precision: 0.3038 - val_recall: 0.2624\n","Epoch 793/10000\n","185/185 [==============================] - 19s 105ms/step - loss: 0.4706 - accuracy: 0.8361 - precision: 0.8691 - recall: 0.7978 - val_loss: 4.7879 - val_accuracy: 0.2898 - val_precision: 0.3078 - val_recall: 0.2710\n","Epoch 794/10000\n","185/185 [==============================] - 20s 108ms/step - loss: 0.4532 - accuracy: 0.8402 - precision: 0.8777 - recall: 0.8066 - val_loss: 4.7771 - val_accuracy: 0.2994 - val_precision: 0.3151 - val_recall: 0.2746\n","Epoch 795/10000\n","185/185 [==============================] - 20s 108ms/step - loss: 0.4695 - accuracy: 0.8311 - precision: 0.8655 - recall: 0.7968 - val_loss: 4.6470 - val_accuracy: 0.2882 - val_precision: 0.3097 - val_recall: 0.2720\n","Epoch 796/10000\n","185/185 [==============================] - 19s 104ms/step - loss: 0.4468 - accuracy: 0.8422 - precision: 0.8776 - recall: 0.8052 - val_loss: 4.5492 - val_accuracy: 0.2918 - val_precision: 0.3072 - val_recall: 0.2720\n","Epoch 797/10000\n","185/185 [==============================] - 19s 104ms/step - loss: 0.4431 - accuracy: 0.8441 - precision: 0.8772 - recall: 0.8098 - val_loss: 4.6481 - val_accuracy: 0.2969 - val_precision: 0.3063 - val_recall: 0.2655\n","Epoch 798/10000\n","185/185 [==============================] - 21s 112ms/step - loss: 0.4687 - accuracy: 0.8409 - precision: 0.8749 - recall: 0.8057 - val_loss: 4.5239 - val_accuracy: 0.3055 - val_precision: 0.3218 - val_recall: 0.2837\n","Epoch 799/10000\n","185/185 [==============================] - 20s 107ms/step - loss: 0.4693 - accuracy: 0.8383 - precision: 0.8735 - recall: 0.8071 - val_loss: 4.8035 - val_accuracy: 0.2938 - val_precision: 0.3051 - val_recall: 0.2720\n","Epoch 800/10000\n","185/185 [==============================] - 19s 105ms/step - loss: 0.4567 - accuracy: 0.8376 - precision: 0.8735 - recall: 0.8076 - val_loss: 4.6186 - val_accuracy: 0.3004 - val_precision: 0.3128 - val_recall: 0.2730\n","Epoch 801/10000\n","185/185 [==============================] - 22s 116ms/step - loss: 0.4381 - accuracy: 0.8456 - precision: 0.8796 - recall: 0.8121 - val_loss: 4.6156 - val_accuracy: 0.2994 - val_precision: 0.3218 - val_recall: 0.2832\n","Epoch 802/10000\n","185/185 [==============================] - 20s 106ms/step - loss: 0.4360 - accuracy: 0.8490 - precision: 0.8842 - recall: 0.8165 - val_loss: 4.7026 - val_accuracy: 0.2918 - val_precision: 0.3096 - val_recall: 0.2730\n","Epoch 803/10000\n","185/185 [==============================] - 19s 105ms/step - loss: 0.4626 - accuracy: 0.8400 - precision: 0.8747 - recall: 0.8066 - val_loss: 4.6884 - val_accuracy: 0.2979 - val_precision: 0.3130 - val_recall: 0.2730\n","Epoch 804/10000\n","185/185 [==============================] - 20s 106ms/step - loss: 0.4552 - accuracy: 0.8466 - precision: 0.8813 - recall: 0.8106 - val_loss: 4.9593 - val_accuracy: 0.2923 - val_precision: 0.3042 - val_recall: 0.2710\n","Epoch 805/10000\n","185/185 [==============================] - 21s 113ms/step - loss: 0.4620 - accuracy: 0.8312 - precision: 0.8700 - recall: 0.7991 - val_loss: 5.0975 - val_accuracy: 0.2953 - val_precision: 0.3014 - val_recall: 0.2695\n","Epoch 806/10000\n","185/185 [==============================] - 19s 105ms/step - loss: 0.4516 - accuracy: 0.8447 - precision: 0.8785 - recall: 0.8158 - val_loss: 4.5091 - val_accuracy: 0.2933 - val_precision: 0.3128 - val_recall: 0.2644\n","Epoch 807/10000\n","185/185 [==============================] - 19s 104ms/step - loss: 0.4754 - accuracy: 0.8373 - precision: 0.8694 - recall: 0.8074 - val_loss: 4.5939 - val_accuracy: 0.2918 - val_precision: 0.3125 - val_recall: 0.2715\n","Epoch 808/10000\n","185/185 [==============================] - 20s 107ms/step - loss: 0.4593 - accuracy: 0.8398 - precision: 0.8721 - recall: 0.8088 - val_loss: 4.8041 - val_accuracy: 0.2903 - val_precision: 0.3061 - val_recall: 0.2675\n","Epoch 809/10000\n","185/185 [==============================] - 21s 111ms/step - loss: 0.4485 - accuracy: 0.8442 - precision: 0.8812 - recall: 0.8137 - val_loss: 4.7643 - val_accuracy: 0.2882 - val_precision: 0.3036 - val_recall: 0.2660\n","Epoch 810/10000\n","185/185 [==============================] - 20s 107ms/step - loss: 0.4489 - accuracy: 0.8441 - precision: 0.8735 - recall: 0.8111 - val_loss: 4.9391 - val_accuracy: 0.2913 - val_precision: 0.3126 - val_recall: 0.2776\n","Epoch 811/10000\n","185/185 [==============================] - 21s 115ms/step - loss: 0.4426 - accuracy: 0.8500 - precision: 0.8810 - recall: 0.8153 - val_loss: 4.8479 - val_accuracy: 0.2872 - val_precision: 0.3072 - val_recall: 0.2685\n","Epoch 812/10000\n","185/185 [==============================] - 21s 111ms/step - loss: 0.4497 - accuracy: 0.8425 - precision: 0.8810 - recall: 0.8106 - val_loss: 4.7113 - val_accuracy: 0.2994 - val_precision: 0.3152 - val_recall: 0.2761\n","Epoch 813/10000\n","185/185 [==============================] - 21s 113ms/step - loss: 0.4310 - accuracy: 0.8485 - precision: 0.8807 - recall: 0.8131 - val_loss: 4.6055 - val_accuracy: 0.3040 - val_precision: 0.3208 - val_recall: 0.2766\n","Epoch 814/10000\n","185/185 [==============================] - 20s 107ms/step - loss: 0.4553 - accuracy: 0.8419 - precision: 0.8762 - recall: 0.8106 - val_loss: 4.6786 - val_accuracy: 0.2964 - val_precision: 0.3146 - val_recall: 0.2781\n","Epoch 815/10000\n","185/185 [==============================] - 20s 106ms/step - loss: 0.4563 - accuracy: 0.8417 - precision: 0.8764 - recall: 0.8109 - val_loss: 4.5937 - val_accuracy: 0.2958 - val_precision: 0.3149 - val_recall: 0.2746\n","Epoch 816/10000\n","185/185 [==============================] - 21s 113ms/step - loss: 0.4334 - accuracy: 0.8463 - precision: 0.8790 - recall: 0.8147 - val_loss: 4.7409 - val_accuracy: 0.2923 - val_precision: 0.3054 - val_recall: 0.2700\n","Epoch 817/10000\n","185/185 [==============================] - 20s 106ms/step - loss: 0.4262 - accuracy: 0.8454 - precision: 0.8818 - recall: 0.8164 - val_loss: 4.5974 - val_accuracy: 0.2958 - val_precision: 0.3121 - val_recall: 0.2725\n","Epoch 818/10000\n","185/185 [==============================] - 20s 106ms/step - loss: 0.4311 - accuracy: 0.8517 - precision: 0.8826 - recall: 0.8240 - val_loss: 4.7822 - val_accuracy: 0.2923 - val_precision: 0.3091 - val_recall: 0.2741\n","Epoch 819/10000\n","185/185 [==============================] - 20s 106ms/step - loss: 0.4356 - accuracy: 0.8469 - precision: 0.8803 - recall: 0.8152 - val_loss: 4.7511 - val_accuracy: 0.2877 - val_precision: 0.3087 - val_recall: 0.2725\n","Epoch 820/10000\n","185/185 [==============================] - 22s 122ms/step - loss: 0.4133 - accuracy: 0.8547 - precision: 0.8896 - recall: 0.8250 - val_loss: 4.6906 - val_accuracy: 0.2974 - val_precision: 0.3112 - val_recall: 0.2736\n","Epoch 821/10000\n","185/185 [==============================] - 20s 109ms/step - loss: 0.4309 - accuracy: 0.8517 - precision: 0.8828 - recall: 0.8246 - val_loss: 4.8083 - val_accuracy: 0.3024 - val_precision: 0.3162 - val_recall: 0.2741\n","Epoch 822/10000\n","185/185 [==============================] - 20s 107ms/step - loss: 0.4352 - accuracy: 0.8483 - precision: 0.8843 - recall: 0.8187 - val_loss: 4.6373 - val_accuracy: 0.2953 - val_precision: 0.3039 - val_recall: 0.2599\n","Epoch 823/10000\n","185/185 [==============================] - 20s 110ms/step - loss: 0.4276 - accuracy: 0.8549 - precision: 0.8829 - recall: 0.8243 - val_loss: 5.0440 - val_accuracy: 0.3004 - val_precision: 0.3084 - val_recall: 0.2756\n","Epoch 824/10000\n","185/185 [==============================] - 21s 112ms/step - loss: 0.4432 - accuracy: 0.8496 - precision: 0.8793 - recall: 0.8206 - val_loss: 4.8389 - val_accuracy: 0.2933 - val_precision: 0.3064 - val_recall: 0.2690\n","Epoch 825/10000\n","185/185 [==============================] - 20s 108ms/step - loss: 0.4331 - accuracy: 0.8508 - precision: 0.8838 - recall: 0.8223 - val_loss: 4.9305 - val_accuracy: 0.2837 - val_precision: 0.2969 - val_recall: 0.2644\n","Epoch 826/10000\n","185/185 [==============================] - 19s 105ms/step - loss: 0.4379 - accuracy: 0.8495 - precision: 0.8801 - recall: 0.8174 - val_loss: 4.7123 - val_accuracy: 0.3080 - val_precision: 0.3274 - val_recall: 0.2893\n","Epoch 827/10000\n","185/185 [==============================] - 21s 113ms/step - loss: 0.4360 - accuracy: 0.8458 - precision: 0.8769 - recall: 0.8135 - val_loss: 5.0032 - val_accuracy: 0.2867 - val_precision: 0.3069 - val_recall: 0.2705\n","Epoch 828/10000\n","185/185 [==============================] - 20s 107ms/step - loss: 0.4449 - accuracy: 0.8456 - precision: 0.8762 - recall: 0.8155 - val_loss: 4.8139 - val_accuracy: 0.2872 - val_precision: 0.3017 - val_recall: 0.2660\n","Epoch 829/10000\n","185/185 [==============================] - 19s 105ms/step - loss: 0.4271 - accuracy: 0.8508 - precision: 0.8800 - recall: 0.8202 - val_loss: 4.9116 - val_accuracy: 0.2928 - val_precision: 0.3069 - val_recall: 0.2700\n","Epoch 830/10000\n","185/185 [==============================] - 21s 112ms/step - loss: 0.4609 - accuracy: 0.8400 - precision: 0.8730 - recall: 0.8130 - val_loss: 4.7184 - val_accuracy: 0.3040 - val_precision: 0.3156 - val_recall: 0.2761\n","Epoch 831/10000\n","185/185 [==============================] - 19s 105ms/step - loss: 0.4358 - accuracy: 0.8501 - precision: 0.8839 - recall: 0.8165 - val_loss: 4.7536 - val_accuracy: 0.2893 - val_precision: 0.3047 - val_recall: 0.2680\n","Epoch 832/10000\n","185/185 [==============================] - 21s 113ms/step - loss: 0.4497 - accuracy: 0.8473 - precision: 0.8828 - recall: 0.8170 - val_loss: 4.6711 - val_accuracy: 0.3009 - val_precision: 0.3173 - val_recall: 0.2806\n","Epoch 833/10000\n","185/185 [==============================] - 20s 106ms/step - loss: 0.4389 - accuracy: 0.8444 - precision: 0.8741 - recall: 0.8116 - val_loss: 4.8358 - val_accuracy: 0.2923 - val_precision: 0.3084 - val_recall: 0.2675\n","Epoch 834/10000\n","185/185 [==============================] - 20s 106ms/step - loss: 0.4192 - accuracy: 0.8481 - precision: 0.8810 - recall: 0.8189 - val_loss: 4.8213 - val_accuracy: 0.2888 - val_precision: 0.3037 - val_recall: 0.2670\n","Epoch 835/10000\n","185/185 [==============================] - 20s 110ms/step - loss: 0.4305 - accuracy: 0.8501 - precision: 0.8837 - recall: 0.8229 - val_loss: 4.6638 - val_accuracy: 0.2893 - val_precision: 0.3072 - val_recall: 0.2685\n","Epoch 836/10000\n","185/185 [==============================] - 20s 107ms/step - loss: 0.4463 - accuracy: 0.8456 - precision: 0.8771 - recall: 0.8130 - val_loss: 4.9532 - val_accuracy: 0.2751 - val_precision: 0.2898 - val_recall: 0.2573\n","Epoch 837/10000\n","185/185 [==============================] - 20s 106ms/step - loss: 0.4278 - accuracy: 0.8527 - precision: 0.8838 - recall: 0.8209 - val_loss: 4.9651 - val_accuracy: 0.2908 - val_precision: 0.3038 - val_recall: 0.2680\n","Epoch 838/10000\n","185/185 [==============================] - 19s 105ms/step - loss: 0.3940 - accuracy: 0.8662 - precision: 0.8938 - recall: 0.8329 - val_loss: 4.7270 - val_accuracy: 0.3009 - val_precision: 0.3168 - val_recall: 0.2806\n","Epoch 839/10000\n","185/185 [==============================] - 21s 112ms/step - loss: 0.4039 - accuracy: 0.8581 - precision: 0.8867 - recall: 0.8331 - val_loss: 4.6046 - val_accuracy: 0.3034 - val_precision: 0.3200 - val_recall: 0.2837\n","Epoch 840/10000\n","185/185 [==============================] - 21s 114ms/step - loss: 0.4370 - accuracy: 0.8490 - precision: 0.8807 - recall: 0.8223 - val_loss: 4.8417 - val_accuracy: 0.2913 - val_precision: 0.3084 - val_recall: 0.2761\n","Epoch 841/10000\n","185/185 [==============================] - 20s 109ms/step - loss: 0.4329 - accuracy: 0.8525 - precision: 0.8801 - recall: 0.8231 - val_loss: 4.8465 - val_accuracy: 0.3045 - val_precision: 0.3153 - val_recall: 0.2832\n","Epoch 842/10000\n","185/185 [==============================] - 21s 112ms/step - loss: 0.4254 - accuracy: 0.8508 - precision: 0.8826 - recall: 0.8221 - val_loss: 4.8246 - val_accuracy: 0.2852 - val_precision: 0.2961 - val_recall: 0.2609\n","Epoch 843/10000\n","185/185 [==============================] - 20s 108ms/step - loss: 0.4211 - accuracy: 0.8549 - precision: 0.8858 - recall: 0.8255 - val_loss: 4.6897 - val_accuracy: 0.3055 - val_precision: 0.3143 - val_recall: 0.2791\n","Epoch 844/10000\n","185/185 [==============================] - 19s 105ms/step - loss: 0.4202 - accuracy: 0.8550 - precision: 0.8866 - recall: 0.8245 - val_loss: 4.8966 - val_accuracy: 0.2862 - val_precision: 0.2934 - val_recall: 0.2609\n","Epoch 845/10000\n","185/185 [==============================] - 20s 106ms/step - loss: 0.4151 - accuracy: 0.8522 - precision: 0.8855 - recall: 0.8258 - val_loss: 4.8435 - val_accuracy: 0.3019 - val_precision: 0.3141 - val_recall: 0.2786\n","Epoch 846/10000\n","185/185 [==============================] - 21s 113ms/step - loss: 0.4150 - accuracy: 0.8539 - precision: 0.8853 - recall: 0.8256 - val_loss: 4.9230 - val_accuracy: 0.2882 - val_precision: 0.3087 - val_recall: 0.2751\n","Epoch 847/10000\n","185/185 [==============================] - 19s 105ms/step - loss: 0.4165 - accuracy: 0.8550 - precision: 0.8868 - recall: 0.8229 - val_loss: 4.9459 - val_accuracy: 0.2908 - val_precision: 0.3060 - val_recall: 0.2680\n","Epoch 848/10000\n","185/185 [==============================] - 19s 105ms/step - loss: 0.3961 - accuracy: 0.8606 - precision: 0.8900 - recall: 0.8311 - val_loss: 4.9090 - val_accuracy: 0.2791 - val_precision: 0.2921 - val_recall: 0.2584\n","Epoch 849/10000\n","185/185 [==============================] - 21s 112ms/step - loss: 0.4173 - accuracy: 0.8542 - precision: 0.8813 - recall: 0.8256 - val_loss: 4.8005 - val_accuracy: 0.2948 - val_precision: 0.3109 - val_recall: 0.2781\n","Epoch 850/10000\n","185/185 [==============================] - 21s 116ms/step - loss: 0.4248 - accuracy: 0.8544 - precision: 0.8847 - recall: 0.8216 - val_loss: 4.8335 - val_accuracy: 0.2958 - val_precision: 0.3109 - val_recall: 0.2766\n","Epoch 851/10000\n","185/185 [==============================] - 20s 107ms/step - loss: 0.3999 - accuracy: 0.8598 - precision: 0.8902 - recall: 0.8314 - val_loss: 5.1456 - val_accuracy: 0.2933 - val_precision: 0.3047 - val_recall: 0.2695\n","Epoch 852/10000\n","185/185 [==============================] - 20s 108ms/step - loss: 0.4358 - accuracy: 0.8432 - precision: 0.8775 - recall: 0.8148 - val_loss: 4.8390 - val_accuracy: 0.3055 - val_precision: 0.3210 - val_recall: 0.2852\n","Epoch 853/10000\n","185/185 [==============================] - 21s 114ms/step - loss: 0.4305 - accuracy: 0.8496 - precision: 0.8795 - recall: 0.8199 - val_loss: 4.8404 - val_accuracy: 0.2852 - val_precision: 0.3031 - val_recall: 0.2655\n","Epoch 854/10000\n","185/185 [==============================] - 20s 110ms/step - loss: 0.4118 - accuracy: 0.8559 - precision: 0.8909 - recall: 0.8304 - val_loss: 4.8119 - val_accuracy: 0.2872 - val_precision: 0.3050 - val_recall: 0.2675\n","Epoch 855/10000\n","185/185 [==============================] - 20s 106ms/step - loss: 0.3852 - accuracy: 0.8667 - precision: 0.8954 - recall: 0.8392 - val_loss: 4.8430 - val_accuracy: 0.3090 - val_precision: 0.3261 - val_recall: 0.2893\n","Epoch 856/10000\n","185/185 [==============================] - 19s 105ms/step - loss: 0.3963 - accuracy: 0.8694 - precision: 0.8931 - recall: 0.8409 - val_loss: 4.9587 - val_accuracy: 0.2903 - val_precision: 0.3063 - val_recall: 0.2695\n","Epoch 857/10000\n","185/185 [==============================] - 22s 117ms/step - loss: 0.4141 - accuracy: 0.8577 - precision: 0.8853 - recall: 0.8305 - val_loss: 4.9526 - val_accuracy: 0.3009 - val_precision: 0.3146 - val_recall: 0.2781\n","Epoch 858/10000\n","185/185 [==============================] - 20s 106ms/step - loss: 0.3951 - accuracy: 0.8653 - precision: 0.8927 - recall: 0.8365 - val_loss: 4.9658 - val_accuracy: 0.2953 - val_precision: 0.3031 - val_recall: 0.2690\n","Epoch 859/10000\n","185/185 [==============================] - 21s 113ms/step - loss: 0.4088 - accuracy: 0.8599 - precision: 0.8894 - recall: 0.8343 - val_loss: 4.9342 - val_accuracy: 0.2872 - val_precision: 0.3050 - val_recall: 0.2690\n","Epoch 860/10000\n","185/185 [==============================] - 21s 113ms/step - loss: 0.4213 - accuracy: 0.8559 - precision: 0.8853 - recall: 0.8270 - val_loss: 4.9151 - val_accuracy: 0.2908 - val_precision: 0.3083 - val_recall: 0.2761\n","Epoch 861/10000\n","185/185 [==============================] - 20s 107ms/step - loss: 0.4304 - accuracy: 0.8528 - precision: 0.8822 - recall: 0.8275 - val_loss: 4.7623 - val_accuracy: 0.2918 - val_precision: 0.3094 - val_recall: 0.2746\n","Epoch 862/10000\n","185/185 [==============================] - 20s 106ms/step - loss: 0.4160 - accuracy: 0.8535 - precision: 0.8837 - recall: 0.8280 - val_loss: 4.9165 - val_accuracy: 0.2893 - val_precision: 0.3075 - val_recall: 0.2730\n","Epoch 863/10000\n","185/185 [==============================] - 20s 109ms/step - loss: 0.3867 - accuracy: 0.8689 - precision: 0.8955 - recall: 0.8397 - val_loss: 5.0257 - val_accuracy: 0.2923 - val_precision: 0.3027 - val_recall: 0.2705\n","Epoch 864/10000\n","185/185 [==============================] - 21s 114ms/step - loss: 0.4030 - accuracy: 0.8638 - precision: 0.8933 - recall: 0.8360 - val_loss: 4.7855 - val_accuracy: 0.3009 - val_precision: 0.3135 - val_recall: 0.2776\n","Epoch 865/10000\n","185/185 [==============================] - 20s 107ms/step - loss: 0.3996 - accuracy: 0.8584 - precision: 0.8844 - recall: 0.8283 - val_loss: 4.9231 - val_accuracy: 0.2989 - val_precision: 0.3149 - val_recall: 0.2796\n","Epoch 866/10000\n","185/185 [==============================] - 20s 106ms/step - loss: 0.4098 - accuracy: 0.8576 - precision: 0.8833 - recall: 0.8283 - val_loss: 4.7514 - val_accuracy: 0.2928 - val_precision: 0.3084 - val_recall: 0.2730\n","Epoch 867/10000\n","185/185 [==============================] - 21s 113ms/step - loss: 0.4182 - accuracy: 0.8572 - precision: 0.8859 - recall: 0.8275 - val_loss: 4.7091 - val_accuracy: 0.3045 - val_precision: 0.3200 - val_recall: 0.2806\n","Epoch 868/10000\n","185/185 [==============================] - 20s 108ms/step - loss: 0.3941 - accuracy: 0.8588 - precision: 0.8904 - recall: 0.8344 - val_loss: 4.8639 - val_accuracy: 0.2928 - val_precision: 0.3082 - val_recall: 0.2736\n","Epoch 869/10000\n","185/185 [==============================] - 21s 115ms/step - loss: 0.4095 - accuracy: 0.8579 - precision: 0.8871 - recall: 0.8268 - val_loss: 4.9356 - val_accuracy: 0.3029 - val_precision: 0.3186 - val_recall: 0.2857\n","Epoch 870/10000\n","185/185 [==============================] - 20s 107ms/step - loss: 0.3974 - accuracy: 0.8596 - precision: 0.8907 - recall: 0.8316 - val_loss: 4.9553 - val_accuracy: 0.2857 - val_precision: 0.2966 - val_recall: 0.2644\n","Epoch 871/10000\n","185/185 [==============================] - 20s 110ms/step - loss: 0.4043 - accuracy: 0.8591 - precision: 0.8844 - recall: 0.8326 - val_loss: 4.9833 - val_accuracy: 0.2994 - val_precision: 0.3094 - val_recall: 0.2817\n","Epoch 872/10000\n","185/185 [==============================] - 20s 110ms/step - loss: 0.4062 - accuracy: 0.8583 - precision: 0.8891 - recall: 0.8302 - val_loss: 5.0734 - val_accuracy: 0.2862 - val_precision: 0.2978 - val_recall: 0.2665\n","Epoch 873/10000\n","185/185 [==============================] - 20s 108ms/step - loss: 0.3824 - accuracy: 0.8645 - precision: 0.8926 - recall: 0.8370 - val_loss: 4.9058 - val_accuracy: 0.3014 - val_precision: 0.3142 - val_recall: 0.2806\n","Epoch 874/10000\n","185/185 [==============================] - 19s 105ms/step - loss: 0.4018 - accuracy: 0.8645 - precision: 0.8880 - recall: 0.8371 - val_loss: 5.0842 - val_accuracy: 0.2943 - val_precision: 0.3077 - val_recall: 0.2720\n","Epoch 875/10000\n","185/185 [==============================] - 21s 113ms/step - loss: 0.4086 - accuracy: 0.8577 - precision: 0.8881 - recall: 0.8300 - val_loss: 4.9832 - val_accuracy: 0.3110 - val_precision: 0.3221 - val_recall: 0.2903\n","Epoch 876/10000\n","185/185 [==============================] - 20s 107ms/step - loss: 0.3850 - accuracy: 0.8686 - precision: 0.8964 - recall: 0.8407 - val_loss: 4.9474 - val_accuracy: 0.2958 - val_precision: 0.3130 - val_recall: 0.2736\n","Epoch 877/10000\n","185/185 [==============================] - 19s 105ms/step - loss: 0.4056 - accuracy: 0.8621 - precision: 0.8888 - recall: 0.8317 - val_loss: 4.7280 - val_accuracy: 0.2938 - val_precision: 0.3012 - val_recall: 0.2710\n","Epoch 878/10000\n","185/185 [==============================] - 20s 107ms/step - loss: 0.4231 - accuracy: 0.8545 - precision: 0.8849 - recall: 0.8272 - val_loss: 4.8650 - val_accuracy: 0.2948 - val_precision: 0.3109 - val_recall: 0.2766\n","Epoch 879/10000\n","185/185 [==============================] - 22s 119ms/step - loss: 0.4117 - accuracy: 0.8599 - precision: 0.8886 - recall: 0.8305 - val_loss: 4.9839 - val_accuracy: 0.2882 - val_precision: 0.3036 - val_recall: 0.2705\n","Epoch 880/10000\n","185/185 [==============================] - 20s 106ms/step - loss: 0.4030 - accuracy: 0.8615 - precision: 0.8906 - recall: 0.8338 - val_loss: 4.9608 - val_accuracy: 0.2801 - val_precision: 0.2896 - val_recall: 0.2538\n","Epoch 881/10000\n","185/185 [==============================] - 20s 108ms/step - loss: 0.4177 - accuracy: 0.8586 - precision: 0.8894 - recall: 0.8297 - val_loss: 4.9884 - val_accuracy: 0.2994 - val_precision: 0.3105 - val_recall: 0.2751\n","Epoch 882/10000\n","185/185 [==============================] - 21s 112ms/step - loss: 0.3929 - accuracy: 0.8637 - precision: 0.8867 - recall: 0.8354 - val_loss: 4.8875 - val_accuracy: 0.2933 - val_precision: 0.3076 - val_recall: 0.2761\n","Epoch 883/10000\n","185/185 [==============================] - 20s 106ms/step - loss: 0.4021 - accuracy: 0.8598 - precision: 0.8883 - recall: 0.8343 - val_loss: 4.9998 - val_accuracy: 0.2974 - val_precision: 0.3135 - val_recall: 0.2837\n","Epoch 884/10000\n","185/185 [==============================] - 20s 106ms/step - loss: 0.3916 - accuracy: 0.8606 - precision: 0.8903 - recall: 0.8348 - val_loss: 4.9489 - val_accuracy: 0.2756 - val_precision: 0.2915 - val_recall: 0.2604\n","Epoch 885/10000\n","185/185 [==============================] - 19s 105ms/step - loss: 0.4127 - accuracy: 0.8594 - precision: 0.8911 - recall: 0.8297 - val_loss: 4.8809 - val_accuracy: 0.2953 - val_precision: 0.3054 - val_recall: 0.2715\n","Epoch 886/10000\n","185/185 [==============================] - 21s 112ms/step - loss: 0.4100 - accuracy: 0.8611 - precision: 0.8887 - recall: 0.8334 - val_loss: 4.9844 - val_accuracy: 0.2984 - val_precision: 0.3097 - val_recall: 0.2766\n","Epoch 887/10000\n","185/185 [==============================] - 20s 109ms/step - loss: 0.3814 - accuracy: 0.8709 - precision: 0.8986 - recall: 0.8427 - val_loss: 5.0928 - val_accuracy: 0.2882 - val_precision: 0.3014 - val_recall: 0.2695\n","Epoch 888/10000\n","185/185 [==============================] - 20s 107ms/step - loss: 0.3968 - accuracy: 0.8642 - precision: 0.8925 - recall: 0.8373 - val_loss: 4.9300 - val_accuracy: 0.2893 - val_precision: 0.2992 - val_recall: 0.2690\n","Epoch 889/10000\n","185/185 [==============================] - 22s 120ms/step - loss: 0.3771 - accuracy: 0.8711 - precision: 0.8970 - recall: 0.8444 - val_loss: 4.9661 - val_accuracy: 0.2837 - val_precision: 0.2993 - val_recall: 0.2690\n","Epoch 890/10000\n","185/185 [==============================] - 20s 109ms/step - loss: 0.4122 - accuracy: 0.8611 - precision: 0.8879 - recall: 0.8339 - val_loss: 5.0017 - val_accuracy: 0.2938 - val_precision: 0.3070 - val_recall: 0.2741\n","Epoch 891/10000\n","185/185 [==============================] - 20s 106ms/step - loss: 0.3853 - accuracy: 0.8642 - precision: 0.8893 - recall: 0.8412 - val_loss: 5.1026 - val_accuracy: 0.2806 - val_precision: 0.2924 - val_recall: 0.2619\n","Epoch 892/10000\n","185/185 [==============================] - 20s 106ms/step - loss: 0.3790 - accuracy: 0.8694 - precision: 0.8954 - recall: 0.8419 - val_loss: 4.8950 - val_accuracy: 0.3029 - val_precision: 0.3130 - val_recall: 0.2776\n","Epoch 893/10000\n","185/185 [==============================] - 21s 115ms/step - loss: 0.3868 - accuracy: 0.8599 - precision: 0.8905 - recall: 0.8324 - val_loss: 4.8883 - val_accuracy: 0.2923 - val_precision: 0.3092 - val_recall: 0.2725\n","Epoch 894/10000\n","185/185 [==============================] - 20s 108ms/step - loss: 0.3619 - accuracy: 0.8762 - precision: 0.9021 - recall: 0.8512 - val_loss: 4.9493 - val_accuracy: 0.2817 - val_precision: 0.2966 - val_recall: 0.2604\n","Epoch 895/10000\n","185/185 [==============================] - 20s 107ms/step - loss: 0.3996 - accuracy: 0.8626 - precision: 0.8913 - recall: 0.8366 - val_loss: 4.9874 - val_accuracy: 0.2938 - val_precision: 0.3081 - val_recall: 0.2766\n","Epoch 896/10000\n","185/185 [==============================] - 20s 108ms/step - loss: 0.3712 - accuracy: 0.8709 - precision: 0.8941 - recall: 0.8456 - val_loss: 4.8974 - val_accuracy: 0.3040 - val_precision: 0.3238 - val_recall: 0.2882\n","Epoch 897/10000\n","185/185 [==============================] - 21s 113ms/step - loss: 0.3719 - accuracy: 0.8689 - precision: 0.8972 - recall: 0.8430 - val_loss: 4.8892 - val_accuracy: 0.2928 - val_precision: 0.3104 - val_recall: 0.2761\n","Epoch 898/10000\n","185/185 [==============================] - 19s 105ms/step - loss: 0.4000 - accuracy: 0.8657 - precision: 0.8919 - recall: 0.8402 - val_loss: 4.8967 - val_accuracy: 0.3004 - val_precision: 0.3190 - val_recall: 0.2847\n","Epoch 899/10000\n","185/185 [==============================] - 21s 114ms/step - loss: 0.3869 - accuracy: 0.8704 - precision: 0.8985 - recall: 0.8483 - val_loss: 4.8147 - val_accuracy: 0.2999 - val_precision: 0.3128 - val_recall: 0.2751\n","Epoch 900/10000\n","185/185 [==============================] - 20s 107ms/step - loss: 0.3574 - accuracy: 0.8748 - precision: 0.9008 - recall: 0.8512 - val_loss: 5.1156 - val_accuracy: 0.2964 - val_precision: 0.3133 - val_recall: 0.2806\n","Epoch 901/10000\n","185/185 [==============================] - 21s 114ms/step - loss: 0.3580 - accuracy: 0.8765 - precision: 0.9027 - recall: 0.8508 - val_loss: 5.0468 - val_accuracy: 0.2948 - val_precision: 0.3087 - val_recall: 0.2756\n","Epoch 902/10000\n","185/185 [==============================] - 20s 106ms/step - loss: 0.3972 - accuracy: 0.8660 - precision: 0.8949 - recall: 0.8412 - val_loss: 5.1641 - val_accuracy: 0.2842 - val_precision: 0.2947 - val_recall: 0.2655\n","Epoch 903/10000\n","185/185 [==============================] - 19s 105ms/step - loss: 0.3763 - accuracy: 0.8667 - precision: 0.8914 - recall: 0.8432 - val_loss: 5.0049 - val_accuracy: 0.2872 - val_precision: 0.3031 - val_recall: 0.2746\n","Epoch 904/10000\n","185/185 [==============================] - 20s 106ms/step - loss: 0.3712 - accuracy: 0.8730 - precision: 0.8974 - recall: 0.8464 - val_loss: 4.9998 - val_accuracy: 0.2888 - val_precision: 0.3043 - val_recall: 0.2690\n","Epoch 905/10000\n","185/185 [==============================] - 22s 119ms/step - loss: 0.3878 - accuracy: 0.8664 - precision: 0.8918 - recall: 0.8427 - val_loss: 5.0334 - val_accuracy: 0.2908 - val_precision: 0.3041 - val_recall: 0.2705\n","Epoch 906/10000\n","185/185 [==============================] - 20s 107ms/step - loss: 0.3679 - accuracy: 0.8692 - precision: 0.8952 - recall: 0.8425 - val_loss: 5.0038 - val_accuracy: 0.2806 - val_precision: 0.2966 - val_recall: 0.2614\n","Epoch 907/10000\n","185/185 [==============================] - 20s 108ms/step - loss: 0.3743 - accuracy: 0.8753 - precision: 0.8998 - recall: 0.8496 - val_loss: 5.0903 - val_accuracy: 0.2801 - val_precision: 0.2954 - val_recall: 0.2614\n","Epoch 908/10000\n","185/185 [==============================] - 20s 110ms/step - loss: 0.3812 - accuracy: 0.8677 - precision: 0.8953 - recall: 0.8478 - val_loss: 4.9490 - val_accuracy: 0.3029 - val_precision: 0.3164 - val_recall: 0.2812\n","Epoch 909/10000\n","185/185 [==============================] - 22s 120ms/step - loss: 0.3809 - accuracy: 0.8692 - precision: 0.8977 - recall: 0.8439 - val_loss: 5.0721 - val_accuracy: 0.2979 - val_precision: 0.3093 - val_recall: 0.2776\n","Epoch 910/10000\n","185/185 [==============================] - 20s 107ms/step - loss: 0.3753 - accuracy: 0.8701 - precision: 0.8940 - recall: 0.8432 - val_loss: 4.9293 - val_accuracy: 0.2862 - val_precision: 0.2994 - val_recall: 0.2670\n","Epoch 911/10000\n","185/185 [==============================] - 20s 107ms/step - loss: 0.3732 - accuracy: 0.8691 - precision: 0.8954 - recall: 0.8476 - val_loss: 4.9783 - val_accuracy: 0.2908 - val_precision: 0.3075 - val_recall: 0.2736\n","Epoch 912/10000\n","185/185 [==============================] - 21s 115ms/step - loss: 0.3927 - accuracy: 0.8665 - precision: 0.8920 - recall: 0.8427 - val_loss: 4.8871 - val_accuracy: 0.3065 - val_precision: 0.3172 - val_recall: 0.2857\n","Epoch 913/10000\n","185/185 [==============================] - 20s 106ms/step - loss: 0.3926 - accuracy: 0.8674 - precision: 0.8968 - recall: 0.8393 - val_loss: 4.7871 - val_accuracy: 0.2943 - val_precision: 0.3089 - val_recall: 0.2771\n","Epoch 914/10000\n","185/185 [==============================] - 20s 107ms/step - loss: 0.3767 - accuracy: 0.8704 - precision: 0.8959 - recall: 0.8464 - val_loss: 4.8529 - val_accuracy: 0.2964 - val_precision: 0.3092 - val_recall: 0.2771\n","Epoch 915/10000\n","185/185 [==============================] - 21s 111ms/step - loss: 0.3753 - accuracy: 0.8694 - precision: 0.8953 - recall: 0.8464 - val_loss: 4.8654 - val_accuracy: 0.3019 - val_precision: 0.3217 - val_recall: 0.2857\n","Epoch 916/10000\n","185/185 [==============================] - 20s 109ms/step - loss: 0.3814 - accuracy: 0.8667 - precision: 0.8935 - recall: 0.8430 - val_loss: 5.0314 - val_accuracy: 0.2969 - val_precision: 0.3066 - val_recall: 0.2730\n","Epoch 917/10000\n","185/185 [==============================] - 20s 107ms/step - loss: 0.3618 - accuracy: 0.8758 - precision: 0.8980 - recall: 0.8510 - val_loss: 5.1714 - val_accuracy: 0.2862 - val_precision: 0.3010 - val_recall: 0.2690\n","Epoch 918/10000\n","185/185 [==============================] - 20s 106ms/step - loss: 0.3761 - accuracy: 0.8679 - precision: 0.8949 - recall: 0.8427 - val_loss: 5.1846 - val_accuracy: 0.2862 - val_precision: 0.3003 - val_recall: 0.2705\n","Epoch 919/10000\n","185/185 [==============================] - 22s 120ms/step - loss: 0.3761 - accuracy: 0.8650 - precision: 0.8894 - recall: 0.8420 - val_loss: 4.7542 - val_accuracy: 0.2994 - val_precision: 0.3155 - val_recall: 0.2786\n","Epoch 920/10000\n","185/185 [==============================] - 20s 107ms/step - loss: 0.3711 - accuracy: 0.8736 - precision: 0.8975 - recall: 0.8507 - val_loss: 5.1087 - val_accuracy: 0.2913 - val_precision: 0.3064 - val_recall: 0.2730\n","Epoch 921/10000\n","185/185 [==============================] - 20s 107ms/step - loss: 0.3907 - accuracy: 0.8660 - precision: 0.8932 - recall: 0.8419 - val_loss: 4.9534 - val_accuracy: 0.2888 - val_precision: 0.3009 - val_recall: 0.2695\n","Epoch 922/10000\n","185/185 [==============================] - 20s 106ms/step - loss: 0.3847 - accuracy: 0.8689 - precision: 0.8961 - recall: 0.8437 - val_loss: 5.0008 - val_accuracy: 0.3055 - val_precision: 0.3171 - val_recall: 0.2842\n","Epoch 923/10000\n","185/185 [==============================] - 21s 116ms/step - loss: 0.3495 - accuracy: 0.8811 - precision: 0.9016 - recall: 0.8603 - val_loss: 5.0492 - val_accuracy: 0.3050 - val_precision: 0.3173 - val_recall: 0.2847\n","Epoch 924/10000\n","185/185 [==============================] - 20s 106ms/step - loss: 0.3747 - accuracy: 0.8728 - precision: 0.8985 - recall: 0.8468 - val_loss: 5.2087 - val_accuracy: 0.2903 - val_precision: 0.3056 - val_recall: 0.2736\n","Epoch 925/10000\n","185/185 [==============================] - 20s 106ms/step - loss: 0.3682 - accuracy: 0.8731 - precision: 0.8937 - recall: 0.8463 - val_loss: 5.1751 - val_accuracy: 0.2938 - val_precision: 0.3059 - val_recall: 0.2746\n","Epoch 926/10000\n","185/185 [==============================] - 21s 111ms/step - loss: 0.3756 - accuracy: 0.8716 - precision: 0.8990 - recall: 0.8496 - val_loss: 5.2116 - val_accuracy: 0.2893 - val_precision: 0.3010 - val_recall: 0.2715\n","Epoch 927/10000\n","185/185 [==============================] - 20s 111ms/step - loss: 0.3509 - accuracy: 0.8765 - precision: 0.9020 - recall: 0.8508 - val_loss: 5.1625 - val_accuracy: 0.2989 - val_precision: 0.3088 - val_recall: 0.2781\n","Epoch 928/10000\n","185/185 [==============================] - 20s 106ms/step - loss: 0.3813 - accuracy: 0.8665 - precision: 0.8973 - recall: 0.8429 - val_loss: 5.0725 - val_accuracy: 0.2837 - val_precision: 0.2989 - val_recall: 0.2685\n","Epoch 929/10000\n","185/185 [==============================] - 21s 114ms/step - loss: 0.3668 - accuracy: 0.8775 - precision: 0.9023 - recall: 0.8505 - val_loss: 5.0036 - val_accuracy: 0.2908 - val_precision: 0.3037 - val_recall: 0.2700\n","Epoch 930/10000\n","185/185 [==============================] - 21s 114ms/step - loss: 0.3583 - accuracy: 0.8674 - precision: 0.8964 - recall: 0.8466 - val_loss: 5.0067 - val_accuracy: 0.2974 - val_precision: 0.3125 - val_recall: 0.2791\n","Epoch 931/10000\n","185/185 [==============================] - 20s 110ms/step - loss: 0.3786 - accuracy: 0.8674 - precision: 0.8940 - recall: 0.8447 - val_loss: 5.1444 - val_accuracy: 0.2882 - val_precision: 0.2993 - val_recall: 0.2705\n","Epoch 932/10000\n","185/185 [==============================] - 20s 109ms/step - loss: 0.3430 - accuracy: 0.8822 - precision: 0.9041 - recall: 0.8621 - val_loss: 5.0183 - val_accuracy: 0.2903 - val_precision: 0.3030 - val_recall: 0.2736\n","Epoch 933/10000\n","185/185 [==============================] - 20s 107ms/step - loss: 0.3540 - accuracy: 0.8772 - precision: 0.9044 - recall: 0.8535 - val_loss: 5.1333 - val_accuracy: 0.2969 - val_precision: 0.3069 - val_recall: 0.2806\n","Epoch 934/10000\n","185/185 [==============================] - 21s 114ms/step - loss: 0.3557 - accuracy: 0.8831 - precision: 0.9034 - recall: 0.8591 - val_loss: 4.9759 - val_accuracy: 0.2984 - val_precision: 0.3090 - val_recall: 0.2761\n","Epoch 935/10000\n","185/185 [==============================] - 20s 107ms/step - loss: 0.3640 - accuracy: 0.8731 - precision: 0.8957 - recall: 0.8518 - val_loss: 4.9323 - val_accuracy: 0.2948 - val_precision: 0.3080 - val_recall: 0.2771\n","Epoch 936/10000\n","185/185 [==============================] - 20s 106ms/step - loss: 0.3657 - accuracy: 0.8733 - precision: 0.8981 - recall: 0.8520 - val_loss: 5.0680 - val_accuracy: 0.2938 - val_precision: 0.3081 - val_recall: 0.2781\n","Epoch 937/10000\n","185/185 [==============================] - 20s 108ms/step - loss: 0.3727 - accuracy: 0.8706 - precision: 0.8959 - recall: 0.8495 - val_loss: 5.1997 - val_accuracy: 0.2761 - val_precision: 0.2848 - val_recall: 0.2538\n","Epoch 938/10000\n","185/185 [==============================] - 21s 114ms/step - loss: 0.3607 - accuracy: 0.8787 - precision: 0.9047 - recall: 0.8561 - val_loss: 5.0999 - val_accuracy: 0.2979 - val_precision: 0.3129 - val_recall: 0.2796\n","Epoch 939/10000\n","185/185 [==============================] - 22s 117ms/step - loss: 0.3414 - accuracy: 0.8861 - precision: 0.9082 - recall: 0.8625 - val_loss: 5.1257 - val_accuracy: 0.2827 - val_precision: 0.2941 - val_recall: 0.2619\n","Epoch 940/10000\n","185/185 [==============================] - 20s 108ms/step - loss: 0.3577 - accuracy: 0.8724 - precision: 0.8982 - recall: 0.8483 - val_loss: 5.0190 - val_accuracy: 0.2923 - val_precision: 0.3045 - val_recall: 0.2746\n","Epoch 941/10000\n","185/185 [==============================] - 20s 109ms/step - loss: 0.3611 - accuracy: 0.8736 - precision: 0.8968 - recall: 0.8540 - val_loss: 5.1301 - val_accuracy: 0.2989 - val_precision: 0.3120 - val_recall: 0.2817\n","Epoch 942/10000\n","185/185 [==============================] - 21s 112ms/step - loss: 0.3357 - accuracy: 0.8833 - precision: 0.9076 - recall: 0.8610 - val_loss: 5.1299 - val_accuracy: 0.2943 - val_precision: 0.3049 - val_recall: 0.2766\n","Epoch 943/10000\n","185/185 [==============================] - 20s 107ms/step - loss: 0.3603 - accuracy: 0.8758 - precision: 0.8984 - recall: 0.8555 - val_loss: 5.0609 - val_accuracy: 0.3019 - val_precision: 0.3102 - val_recall: 0.2806\n","Epoch 944/10000\n","185/185 [==============================] - 20s 107ms/step - loss: 0.3441 - accuracy: 0.8821 - precision: 0.9077 - recall: 0.8603 - val_loss: 5.2021 - val_accuracy: 0.2969 - val_precision: 0.3108 - val_recall: 0.2766\n","Epoch 945/10000\n","185/185 [==============================] - 20s 110ms/step - loss: 0.3715 - accuracy: 0.8697 - precision: 0.8951 - recall: 0.8505 - val_loss: 4.9883 - val_accuracy: 0.2989 - val_precision: 0.3142 - val_recall: 0.2801\n","Epoch 946/10000\n","185/185 [==============================] - 21s 114ms/step - loss: 0.3736 - accuracy: 0.8730 - precision: 0.8921 - recall: 0.8537 - val_loss: 5.2609 - val_accuracy: 0.2893 - val_precision: 0.3055 - val_recall: 0.2746\n","Epoch 947/10000\n","185/185 [==============================] - 20s 107ms/step - loss: 0.3520 - accuracy: 0.8785 - precision: 0.9019 - recall: 0.8544 - val_loss: 5.0997 - val_accuracy: 0.3024 - val_precision: 0.3148 - val_recall: 0.2817\n","Epoch 948/10000\n","185/185 [==============================] - 20s 106ms/step - loss: 0.3624 - accuracy: 0.8709 - precision: 0.8971 - recall: 0.8469 - val_loss: 5.0309 - val_accuracy: 0.2882 - val_precision: 0.3052 - val_recall: 0.2710\n","Epoch 949/10000\n","185/185 [==============================] - 22s 122ms/step - loss: 0.3506 - accuracy: 0.8819 - precision: 0.9040 - recall: 0.8604 - val_loss: 5.2486 - val_accuracy: 0.2867 - val_precision: 0.3011 - val_recall: 0.2725\n","Epoch 950/10000\n","185/185 [==============================] - 21s 113ms/step - loss: 0.3673 - accuracy: 0.8763 - precision: 0.8992 - recall: 0.8559 - val_loss: 5.1528 - val_accuracy: 0.3029 - val_precision: 0.3132 - val_recall: 0.2806\n","Epoch 951/10000\n","185/185 [==============================] - 21s 111ms/step - loss: 0.3483 - accuracy: 0.8826 - precision: 0.9031 - recall: 0.8613 - val_loss: 5.1948 - val_accuracy: 0.2923 - val_precision: 0.3027 - val_recall: 0.2685\n","Epoch 952/10000\n","185/185 [==============================] - 22s 121ms/step - loss: 0.3356 - accuracy: 0.8890 - precision: 0.9096 - recall: 0.8665 - val_loss: 5.0874 - val_accuracy: 0.2984 - val_precision: 0.3112 - val_recall: 0.2806\n","Epoch 953/10000\n","185/185 [==============================] - 21s 114ms/step - loss: 0.3416 - accuracy: 0.8817 - precision: 0.9033 - recall: 0.8598 - val_loss: 5.2600 - val_accuracy: 0.2847 - val_precision: 0.3008 - val_recall: 0.2690\n","Epoch 954/10000\n","185/185 [==============================] - 20s 109ms/step - loss: 0.3450 - accuracy: 0.8809 - precision: 0.8993 - recall: 0.8598 - val_loss: 4.9016 - val_accuracy: 0.2948 - val_precision: 0.3157 - val_recall: 0.2786\n","Epoch 955/10000\n","185/185 [==============================] - 20s 109ms/step - loss: 0.3541 - accuracy: 0.8767 - precision: 0.9015 - recall: 0.8520 - val_loss: 5.4223 - val_accuracy: 0.2923 - val_precision: 0.3011 - val_recall: 0.2746\n","Epoch 956/10000\n","185/185 [==============================] - 21s 116ms/step - loss: 0.3569 - accuracy: 0.8745 - precision: 0.8994 - recall: 0.8550 - val_loss: 4.8455 - val_accuracy: 0.2953 - val_precision: 0.3107 - val_recall: 0.2756\n","Epoch 957/10000\n","185/185 [==============================] - 20s 108ms/step - loss: 0.3316 - accuracy: 0.8811 - precision: 0.9058 - recall: 0.8591 - val_loss: 5.1192 - val_accuracy: 0.2847 - val_precision: 0.2959 - val_recall: 0.2660\n","Epoch 958/10000\n","185/185 [==============================] - 20s 109ms/step - loss: 0.3448 - accuracy: 0.8782 - precision: 0.8990 - recall: 0.8569 - val_loss: 5.1599 - val_accuracy: 0.2999 - val_precision: 0.3157 - val_recall: 0.2872\n","Epoch 959/10000\n","185/185 [==============================] - 23s 123ms/step - loss: 0.3447 - accuracy: 0.8757 - precision: 0.8980 - recall: 0.8540 - val_loss: 5.3129 - val_accuracy: 0.2928 - val_precision: 0.3068 - val_recall: 0.2812\n","Epoch 960/10000\n","185/185 [==============================] - 21s 111ms/step - loss: 0.3496 - accuracy: 0.8763 - precision: 0.9031 - recall: 0.8545 - val_loss: 5.1804 - val_accuracy: 0.3045 - val_precision: 0.3166 - val_recall: 0.2867\n","Epoch 961/10000\n","185/185 [==============================] - 20s 110ms/step - loss: 0.3200 - accuracy: 0.8905 - precision: 0.9100 - recall: 0.8675 - val_loss: 4.8912 - val_accuracy: 0.2989 - val_precision: 0.3136 - val_recall: 0.2786\n","Epoch 962/10000\n","185/185 [==============================] - 20s 111ms/step - loss: 0.3440 - accuracy: 0.8814 - precision: 0.9021 - recall: 0.8591 - val_loss: 5.1669 - val_accuracy: 0.2958 - val_precision: 0.3080 - val_recall: 0.2766\n","Epoch 963/10000\n","185/185 [==============================] - 21s 112ms/step - loss: 0.3433 - accuracy: 0.8814 - precision: 0.9052 - recall: 0.8630 - val_loss: 5.3790 - val_accuracy: 0.2913 - val_precision: 0.3073 - val_recall: 0.2776\n","Epoch 964/10000\n","185/185 [==============================] - 20s 108ms/step - loss: 0.3339 - accuracy: 0.8834 - precision: 0.9057 - recall: 0.8604 - val_loss: 5.2413 - val_accuracy: 0.3004 - val_precision: 0.3055 - val_recall: 0.2796\n","Epoch 965/10000\n","185/185 [==============================] - 20s 107ms/step - loss: 0.3446 - accuracy: 0.8836 - precision: 0.9041 - recall: 0.8630 - val_loss: 5.1100 - val_accuracy: 0.2908 - val_precision: 0.3060 - val_recall: 0.2741\n","Epoch 966/10000\n","185/185 [==============================] - 21s 113ms/step - loss: 0.3582 - accuracy: 0.8758 - precision: 0.8974 - recall: 0.8544 - val_loss: 5.1855 - val_accuracy: 0.2812 - val_precision: 0.2951 - val_recall: 0.2685\n","Epoch 967/10000\n","185/185 [==============================] - 20s 110ms/step - loss: 0.3347 - accuracy: 0.8851 - precision: 0.9040 - recall: 0.8637 - val_loss: 5.2355 - val_accuracy: 0.2999 - val_precision: 0.3117 - val_recall: 0.2801\n","Epoch 968/10000\n","185/185 [==============================] - 20s 108ms/step - loss: 0.3459 - accuracy: 0.8770 - precision: 0.9015 - recall: 0.8549 - val_loss: 5.0839 - val_accuracy: 0.2898 - val_precision: 0.3040 - val_recall: 0.2761\n","Epoch 969/10000\n","185/185 [==============================] - 22s 118ms/step - loss: 0.3519 - accuracy: 0.8795 - precision: 0.9024 - recall: 0.8588 - val_loss: 5.0190 - val_accuracy: 0.2913 - val_precision: 0.3063 - val_recall: 0.2776\n","Epoch 970/10000\n","185/185 [==============================] - 21s 113ms/step - loss: 0.3485 - accuracy: 0.8794 - precision: 0.9031 - recall: 0.8562 - val_loss: 5.3466 - val_accuracy: 0.2862 - val_precision: 0.3013 - val_recall: 0.2685\n","Epoch 971/10000\n","185/185 [==============================] - 20s 107ms/step - loss: 0.3280 - accuracy: 0.8841 - precision: 0.9070 - recall: 0.8638 - val_loss: 5.1270 - val_accuracy: 0.2918 - val_precision: 0.3042 - val_recall: 0.2730\n","Epoch 972/10000\n","185/185 [==============================] - 20s 107ms/step - loss: 0.3546 - accuracy: 0.8753 - precision: 0.8971 - recall: 0.8544 - val_loss: 5.1890 - val_accuracy: 0.2953 - val_precision: 0.3054 - val_recall: 0.2771\n","Epoch 973/10000\n","185/185 [==============================] - 21s 111ms/step - loss: 0.3474 - accuracy: 0.8777 - precision: 0.9029 - recall: 0.8557 - val_loss: 5.0283 - val_accuracy: 0.2857 - val_precision: 0.3002 - val_recall: 0.2695\n","Epoch 974/10000\n","185/185 [==============================] - 20s 110ms/step - loss: 0.3565 - accuracy: 0.8741 - precision: 0.9003 - recall: 0.8547 - val_loss: 5.1708 - val_accuracy: 0.3014 - val_precision: 0.3147 - val_recall: 0.2817\n","Epoch 975/10000\n","185/185 [==============================] - 20s 109ms/step - loss: 0.3628 - accuracy: 0.8812 - precision: 0.9022 - recall: 0.8572 - val_loss: 5.1888 - val_accuracy: 0.2908 - val_precision: 0.3068 - val_recall: 0.2751\n","Epoch 976/10000\n","185/185 [==============================] - 20s 108ms/step - loss: 0.3365 - accuracy: 0.8828 - precision: 0.9059 - recall: 0.8632 - val_loss: 5.0415 - val_accuracy: 0.3080 - val_precision: 0.3236 - val_recall: 0.2913\n","Epoch 977/10000\n","185/185 [==============================] - 21s 115ms/step - loss: 0.3507 - accuracy: 0.8777 - precision: 0.9011 - recall: 0.8555 - val_loss: 5.0959 - val_accuracy: 0.3060 - val_precision: 0.3186 - val_recall: 0.2842\n","Epoch 978/10000\n","185/185 [==============================] - 20s 109ms/step - loss: 0.3704 - accuracy: 0.8711 - precision: 0.8921 - recall: 0.8495 - val_loss: 5.0857 - val_accuracy: 0.2989 - val_precision: 0.3077 - val_recall: 0.2761\n","Epoch 979/10000\n","185/185 [==============================] - 21s 116ms/step - loss: 0.3345 - accuracy: 0.8856 - precision: 0.9060 - recall: 0.8616 - val_loss: 5.1059 - val_accuracy: 0.3004 - val_precision: 0.3139 - val_recall: 0.2837\n","Epoch 980/10000\n","185/185 [==============================] - 21s 114ms/step - loss: 0.3279 - accuracy: 0.8870 - precision: 0.9085 - recall: 0.8657 - val_loss: 5.1075 - val_accuracy: 0.2888 - val_precision: 0.3026 - val_recall: 0.2710\n","Epoch 981/10000\n","185/185 [==============================] - 20s 109ms/step - loss: 0.3327 - accuracy: 0.8843 - precision: 0.9045 - recall: 0.8638 - val_loss: 5.2111 - val_accuracy: 0.2837 - val_precision: 0.2953 - val_recall: 0.2660\n","Epoch 982/10000\n","185/185 [==============================] - 20s 108ms/step - loss: 0.3370 - accuracy: 0.8841 - precision: 0.9081 - recall: 0.8669 - val_loss: 5.0809 - val_accuracy: 0.3060 - val_precision: 0.3235 - val_recall: 0.2933\n","Epoch 983/10000\n","185/185 [==============================] - 20s 109ms/step - loss: 0.3352 - accuracy: 0.8880 - precision: 0.9092 - recall: 0.8681 - val_loss: 5.0382 - val_accuracy: 0.3004 - val_precision: 0.3146 - val_recall: 0.2837\n","Epoch 984/10000\n","185/185 [==============================] - 22s 116ms/step - loss: 0.3381 - accuracy: 0.8812 - precision: 0.9085 - recall: 0.8603 - val_loss: 5.2947 - val_accuracy: 0.2862 - val_precision: 0.2971 - val_recall: 0.2655\n","Epoch 985/10000\n","185/185 [==============================] - 20s 109ms/step - loss: 0.3162 - accuracy: 0.8898 - precision: 0.9112 - recall: 0.8699 - val_loss: 5.2794 - val_accuracy: 0.2913 - val_precision: 0.3055 - val_recall: 0.2796\n","Epoch 986/10000\n","185/185 [==============================] - 20s 108ms/step - loss: 0.3359 - accuracy: 0.8866 - precision: 0.9108 - recall: 0.8664 - val_loss: 5.3389 - val_accuracy: 0.2852 - val_precision: 0.2971 - val_recall: 0.2725\n","Epoch 987/10000\n","185/185 [==============================] - 21s 116ms/step - loss: 0.3146 - accuracy: 0.8888 - precision: 0.9107 - recall: 0.8714 - val_loss: 5.1306 - val_accuracy: 0.3045 - val_precision: 0.3153 - val_recall: 0.2837\n","Epoch 988/10000\n","185/185 [==============================] - 20s 110ms/step - loss: 0.3143 - accuracy: 0.8931 - precision: 0.9135 - recall: 0.8723 - val_loss: 5.1580 - val_accuracy: 0.2872 - val_precision: 0.3016 - val_recall: 0.2756\n","Epoch 989/10000\n","185/185 [==============================] - 20s 110ms/step - loss: 0.3185 - accuracy: 0.8914 - precision: 0.9105 - recall: 0.8694 - val_loss: 5.0184 - val_accuracy: 0.3090 - val_precision: 0.3268 - val_recall: 0.2958\n","Epoch 990/10000\n","185/185 [==============================] - 22s 120ms/step - loss: 0.3074 - accuracy: 0.8971 - precision: 0.9154 - recall: 0.8777 - val_loss: 5.3482 - val_accuracy: 0.2847 - val_precision: 0.2971 - val_recall: 0.2685\n","Epoch 991/10000\n","185/185 [==============================] - 22s 116ms/step - loss: 0.3186 - accuracy: 0.8878 - precision: 0.9095 - recall: 0.8692 - val_loss: 5.4053 - val_accuracy: 0.2852 - val_precision: 0.2976 - val_recall: 0.2670\n","Epoch 992/10000\n","185/185 [==============================] - 20s 110ms/step - loss: 0.3332 - accuracy: 0.8876 - precision: 0.9076 - recall: 0.8664 - val_loss: 5.0922 - val_accuracy: 0.2948 - val_precision: 0.3061 - val_recall: 0.2766\n","Epoch 993/10000\n","185/185 [==============================] - 20s 108ms/step - loss: 0.3095 - accuracy: 0.8946 - precision: 0.9166 - recall: 0.8731 - val_loss: 5.2815 - val_accuracy: 0.3009 - val_precision: 0.3118 - val_recall: 0.2837\n","Epoch 994/10000\n","185/185 [==============================] - 20s 108ms/step - loss: 0.3283 - accuracy: 0.8902 - precision: 0.9111 - recall: 0.8670 - val_loss: 5.1389 - val_accuracy: 0.3014 - val_precision: 0.3174 - val_recall: 0.2852\n","Epoch 995/10000\n","185/185 [==============================] - 21s 115ms/step - loss: 0.3132 - accuracy: 0.8898 - precision: 0.9117 - recall: 0.8704 - val_loss: 5.5027 - val_accuracy: 0.2958 - val_precision: 0.2991 - val_recall: 0.2746\n","Epoch 996/10000\n","185/185 [==============================] - 20s 108ms/step - loss: 0.3219 - accuracy: 0.8915 - precision: 0.9119 - recall: 0.8713 - val_loss: 5.1869 - val_accuracy: 0.3009 - val_precision: 0.3148 - val_recall: 0.2842\n","Epoch 997/10000\n","185/185 [==============================] - 21s 111ms/step - loss: 0.3377 - accuracy: 0.8839 - precision: 0.9048 - recall: 0.8652 - val_loss: 5.0481 - val_accuracy: 0.2903 - val_precision: 0.3031 - val_recall: 0.2741\n","Epoch 998/10000\n","185/185 [==============================] - 21s 115ms/step - loss: 0.3421 - accuracy: 0.8775 - precision: 0.9028 - recall: 0.8581 - val_loss: 5.3401 - val_accuracy: 0.2964 - val_precision: 0.3088 - val_recall: 0.2801\n","Epoch 999/10000\n","185/185 [==============================] - 21s 112ms/step - loss: 0.3311 - accuracy: 0.8882 - precision: 0.9088 - recall: 0.8665 - val_loss: 5.4276 - val_accuracy: 0.3024 - val_precision: 0.3101 - val_recall: 0.2817\n","Epoch 1000/10000\n","185/185 [==============================] - 21s 116ms/step - loss: 0.3272 - accuracy: 0.8868 - precision: 0.9076 - recall: 0.8667 - val_loss: 5.1907 - val_accuracy: 0.2989 - val_precision: 0.3105 - val_recall: 0.2822\n","Epoch 1001/10000\n","185/185 [==============================] - 20s 107ms/step - loss: 0.3186 - accuracy: 0.8882 - precision: 0.9087 - recall: 0.8679 - val_loss: 5.3730 - val_accuracy: 0.2898 - val_precision: 0.3043 - val_recall: 0.2746\n","Epoch 1002/10000\n","185/185 [==============================] - 20s 107ms/step - loss: 0.3212 - accuracy: 0.8861 - precision: 0.9045 - recall: 0.8657 - val_loss: 5.1849 - val_accuracy: 0.2974 - val_precision: 0.3123 - val_recall: 0.2801\n","Epoch 1003/10000\n","185/185 [==============================] - 21s 115ms/step - loss: 0.3304 - accuracy: 0.8853 - precision: 0.9069 - recall: 0.8675 - val_loss: 5.1143 - val_accuracy: 0.2979 - val_precision: 0.3085 - val_recall: 0.2786\n","Epoch 1004/10000\n","185/185 [==============================] - 20s 110ms/step - loss: 0.3185 - accuracy: 0.8880 - precision: 0.9081 - recall: 0.8699 - val_loss: 5.1270 - val_accuracy: 0.2908 - val_precision: 0.3064 - val_recall: 0.2781\n","Epoch 1005/10000\n","185/185 [==============================] - 20s 109ms/step - loss: 0.3318 - accuracy: 0.8834 - precision: 0.9074 - recall: 0.8672 - val_loss: 5.3058 - val_accuracy: 0.2882 - val_precision: 0.3022 - val_recall: 0.2736\n","Epoch 1006/10000\n","185/185 [==============================] - 21s 114ms/step - loss: 0.3149 - accuracy: 0.8937 - precision: 0.9115 - recall: 0.8714 - val_loss: 5.1838 - val_accuracy: 0.2979 - val_precision: 0.3101 - val_recall: 0.2796\n","Epoch 1007/10000\n","185/185 [==============================] - 21s 113ms/step - loss: 0.3282 - accuracy: 0.8897 - precision: 0.9089 - recall: 0.8677 - val_loss: 5.1492 - val_accuracy: 0.2953 - val_precision: 0.3119 - val_recall: 0.2801\n","Epoch 1008/10000\n","185/185 [==============================] - 20s 110ms/step - loss: 0.3147 - accuracy: 0.8868 - precision: 0.9069 - recall: 0.8687 - val_loss: 5.1899 - val_accuracy: 0.3176 - val_precision: 0.3337 - val_recall: 0.3019\n","Epoch 1009/10000\n","185/185 [==============================] - 20s 109ms/step - loss: 0.2962 - accuracy: 0.8961 - precision: 0.9154 - recall: 0.8775 - val_loss: 5.4050 - val_accuracy: 0.2877 - val_precision: 0.3018 - val_recall: 0.2730\n","Epoch 1010/10000\n","185/185 [==============================] - 22s 119ms/step - loss: 0.3356 - accuracy: 0.8849 - precision: 0.9069 - recall: 0.8637 - val_loss: 5.1493 - val_accuracy: 0.2948 - val_precision: 0.3028 - val_recall: 0.2751\n","Epoch 1011/10000\n","185/185 [==============================] - 22s 117ms/step - loss: 0.3252 - accuracy: 0.8885 - precision: 0.9107 - recall: 0.8706 - val_loss: 5.2265 - val_accuracy: 0.2923 - val_precision: 0.3125 - val_recall: 0.2812\n","Epoch 1012/10000\n","185/185 [==============================] - 20s 110ms/step - loss: 0.3377 - accuracy: 0.8878 - precision: 0.9057 - recall: 0.8697 - val_loss: 5.1936 - val_accuracy: 0.2862 - val_precision: 0.3025 - val_recall: 0.2705\n","Epoch 1013/10000\n","185/185 [==============================] - 22s 118ms/step - loss: 0.3064 - accuracy: 0.8954 - precision: 0.9122 - recall: 0.8743 - val_loss: 5.1177 - val_accuracy: 0.2958 - val_precision: 0.3144 - val_recall: 0.2801\n","Epoch 1014/10000\n","185/185 [==============================] - 21s 112ms/step - loss: 0.3113 - accuracy: 0.8920 - precision: 0.9141 - recall: 0.8701 - val_loss: 5.4587 - val_accuracy: 0.2842 - val_precision: 0.2998 - val_recall: 0.2730\n","Epoch 1015/10000\n","185/185 [==============================] - 20s 109ms/step - loss: 0.3139 - accuracy: 0.8941 - precision: 0.9136 - recall: 0.8750 - val_loss: 5.0649 - val_accuracy: 0.2918 - val_precision: 0.3022 - val_recall: 0.2736\n","Epoch 1016/10000\n","185/185 [==============================] - 21s 114ms/step - loss: 0.3305 - accuracy: 0.8885 - precision: 0.9070 - recall: 0.8681 - val_loss: 5.1059 - val_accuracy: 0.2918 - val_precision: 0.3026 - val_recall: 0.2741\n","Epoch 1017/10000\n","185/185 [==============================] - 21s 111ms/step - loss: 0.3205 - accuracy: 0.8912 - precision: 0.9105 - recall: 0.8735 - val_loss: 5.4068 - val_accuracy: 0.2827 - val_precision: 0.2943 - val_recall: 0.2660\n","Epoch 1018/10000\n","185/185 [==============================] - 20s 109ms/step - loss: 0.3257 - accuracy: 0.8883 - precision: 0.9073 - recall: 0.8684 - val_loss: 5.3071 - val_accuracy: 0.2888 - val_precision: 0.3022 - val_recall: 0.2741\n","Epoch 1019/10000\n","185/185 [==============================] - 20s 110ms/step - loss: 0.3208 - accuracy: 0.8897 - precision: 0.9098 - recall: 0.8708 - val_loss: 5.5257 - val_accuracy: 0.2984 - val_precision: 0.3111 - val_recall: 0.2817\n","Epoch 1020/10000\n","185/185 [==============================] - 22s 116ms/step - loss: 0.3179 - accuracy: 0.8887 - precision: 0.9064 - recall: 0.8716 - val_loss: 5.1374 - val_accuracy: 0.2953 - val_precision: 0.3105 - val_recall: 0.2806\n","Epoch 1021/10000\n","185/185 [==============================] - 22s 118ms/step - loss: 0.3112 - accuracy: 0.8927 - precision: 0.9142 - recall: 0.8751 - val_loss: 5.2199 - val_accuracy: 0.2903 - val_precision: 0.3011 - val_recall: 0.2725\n","Epoch 1022/10000\n","185/185 [==============================] - 20s 110ms/step - loss: 0.2927 - accuracy: 0.9010 - precision: 0.9191 - recall: 0.8826 - val_loss: 5.0769 - val_accuracy: 0.3075 - val_precision: 0.3209 - val_recall: 0.2923\n","Epoch 1023/10000\n","185/185 [==============================] - 20s 110ms/step - loss: 0.3046 - accuracy: 0.8939 - precision: 0.9120 - recall: 0.8757 - val_loss: 5.3018 - val_accuracy: 0.3014 - val_precision: 0.3157 - val_recall: 0.2847\n","Epoch 1024/10000\n","185/185 [==============================] - 22s 116ms/step - loss: 0.3259 - accuracy: 0.8853 - precision: 0.9071 - recall: 0.8682 - val_loss: 5.3121 - val_accuracy: 0.2913 - val_precision: 0.3049 - val_recall: 0.2756\n","Epoch 1025/10000\n","185/185 [==============================] - 20s 109ms/step - loss: 0.3369 - accuracy: 0.8834 - precision: 0.9049 - recall: 0.8662 - val_loss: 5.4095 - val_accuracy: 0.2938 - val_precision: 0.3037 - val_recall: 0.2730\n","Epoch 1026/10000\n","185/185 [==============================] - 20s 109ms/step - loss: 0.3198 - accuracy: 0.8936 - precision: 0.9136 - recall: 0.8718 - val_loss: 5.3145 - val_accuracy: 0.3080 - val_precision: 0.3220 - val_recall: 0.2933\n","Epoch 1027/10000\n","185/185 [==============================] - 21s 116ms/step - loss: 0.3099 - accuracy: 0.8968 - precision: 0.9164 - recall: 0.8802 - val_loss: 5.2211 - val_accuracy: 0.2938 - val_precision: 0.3059 - val_recall: 0.2806\n","Epoch 1028/10000\n","185/185 [==============================] - 20s 110ms/step - loss: 0.3101 - accuracy: 0.8944 - precision: 0.9155 - recall: 0.8753 - val_loss: 5.2995 - val_accuracy: 0.2964 - val_precision: 0.3106 - val_recall: 0.2832\n","Epoch 1029/10000\n","185/185 [==============================] - 20s 109ms/step - loss: 0.3000 - accuracy: 0.8961 - precision: 0.9158 - recall: 0.8767 - val_loss: 5.2887 - val_accuracy: 0.2999 - val_precision: 0.3117 - val_recall: 0.2796\n","Epoch 1030/10000\n","185/185 [==============================] - 21s 112ms/step - loss: 0.3243 - accuracy: 0.8838 - precision: 0.9046 - recall: 0.8670 - val_loss: 5.2496 - val_accuracy: 0.2964 - val_precision: 0.3119 - val_recall: 0.2832\n","Epoch 1031/10000\n","185/185 [==============================] - 21s 114ms/step - loss: 0.3257 - accuracy: 0.8895 - precision: 0.9076 - recall: 0.8708 - val_loss: 5.2402 - val_accuracy: 0.2984 - val_precision: 0.3139 - val_recall: 0.2862\n","Epoch 1032/10000\n","185/185 [==============================] - 22s 119ms/step - loss: 0.3195 - accuracy: 0.8929 - precision: 0.9100 - recall: 0.8746 - val_loss: 5.2372 - val_accuracy: 0.3075 - val_precision: 0.3201 - val_recall: 0.2948\n","Epoch 1033/10000\n","185/185 [==============================] - 21s 111ms/step - loss: 0.3130 - accuracy: 0.8924 - precision: 0.9123 - recall: 0.8735 - val_loss: 5.2157 - val_accuracy: 0.3045 - val_precision: 0.3103 - val_recall: 0.2847\n","Epoch 1034/10000\n","185/185 [==============================] - 22s 118ms/step - loss: 0.3208 - accuracy: 0.8843 - precision: 0.9059 - recall: 0.8640 - val_loss: 5.3023 - val_accuracy: 0.2852 - val_precision: 0.2981 - val_recall: 0.2655\n","Epoch 1035/10000\n","185/185 [==============================] - 21s 112ms/step - loss: 0.2988 - accuracy: 0.8947 - precision: 0.9144 - recall: 0.8758 - val_loss: 5.2544 - val_accuracy: 0.2979 - val_precision: 0.3149 - val_recall: 0.2888\n","Epoch 1036/10000\n","185/185 [==============================] - 20s 111ms/step - loss: 0.2924 - accuracy: 0.8993 - precision: 0.9198 - recall: 0.8811 - val_loss: 5.2299 - val_accuracy: 0.2974 - val_precision: 0.3099 - val_recall: 0.2817\n","Epoch 1037/10000\n","185/185 [==============================] - 21s 115ms/step - loss: 0.3245 - accuracy: 0.8909 - precision: 0.9130 - recall: 0.8728 - val_loss: 5.4142 - val_accuracy: 0.2969 - val_precision: 0.3118 - val_recall: 0.2837\n","Epoch 1038/10000\n","185/185 [==============================] - 20s 110ms/step - loss: 0.2890 - accuracy: 0.9008 - precision: 0.9164 - recall: 0.8855 - val_loss: 5.4959 - val_accuracy: 0.3055 - val_precision: 0.3147 - val_recall: 0.2877\n","Epoch 1039/10000\n","185/185 [==============================] - 20s 110ms/step - loss: 0.3013 - accuracy: 0.8949 - precision: 0.9137 - recall: 0.8763 - val_loss: 5.3418 - val_accuracy: 0.2964 - val_precision: 0.3100 - val_recall: 0.2776\n","Epoch 1040/10000\n","185/185 [==============================] - 20s 109ms/step - loss: 0.2842 - accuracy: 0.8978 - precision: 0.9163 - recall: 0.8824 - val_loss: 5.4174 - val_accuracy: 0.2908 - val_precision: 0.2996 - val_recall: 0.2741\n","Epoch 1041/10000\n","185/185 [==============================] - 22s 117ms/step - loss: 0.3179 - accuracy: 0.8882 - precision: 0.9090 - recall: 0.8711 - val_loss: 5.4615 - val_accuracy: 0.2817 - val_precision: 0.2912 - val_recall: 0.2634\n","Epoch 1042/10000\n","185/185 [==============================] - 21s 112ms/step - loss: 0.2878 - accuracy: 0.8988 - precision: 0.9167 - recall: 0.8828 - val_loss: 5.1944 - val_accuracy: 0.2958 - val_precision: 0.3091 - val_recall: 0.2827\n","Epoch 1043/10000\n","185/185 [==============================] - 22s 117ms/step - loss: 0.2670 - accuracy: 0.9062 - precision: 0.9240 - recall: 0.8892 - val_loss: 5.4797 - val_accuracy: 0.3050 - val_precision: 0.3157 - val_recall: 0.2872\n","Epoch 1044/10000\n","185/185 [==============================] - 21s 115ms/step - loss: 0.2707 - accuracy: 0.9064 - precision: 0.9243 - recall: 0.8910 - val_loss: 5.3096 - val_accuracy: 0.2918 - val_precision: 0.3081 - val_recall: 0.2786\n","Epoch 1045/10000\n","185/185 [==============================] - 21s 114ms/step - loss: 0.3150 - accuracy: 0.8941 - precision: 0.9117 - recall: 0.8775 - val_loss: 5.3905 - val_accuracy: 0.2822 - val_precision: 0.2972 - val_recall: 0.2655\n","Epoch 1046/10000\n","185/185 [==============================] - 20s 110ms/step - loss: 0.2961 - accuracy: 0.8959 - precision: 0.9175 - recall: 0.8812 - val_loss: 5.3551 - val_accuracy: 0.2953 - val_precision: 0.3051 - val_recall: 0.2791\n","Epoch 1047/10000\n","185/185 [==============================] - 20s 110ms/step - loss: 0.3190 - accuracy: 0.8873 - precision: 0.9053 - recall: 0.8721 - val_loss: 5.4415 - val_accuracy: 0.2943 - val_precision: 0.2985 - val_recall: 0.2695\n","Epoch 1048/10000\n","185/185 [==============================] - 22s 118ms/step - loss: 0.3061 - accuracy: 0.8936 - precision: 0.9129 - recall: 0.8745 - val_loss: 5.3485 - val_accuracy: 0.2913 - val_precision: 0.3083 - val_recall: 0.2791\n","Epoch 1049/10000\n","185/185 [==============================] - 20s 109ms/step - loss: 0.3151 - accuracy: 0.8924 - precision: 0.9101 - recall: 0.8755 - val_loss: 5.1495 - val_accuracy: 0.3070 - val_precision: 0.3171 - val_recall: 0.2837\n","Epoch 1050/10000\n","185/185 [==============================] - 20s 110ms/step - loss: 0.2970 - accuracy: 0.8949 - precision: 0.9144 - recall: 0.8809 - val_loss: 5.4847 - val_accuracy: 0.2893 - val_precision: 0.2966 - val_recall: 0.2710\n","Epoch 1051/10000\n","185/185 [==============================] - 22s 117ms/step - loss: 0.2980 - accuracy: 0.8986 - precision: 0.9183 - recall: 0.8792 - val_loss: 5.2297 - val_accuracy: 0.2908 - val_precision: 0.3075 - val_recall: 0.2771\n","Epoch 1052/10000\n","185/185 [==============================] - 20s 110ms/step - loss: 0.2911 - accuracy: 0.9023 - precision: 0.9202 - recall: 0.8870 - val_loss: 5.3964 - val_accuracy: 0.2969 - val_precision: 0.3084 - val_recall: 0.2776\n","Epoch 1053/10000\n","185/185 [==============================] - 20s 109ms/step - loss: 0.2763 - accuracy: 0.9057 - precision: 0.9242 - recall: 0.8883 - val_loss: 5.2599 - val_accuracy: 0.2948 - val_precision: 0.3084 - val_recall: 0.2781\n","Epoch 1054/10000\n","185/185 [==============================] - 22s 118ms/step - loss: 0.2969 - accuracy: 0.8947 - precision: 0.9145 - recall: 0.8777 - val_loss: 5.2293 - val_accuracy: 0.2877 - val_precision: 0.3025 - val_recall: 0.2746\n","Epoch 1055/10000\n","185/185 [==============================] - 22s 118ms/step - loss: 0.2862 - accuracy: 0.8971 - precision: 0.9180 - recall: 0.8812 - val_loss: 5.4881 - val_accuracy: 0.2812 - val_precision: 0.2966 - val_recall: 0.2690\n","Epoch 1056/10000\n","185/185 [==============================] - 20s 111ms/step - loss: 0.3136 - accuracy: 0.8925 - precision: 0.9102 - recall: 0.8765 - val_loss: 5.4607 - val_accuracy: 0.2715 - val_precision: 0.2843 - val_recall: 0.2584\n","Epoch 1057/10000\n","185/185 [==============================] - 20s 111ms/step - loss: 0.3112 - accuracy: 0.8907 - precision: 0.9103 - recall: 0.8731 - val_loss: 5.5010 - val_accuracy: 0.2893 - val_precision: 0.2938 - val_recall: 0.2660\n","Epoch 1058/10000\n","185/185 [==============================] - 22s 117ms/step - loss: 0.3205 - accuracy: 0.8888 - precision: 0.9085 - recall: 0.8709 - val_loss: 5.3006 - val_accuracy: 0.2979 - val_precision: 0.3053 - val_recall: 0.2781\n","Epoch 1059/10000\n","185/185 [==============================] - 21s 111ms/step - loss: 0.2968 - accuracy: 0.8995 - precision: 0.9155 - recall: 0.8822 - val_loss: 5.5887 - val_accuracy: 0.2837 - val_precision: 0.2903 - val_recall: 0.2675\n","Epoch 1060/10000\n","185/185 [==============================] - 20s 109ms/step - loss: 0.2970 - accuracy: 0.8968 - precision: 0.9168 - recall: 0.8806 - val_loss: 5.2556 - val_accuracy: 0.3009 - val_precision: 0.3154 - val_recall: 0.2857\n","Epoch 1061/10000\n","185/185 [==============================] - 20s 110ms/step - loss: 0.2945 - accuracy: 0.8986 - precision: 0.9171 - recall: 0.8806 - val_loss: 5.2994 - val_accuracy: 0.2898 - val_precision: 0.3016 - val_recall: 0.2741\n","Epoch 1062/10000\n","185/185 [==============================] - 22s 119ms/step - loss: 0.2971 - accuracy: 0.8958 - precision: 0.9147 - recall: 0.8792 - val_loss: 5.1941 - val_accuracy: 0.2953 - val_precision: 0.3104 - val_recall: 0.2812\n","Epoch 1063/10000\n","185/185 [==============================] - 21s 111ms/step - loss: 0.3023 - accuracy: 0.8910 - precision: 0.9136 - recall: 0.8767 - val_loss: 5.2671 - val_accuracy: 0.3014 - val_precision: 0.3088 - val_recall: 0.2761\n","Epoch 1064/10000\n","185/185 [==============================] - 20s 109ms/step - loss: 0.2954 - accuracy: 0.9025 - precision: 0.9229 - recall: 0.8855 - val_loss: 5.6057 - val_accuracy: 0.2867 - val_precision: 0.2998 - val_recall: 0.2746\n","Epoch 1065/10000\n","185/185 [==============================] - 21s 115ms/step - loss: 0.2923 - accuracy: 0.9007 - precision: 0.9207 - recall: 0.8826 - val_loss: 5.5128 - val_accuracy: 0.2974 - val_precision: 0.3082 - val_recall: 0.2812\n","Epoch 1066/10000\n","185/185 [==============================] - 22s 117ms/step - loss: 0.2717 - accuracy: 0.9035 - precision: 0.9205 - recall: 0.8887 - val_loss: 5.2642 - val_accuracy: 0.3080 - val_precision: 0.3206 - val_recall: 0.2938\n","Epoch 1067/10000\n","185/185 [==============================] - 20s 110ms/step - loss: 0.2906 - accuracy: 0.8980 - precision: 0.9184 - recall: 0.8807 - val_loss: 5.3400 - val_accuracy: 0.3080 - val_precision: 0.3190 - val_recall: 0.2898\n","Epoch 1068/10000\n","185/185 [==============================] - 22s 117ms/step - loss: 0.2937 - accuracy: 0.8964 - precision: 0.9134 - recall: 0.8826 - val_loss: 5.4379 - val_accuracy: 0.2913 - val_precision: 0.3037 - val_recall: 0.2756\n","Epoch 1069/10000\n","185/185 [==============================] - 21s 111ms/step - loss: 0.3156 - accuracy: 0.8941 - precision: 0.9125 - recall: 0.8790 - val_loss: 5.3991 - val_accuracy: 0.2893 - val_precision: 0.2994 - val_recall: 0.2715\n","Epoch 1070/10000\n","185/185 [==============================] - 20s 110ms/step - loss: 0.3039 - accuracy: 0.8958 - precision: 0.9124 - recall: 0.8784 - val_loss: 5.2762 - val_accuracy: 0.3075 - val_precision: 0.3208 - val_recall: 0.2928\n","Epoch 1071/10000\n","185/185 [==============================] - 20s 110ms/step - loss: 0.2755 - accuracy: 0.9083 - precision: 0.9272 - recall: 0.8888 - val_loss: 5.4585 - val_accuracy: 0.2847 - val_precision: 0.2969 - val_recall: 0.2660\n","Epoch 1072/10000\n","185/185 [==============================] - 22s 117ms/step - loss: 0.2969 - accuracy: 0.8963 - precision: 0.9132 - recall: 0.8784 - val_loss: 5.3765 - val_accuracy: 0.3034 - val_precision: 0.3113 - val_recall: 0.2842\n","Epoch 1073/10000\n","185/185 [==============================] - 20s 110ms/step - loss: 0.2968 - accuracy: 0.8968 - precision: 0.9163 - recall: 0.8804 - val_loss: 5.1723 - val_accuracy: 0.3019 - val_precision: 0.3096 - val_recall: 0.2796\n","Epoch 1074/10000\n","185/185 [==============================] - 20s 110ms/step - loss: 0.2864 - accuracy: 0.9013 - precision: 0.9194 - recall: 0.8848 - val_loss: 5.4288 - val_accuracy: 0.2928 - val_precision: 0.3056 - val_recall: 0.2812\n","Epoch 1075/10000\n","185/185 [==============================] - 21s 115ms/step - loss: 0.2906 - accuracy: 0.9030 - precision: 0.9197 - recall: 0.8858 - val_loss: 5.3395 - val_accuracy: 0.2923 - val_precision: 0.3025 - val_recall: 0.2751\n","Epoch 1076/10000\n","185/185 [==============================] - 22s 120ms/step - loss: 0.2752 - accuracy: 0.9030 - precision: 0.9235 - recall: 0.8897 - val_loss: 5.2897 - val_accuracy: 0.2882 - val_precision: 0.3077 - val_recall: 0.2776\n","Epoch 1077/10000\n","185/185 [==============================] - 23s 122ms/step - loss: 0.2920 - accuracy: 0.9005 - precision: 0.9189 - recall: 0.8839 - val_loss: 5.2892 - val_accuracy: 0.2948 - val_precision: 0.3088 - val_recall: 0.2806\n","Epoch 1078/10000\n","185/185 [==============================] - 20s 111ms/step - loss: 0.2909 - accuracy: 0.9018 - precision: 0.9176 - recall: 0.8826 - val_loss: 5.2924 - val_accuracy: 0.2776 - val_precision: 0.2924 - val_recall: 0.2639\n","Epoch 1079/10000\n","185/185 [==============================] - 21s 116ms/step - loss: 0.3000 - accuracy: 0.9003 - precision: 0.9194 - recall: 0.8831 - val_loss: 5.4693 - val_accuracy: 0.2964 - val_precision: 0.3111 - val_recall: 0.2842\n","Epoch 1080/10000\n","185/185 [==============================] - 21s 112ms/step - loss: 0.2992 - accuracy: 0.8974 - precision: 0.9122 - recall: 0.8795 - val_loss: 5.3634 - val_accuracy: 0.2999 - val_precision: 0.3095 - val_recall: 0.2801\n","Epoch 1081/10000\n","185/185 [==============================] - 20s 110ms/step - loss: 0.2726 - accuracy: 0.9059 - precision: 0.9234 - recall: 0.8902 - val_loss: 5.2316 - val_accuracy: 0.2964 - val_precision: 0.3139 - val_recall: 0.2812\n","Epoch 1082/10000\n","185/185 [==============================] - 21s 112ms/step - loss: 0.3111 - accuracy: 0.8912 - precision: 0.9097 - recall: 0.8745 - val_loss: 5.6322 - val_accuracy: 0.2908 - val_precision: 0.3008 - val_recall: 0.2781\n","Epoch 1083/10000\n","185/185 [==============================] - 22s 118ms/step - loss: 0.3091 - accuracy: 0.8937 - precision: 0.9132 - recall: 0.8785 - val_loss: 5.5244 - val_accuracy: 0.2801 - val_precision: 0.2850 - val_recall: 0.2639\n","Epoch 1084/10000\n","185/185 [==============================] - 20s 110ms/step - loss: 0.2756 - accuracy: 0.9071 - precision: 0.9258 - recall: 0.8900 - val_loss: 5.3922 - val_accuracy: 0.3034 - val_precision: 0.3170 - val_recall: 0.2913\n","Epoch 1085/10000\n","185/185 [==============================] - 20s 111ms/step - loss: 0.2808 - accuracy: 0.9020 - precision: 0.9192 - recall: 0.8865 - val_loss: 5.4510 - val_accuracy: 0.2938 - val_precision: 0.3072 - val_recall: 0.2781\n","Epoch 1086/10000\n","185/185 [==============================] - 21s 115ms/step - loss: 0.2704 - accuracy: 0.9045 - precision: 0.9218 - recall: 0.8883 - val_loss: 5.2292 - val_accuracy: 0.2938 - val_precision: 0.3018 - val_recall: 0.2736\n","Epoch 1087/10000\n","185/185 [==============================] - 21s 113ms/step - loss: 0.2995 - accuracy: 0.8969 - precision: 0.9179 - recall: 0.8817 - val_loss: 5.4181 - val_accuracy: 0.2923 - val_precision: 0.3010 - val_recall: 0.2736\n","Epoch 1088/10000\n","185/185 [==============================] - 22s 120ms/step - loss: 0.2876 - accuracy: 0.9000 - precision: 0.9168 - recall: 0.8856 - val_loss: 5.3910 - val_accuracy: 0.2888 - val_precision: 0.3025 - val_recall: 0.2720\n","Epoch 1089/10000\n","185/185 [==============================] - 21s 111ms/step - loss: 0.2842 - accuracy: 0.9045 - precision: 0.9216 - recall: 0.8871 - val_loss: 5.4518 - val_accuracy: 0.2867 - val_precision: 0.3007 - val_recall: 0.2751\n","Epoch 1090/10000\n","185/185 [==============================] - 21s 111ms/step - loss: 0.2844 - accuracy: 0.9008 - precision: 0.9175 - recall: 0.8834 - val_loss: 5.4980 - val_accuracy: 0.3034 - val_precision: 0.3145 - val_recall: 0.2882\n","Epoch 1091/10000\n","185/185 [==============================] - 22s 119ms/step - loss: 0.2922 - accuracy: 0.8963 - precision: 0.9152 - recall: 0.8822 - val_loss: 5.4737 - val_accuracy: 0.2862 - val_precision: 0.2954 - val_recall: 0.2685\n","Epoch 1092/10000\n","185/185 [==============================] - 20s 111ms/step - loss: 0.2925 - accuracy: 0.9015 - precision: 0.9167 - recall: 0.8873 - val_loss: 5.4343 - val_accuracy: 0.2918 - val_precision: 0.3078 - val_recall: 0.2786\n","Epoch 1093/10000\n","185/185 [==============================] - 20s 111ms/step - loss: 0.2976 - accuracy: 0.8983 - precision: 0.9167 - recall: 0.8812 - val_loss: 5.4226 - val_accuracy: 0.2781 - val_precision: 0.2909 - val_recall: 0.2619\n","Epoch 1094/10000\n","185/185 [==============================] - 21s 115ms/step - loss: 0.2891 - accuracy: 0.9059 - precision: 0.9211 - recall: 0.8855 - val_loss: 5.4541 - val_accuracy: 0.2953 - val_precision: 0.3104 - val_recall: 0.2806\n","Epoch 1095/10000\n","185/185 [==============================] - 21s 111ms/step - loss: 0.2885 - accuracy: 0.9030 - precision: 0.9198 - recall: 0.8878 - val_loss: 5.7175 - val_accuracy: 0.2877 - val_precision: 0.3010 - val_recall: 0.2771\n","Epoch 1096/10000\n","185/185 [==============================] - 20s 110ms/step - loss: 0.2947 - accuracy: 0.9023 - precision: 0.9188 - recall: 0.8851 - val_loss: 5.4015 - val_accuracy: 0.2943 - val_precision: 0.3090 - val_recall: 0.2812\n","Epoch 1097/10000\n","185/185 [==============================] - 21s 111ms/step - loss: 0.2682 - accuracy: 0.9081 - precision: 0.9240 - recall: 0.8920 - val_loss: 5.5005 - val_accuracy: 0.2877 - val_precision: 0.3019 - val_recall: 0.2776\n","Epoch 1098/10000\n","185/185 [==============================] - 22s 117ms/step - loss: 0.2972 - accuracy: 0.8963 - precision: 0.9151 - recall: 0.8811 - val_loss: 5.4725 - val_accuracy: 0.2943 - val_precision: 0.3079 - val_recall: 0.2801\n","Epoch 1099/10000\n","185/185 [==============================] - 22s 119ms/step - loss: 0.2811 - accuracy: 0.9030 - precision: 0.9195 - recall: 0.8880 - val_loss: 5.3311 - val_accuracy: 0.2857 - val_precision: 0.3010 - val_recall: 0.2751\n","Epoch 1100/10000\n","185/185 [==============================] - 20s 110ms/step - loss: 0.2708 - accuracy: 0.9071 - precision: 0.9243 - recall: 0.8914 - val_loss: 5.3969 - val_accuracy: 0.2908 - val_precision: 0.3065 - val_recall: 0.2776\n","Epoch 1101/10000\n","185/185 [==============================] - 20s 110ms/step - loss: 0.2662 - accuracy: 0.9074 - precision: 0.9236 - recall: 0.8927 - val_loss: 5.2953 - val_accuracy: 0.2852 - val_precision: 0.3002 - val_recall: 0.2695\n","Epoch 1102/10000\n","185/185 [==============================] - 22s 117ms/step - loss: 0.2870 - accuracy: 0.9051 - precision: 0.9186 - recall: 0.8866 - val_loss: 5.6672 - val_accuracy: 0.2852 - val_precision: 0.2950 - val_recall: 0.2705\n","Epoch 1103/10000\n","185/185 [==============================] - 20s 109ms/step - loss: 0.2766 - accuracy: 0.9027 - precision: 0.9211 - recall: 0.8876 - val_loss: 5.5917 - val_accuracy: 0.2888 - val_precision: 0.2977 - val_recall: 0.2710\n","Epoch 1104/10000\n","185/185 [==============================] - 20s 110ms/step - loss: 0.2789 - accuracy: 0.9042 - precision: 0.9199 - recall: 0.8892 - val_loss: 5.7056 - val_accuracy: 0.2852 - val_precision: 0.2908 - val_recall: 0.2680\n","Epoch 1105/10000\n","185/185 [==============================] - 20s 110ms/step - loss: 0.2793 - accuracy: 0.9002 - precision: 0.9175 - recall: 0.8853 - val_loss: 5.5233 - val_accuracy: 0.2989 - val_precision: 0.3058 - val_recall: 0.2817\n","Epoch 1106/10000\n","185/185 [==============================] - 22s 118ms/step - loss: 0.2780 - accuracy: 0.9051 - precision: 0.9218 - recall: 0.8863 - val_loss: 5.6660 - val_accuracy: 0.2908 - val_precision: 0.3000 - val_recall: 0.2766\n","Epoch 1107/10000\n","185/185 [==============================] - 20s 110ms/step - loss: 0.3238 - accuracy: 0.8956 - precision: 0.9104 - recall: 0.8785 - val_loss: 5.6162 - val_accuracy: 0.2948 - val_precision: 0.3065 - val_recall: 0.2801\n","Epoch 1108/10000\n","185/185 [==============================] - 20s 111ms/step - loss: 0.2778 - accuracy: 0.9029 - precision: 0.9225 - recall: 0.8892 - val_loss: 5.6328 - val_accuracy: 0.2857 - val_precision: 0.2949 - val_recall: 0.2736\n","Epoch 1109/10000\n","185/185 [==============================] - 21s 116ms/step - loss: 0.2655 - accuracy: 0.9062 - precision: 0.9244 - recall: 0.8904 - val_loss: 5.4097 - val_accuracy: 0.2994 - val_precision: 0.3092 - val_recall: 0.2817\n","Epoch 1110/10000\n","185/185 [==============================] - 22s 120ms/step - loss: 0.2655 - accuracy: 0.9066 - precision: 0.9223 - recall: 0.8920 - val_loss: 5.5592 - val_accuracy: 0.2852 - val_precision: 0.2960 - val_recall: 0.2715\n","Epoch 1111/10000\n","185/185 [==============================] - 20s 111ms/step - loss: 0.2878 - accuracy: 0.9040 - precision: 0.9199 - recall: 0.8909 - val_loss: 5.5131 - val_accuracy: 0.2923 - val_precision: 0.3021 - val_recall: 0.2741\n","Epoch 1112/10000\n","185/185 [==============================] - 20s 110ms/step - loss: 0.2877 - accuracy: 0.9027 - precision: 0.9211 - recall: 0.8875 - val_loss: 5.7260 - val_accuracy: 0.2989 - val_precision: 0.3098 - val_recall: 0.2842\n","Epoch 1113/10000\n","185/185 [==============================] - 20s 110ms/step - loss: 0.2625 - accuracy: 0.9110 - precision: 0.9267 - recall: 0.8966 - val_loss: 5.6744 - val_accuracy: 0.2776 - val_precision: 0.2907 - val_recall: 0.2639\n","Epoch 1114/10000\n","185/185 [==============================] - 22s 116ms/step - loss: 0.2517 - accuracy: 0.9113 - precision: 0.9278 - recall: 0.8966 - val_loss: 5.3207 - val_accuracy: 0.2984 - val_precision: 0.3132 - val_recall: 0.2832\n","Epoch 1115/10000\n","185/185 [==============================] - 20s 110ms/step - loss: 0.2794 - accuracy: 0.9086 - precision: 0.9244 - recall: 0.8924 - val_loss: 5.4285 - val_accuracy: 0.3034 - val_precision: 0.3171 - val_recall: 0.2903\n","Epoch 1116/10000\n","185/185 [==============================] - 20s 109ms/step - loss: 0.2713 - accuracy: 0.9018 - precision: 0.9206 - recall: 0.8860 - val_loss: 5.5634 - val_accuracy: 0.2938 - val_precision: 0.3088 - val_recall: 0.2842\n","Epoch 1117/10000\n","185/185 [==============================] - 20s 110ms/step - loss: 0.2728 - accuracy: 0.9039 - precision: 0.9212 - recall: 0.8902 - val_loss: 5.2480 - val_accuracy: 0.3014 - val_precision: 0.3224 - val_recall: 0.2928\n","Epoch 1118/10000\n","185/185 [==============================] - 22s 119ms/step - loss: 0.2751 - accuracy: 0.9067 - precision: 0.9230 - recall: 0.8915 - val_loss: 5.7271 - val_accuracy: 0.2974 - val_precision: 0.3085 - val_recall: 0.2827\n","Epoch 1119/10000\n","185/185 [==============================] - 21s 111ms/step - loss: 0.2834 - accuracy: 0.9030 - precision: 0.9177 - recall: 0.8875 - val_loss: 5.4119 - val_accuracy: 0.3024 - val_precision: 0.3104 - val_recall: 0.2852\n","Epoch 1120/10000\n","185/185 [==============================] - 21s 112ms/step - loss: 0.2717 - accuracy: 0.9069 - precision: 0.9226 - recall: 0.8907 - val_loss: 5.3010 - val_accuracy: 0.2913 - val_precision: 0.3080 - val_recall: 0.2766\n","Epoch 1121/10000\n","185/185 [==============================] - 22s 119ms/step - loss: 0.2677 - accuracy: 0.9083 - precision: 0.9233 - recall: 0.8947 - val_loss: 5.4350 - val_accuracy: 0.2933 - val_precision: 0.3069 - val_recall: 0.2761\n","Epoch 1122/10000\n","185/185 [==============================] - 23s 124ms/step - loss: 0.2890 - accuracy: 0.8973 - precision: 0.9141 - recall: 0.8824 - val_loss: 5.4865 - val_accuracy: 0.2908 - val_precision: 0.3056 - val_recall: 0.2786\n","Epoch 1123/10000\n","185/185 [==============================] - 21s 112ms/step - loss: 0.2730 - accuracy: 0.9017 - precision: 0.9194 - recall: 0.8883 - val_loss: 5.4867 - val_accuracy: 0.2943 - val_precision: 0.3114 - val_recall: 0.2827\n","Epoch 1124/10000\n","185/185 [==============================] - 21s 112ms/step - loss: 0.2731 - accuracy: 0.9083 - precision: 0.9227 - recall: 0.8956 - val_loss: 5.4573 - val_accuracy: 0.2872 - val_precision: 0.3029 - val_recall: 0.2776\n","Epoch 1125/10000\n","185/185 [==============================] - 22s 117ms/step - loss: 0.2845 - accuracy: 0.9005 - precision: 0.9185 - recall: 0.8836 - val_loss: 5.6348 - val_accuracy: 0.2923 - val_precision: 0.3032 - val_recall: 0.2791\n","Epoch 1126/10000\n","185/185 [==============================] - 20s 111ms/step - loss: 0.2740 - accuracy: 0.9072 - precision: 0.9211 - recall: 0.8897 - val_loss: 5.2567 - val_accuracy: 0.2928 - val_precision: 0.3065 - val_recall: 0.2791\n","Epoch 1127/10000\n","185/185 [==============================] - 20s 110ms/step - loss: 0.2768 - accuracy: 0.9029 - precision: 0.9169 - recall: 0.8868 - val_loss: 5.4286 - val_accuracy: 0.2989 - val_precision: 0.3147 - val_recall: 0.2882\n","Epoch 1128/10000\n","185/185 [==============================] - 21s 111ms/step - loss: 0.2664 - accuracy: 0.9091 - precision: 0.9239 - recall: 0.8978 - val_loss: 5.2441 - val_accuracy: 0.2908 - val_precision: 0.3071 - val_recall: 0.2771\n","Epoch 1129/10000\n","185/185 [==============================] - 22s 118ms/step - loss: 0.2797 - accuracy: 0.9007 - precision: 0.9176 - recall: 0.8875 - val_loss: 5.6013 - val_accuracy: 0.2969 - val_precision: 0.3107 - val_recall: 0.2852\n","Epoch 1130/10000\n","185/185 [==============================] - 20s 109ms/step - loss: 0.2617 - accuracy: 0.9137 - precision: 0.9311 - recall: 0.8993 - val_loss: 5.5971 - val_accuracy: 0.2928 - val_precision: 0.3031 - val_recall: 0.2796\n","Epoch 1131/10000\n","185/185 [==============================] - 20s 110ms/step - loss: 0.2610 - accuracy: 0.9108 - precision: 0.9227 - recall: 0.8951 - val_loss: 5.3309 - val_accuracy: 0.2943 - val_precision: 0.3029 - val_recall: 0.2786\n","Epoch 1132/10000\n","185/185 [==============================] - 21s 116ms/step - loss: 0.2466 - accuracy: 0.9165 - precision: 0.9308 - recall: 0.8996 - val_loss: 5.4666 - val_accuracy: 0.3009 - val_precision: 0.3140 - val_recall: 0.2882\n","Epoch 1133/10000\n","185/185 [==============================] - 22s 120ms/step - loss: 0.2712 - accuracy: 0.9030 - precision: 0.9200 - recall: 0.8873 - val_loss: 5.6228 - val_accuracy: 0.2943 - val_precision: 0.3001 - val_recall: 0.2771\n","Epoch 1134/10000\n","185/185 [==============================] - 20s 110ms/step - loss: 0.2610 - accuracy: 0.9162 - precision: 0.9294 - recall: 0.9008 - val_loss: 5.6158 - val_accuracy: 0.2736 - val_precision: 0.2867 - val_recall: 0.2609\n","Epoch 1135/10000\n","185/185 [==============================] - 20s 109ms/step - loss: 0.2784 - accuracy: 0.9066 - precision: 0.9202 - recall: 0.8905 - val_loss: 5.5789 - val_accuracy: 0.2933 - val_precision: 0.3052 - val_recall: 0.2786\n","Epoch 1136/10000\n","185/185 [==============================] - 21s 111ms/step - loss: 0.2742 - accuracy: 0.9056 - precision: 0.9201 - recall: 0.8915 - val_loss: 5.7456 - val_accuracy: 0.2913 - val_precision: 0.3065 - val_recall: 0.2812\n","Epoch 1137/10000\n","185/185 [==============================] - 22s 119ms/step - loss: 0.2512 - accuracy: 0.9132 - precision: 0.9309 - recall: 0.8971 - val_loss: 5.5472 - val_accuracy: 0.2786 - val_precision: 0.2871 - val_recall: 0.2639\n","Epoch 1138/10000\n","185/185 [==============================] - 20s 111ms/step - loss: 0.2702 - accuracy: 0.9081 - precision: 0.9226 - recall: 0.8946 - val_loss: 5.4986 - val_accuracy: 0.2938 - val_precision: 0.3009 - val_recall: 0.2771\n","Epoch 1139/10000\n","185/185 [==============================] - 20s 110ms/step - loss: 0.2624 - accuracy: 0.9105 - precision: 0.9256 - recall: 0.8947 - val_loss: 5.5279 - val_accuracy: 0.2903 - val_precision: 0.3044 - val_recall: 0.2791\n","Epoch 1140/10000\n","185/185 [==============================] - 21s 115ms/step - loss: 0.2660 - accuracy: 0.9084 - precision: 0.9248 - recall: 0.8936 - val_loss: 5.3966 - val_accuracy: 0.2943 - val_precision: 0.3073 - val_recall: 0.2832\n","Epoch 1141/10000\n","185/185 [==============================] - 21s 113ms/step - loss: 0.2641 - accuracy: 0.9076 - precision: 0.9236 - recall: 0.8966 - val_loss: 5.3851 - val_accuracy: 0.2898 - val_precision: 0.3067 - val_recall: 0.2781\n","Epoch 1142/10000\n","185/185 [==============================] - 20s 111ms/step - loss: 0.2701 - accuracy: 0.9083 - precision: 0.9225 - recall: 0.8966 - val_loss: 5.5823 - val_accuracy: 0.3029 - val_precision: 0.3148 - val_recall: 0.2918\n","Epoch 1143/10000\n","185/185 [==============================] - 20s 110ms/step - loss: 0.2533 - accuracy: 0.9152 - precision: 0.9284 - recall: 0.9005 - val_loss: 5.4837 - val_accuracy: 0.3050 - val_precision: 0.3192 - val_recall: 0.2938\n","Epoch 1144/10000\n","185/185 [==============================] - 22s 118ms/step - loss: 0.2482 - accuracy: 0.9127 - precision: 0.9292 - recall: 0.8983 - val_loss: 5.6271 - val_accuracy: 0.3004 - val_precision: 0.3093 - val_recall: 0.2847\n","Epoch 1145/10000\n","185/185 [==============================] - 22s 118ms/step - loss: 0.2724 - accuracy: 0.9030 - precision: 0.9200 - recall: 0.8876 - val_loss: 5.5193 - val_accuracy: 0.2918 - val_precision: 0.3036 - val_recall: 0.2776\n","Epoch 1146/10000\n","185/185 [==============================] - 20s 109ms/step - loss: 0.2581 - accuracy: 0.9094 - precision: 0.9267 - recall: 0.8934 - val_loss: 5.5531 - val_accuracy: 0.2918 - val_precision: 0.3063 - val_recall: 0.2812\n","Epoch 1147/10000\n","185/185 [==============================] - 20s 109ms/step - loss: 0.2443 - accuracy: 0.9135 - precision: 0.9290 - recall: 0.9002 - val_loss: 5.5016 - val_accuracy: 0.2984 - val_precision: 0.3070 - val_recall: 0.2837\n","Epoch 1148/10000\n","185/185 [==============================] - 20s 110ms/step - loss: 0.2599 - accuracy: 0.9132 - precision: 0.9304 - recall: 0.9005 - val_loss: 5.4949 - val_accuracy: 0.2888 - val_precision: 0.2998 - val_recall: 0.2736\n","Epoch 1149/10000\n","185/185 [==============================] - 22s 117ms/step - loss: 0.2593 - accuracy: 0.9105 - precision: 0.9264 - recall: 0.8976 - val_loss: 5.3331 - val_accuracy: 0.2948 - val_precision: 0.3026 - val_recall: 0.2776\n","Epoch 1150/10000\n","185/185 [==============================] - 20s 110ms/step - loss: 0.2677 - accuracy: 0.9081 - precision: 0.9232 - recall: 0.8939 - val_loss: 5.6215 - val_accuracy: 0.2877 - val_precision: 0.2962 - val_recall: 0.2736\n","Epoch 1151/10000\n","185/185 [==============================] - 20s 110ms/step - loss: 0.2524 - accuracy: 0.9121 - precision: 0.9277 - recall: 0.8995 - val_loss: 5.5003 - val_accuracy: 0.3004 - val_precision: 0.3137 - val_recall: 0.2837\n","Epoch 1152/10000\n","185/185 [==============================] - 20s 110ms/step - loss: 0.2723 - accuracy: 0.9047 - precision: 0.9215 - recall: 0.8910 - val_loss: 5.5798 - val_accuracy: 0.2984 - val_precision: 0.3047 - val_recall: 0.2786\n","Epoch 1153/10000\n","185/185 [==============================] - 22s 118ms/step - loss: 0.2657 - accuracy: 0.9113 - precision: 0.9239 - recall: 0.8959 - val_loss: 5.5318 - val_accuracy: 0.2877 - val_precision: 0.2959 - val_recall: 0.2736\n","Epoch 1154/10000\n","185/185 [==============================] - 20s 110ms/step - loss: 0.2629 - accuracy: 0.9088 - precision: 0.9225 - recall: 0.8931 - val_loss: 5.5100 - val_accuracy: 0.3040 - val_precision: 0.3114 - val_recall: 0.2877\n","Epoch 1155/10000\n","185/185 [==============================] - 22s 119ms/step - loss: 0.2715 - accuracy: 0.9084 - precision: 0.9229 - recall: 0.8936 - val_loss: 5.5845 - val_accuracy: 0.2913 - val_precision: 0.2954 - val_recall: 0.2720\n","Epoch 1156/10000\n","185/185 [==============================] - 20s 110ms/step - loss: 0.2771 - accuracy: 0.9071 - precision: 0.9219 - recall: 0.8936 - val_loss: 5.3591 - val_accuracy: 0.2938 - val_precision: 0.3028 - val_recall: 0.2776\n","Epoch 1157/10000\n","185/185 [==============================] - 22s 118ms/step - loss: 0.2495 - accuracy: 0.9164 - precision: 0.9298 - recall: 0.9022 - val_loss: 5.5214 - val_accuracy: 0.2842 - val_precision: 0.2991 - val_recall: 0.2756\n","Epoch 1158/10000\n","185/185 [==============================] - 20s 109ms/step - loss: 0.2710 - accuracy: 0.9040 - precision: 0.9213 - recall: 0.8937 - val_loss: 5.4781 - val_accuracy: 0.2974 - val_precision: 0.3114 - val_recall: 0.2847\n","Epoch 1159/10000\n","185/185 [==============================] - 20s 110ms/step - loss: 0.2549 - accuracy: 0.9115 - precision: 0.9260 - recall: 0.8980 - val_loss: 5.4781 - val_accuracy: 0.3014 - val_precision: 0.3121 - val_recall: 0.2857\n","Epoch 1160/10000\n","185/185 [==============================] - 20s 110ms/step - loss: 0.2767 - accuracy: 0.9049 - precision: 0.9205 - recall: 0.8887 - val_loss: 5.3619 - val_accuracy: 0.2837 - val_precision: 0.2968 - val_recall: 0.2690\n","Epoch 1161/10000\n","185/185 [==============================] - 22s 119ms/step - loss: 0.2595 - accuracy: 0.9135 - precision: 0.9282 - recall: 0.8996 - val_loss: 5.7161 - val_accuracy: 0.2842 - val_precision: 0.2970 - val_recall: 0.2730\n","Epoch 1162/10000\n","185/185 [==============================] - 21s 114ms/step - loss: 0.2441 - accuracy: 0.9167 - precision: 0.9322 - recall: 0.9040 - val_loss: 5.7603 - val_accuracy: 0.2857 - val_precision: 0.2969 - val_recall: 0.2725\n","Epoch 1163/10000\n","185/185 [==============================] - 20s 110ms/step - loss: 0.2503 - accuracy: 0.9133 - precision: 0.9307 - recall: 0.8990 - val_loss: 5.7342 - val_accuracy: 0.2862 - val_precision: 0.2986 - val_recall: 0.2756\n","Epoch 1164/10000\n","185/185 [==============================] - 21s 114ms/step - loss: 0.2442 - accuracy: 0.9184 - precision: 0.9330 - recall: 0.9054 - val_loss: 5.4547 - val_accuracy: 0.2852 - val_precision: 0.2983 - val_recall: 0.2720\n","Epoch 1165/10000\n","185/185 [==============================] - 21s 115ms/step - loss: 0.2474 - accuracy: 0.9111 - precision: 0.9264 - recall: 0.9000 - val_loss: 5.5447 - val_accuracy: 0.2903 - val_precision: 0.2999 - val_recall: 0.2746\n","Epoch 1166/10000\n","185/185 [==============================] - 22s 118ms/step - loss: 0.2523 - accuracy: 0.9154 - precision: 0.9300 - recall: 0.9017 - val_loss: 5.6572 - val_accuracy: 0.2903 - val_precision: 0.2996 - val_recall: 0.2771\n","Epoch 1167/10000\n","185/185 [==============================] - 20s 111ms/step - loss: 0.2346 - accuracy: 0.9199 - precision: 0.9314 - recall: 0.9086 - val_loss: 5.6190 - val_accuracy: 0.2791 - val_precision: 0.2902 - val_recall: 0.2624\n","Epoch 1168/10000\n","185/185 [==============================] - 22s 116ms/step - loss: 0.2352 - accuracy: 0.9192 - precision: 0.9338 - recall: 0.9061 - val_loss: 5.5418 - val_accuracy: 0.2872 - val_precision: 0.2994 - val_recall: 0.2715\n","Epoch 1169/10000\n","185/185 [==============================] - 21s 112ms/step - loss: 0.2578 - accuracy: 0.9113 - precision: 0.9273 - recall: 0.9002 - val_loss: 5.6422 - val_accuracy: 0.2933 - val_precision: 0.3010 - val_recall: 0.2771\n","Epoch 1170/10000\n","185/185 [==============================] - 20s 110ms/step - loss: 0.2502 - accuracy: 0.9164 - precision: 0.9293 - recall: 0.9044 - val_loss: 5.6399 - val_accuracy: 0.2806 - val_precision: 0.2911 - val_recall: 0.2665\n","Epoch 1171/10000\n","185/185 [==============================] - 22s 119ms/step - loss: 0.2720 - accuracy: 0.9086 - precision: 0.9220 - recall: 0.8942 - val_loss: 5.4771 - val_accuracy: 0.2877 - val_precision: 0.3006 - val_recall: 0.2725\n","Epoch 1172/10000\n","185/185 [==============================] - 21s 116ms/step - loss: 0.2599 - accuracy: 0.9118 - precision: 0.9283 - recall: 0.8985 - val_loss: 5.6158 - val_accuracy: 0.2888 - val_precision: 0.3001 - val_recall: 0.2730\n","Epoch 1173/10000\n","185/185 [==============================] - 20s 109ms/step - loss: 0.2736 - accuracy: 0.9049 - precision: 0.9236 - recall: 0.8900 - val_loss: 5.6547 - val_accuracy: 0.2903 - val_precision: 0.3036 - val_recall: 0.2761\n","Epoch 1174/10000\n","185/185 [==============================] - 20s 110ms/step - loss: 0.2563 - accuracy: 0.9147 - precision: 0.9292 - recall: 0.9030 - val_loss: 5.8238 - val_accuracy: 0.2989 - val_precision: 0.3048 - val_recall: 0.2832\n","Epoch 1175/10000\n","185/185 [==============================] - 20s 110ms/step - loss: 0.2631 - accuracy: 0.9083 - precision: 0.9213 - recall: 0.8925 - val_loss: 5.8245 - val_accuracy: 0.2964 - val_precision: 0.3080 - val_recall: 0.2817\n","Epoch 1176/10000\n","185/185 [==============================] - 22s 119ms/step - loss: 0.2877 - accuracy: 0.9057 - precision: 0.9195 - recall: 0.8932 - val_loss: 5.7360 - val_accuracy: 0.2837 - val_precision: 0.2936 - val_recall: 0.2705\n","Epoch 1177/10000\n","185/185 [==============================] - 21s 113ms/step - loss: 0.2456 - accuracy: 0.9150 - precision: 0.9298 - recall: 0.9020 - val_loss: 5.5419 - val_accuracy: 0.2903 - val_precision: 0.3013 - val_recall: 0.2781\n","Epoch 1178/10000\n","185/185 [==============================] - 22s 119ms/step - loss: 0.2212 - accuracy: 0.9226 - precision: 0.9360 - recall: 0.9094 - val_loss: 5.4436 - val_accuracy: 0.3045 - val_precision: 0.3217 - val_recall: 0.2938\n","Epoch 1179/10000\n","185/185 [==============================] - 22s 119ms/step - loss: 0.2375 - accuracy: 0.9179 - precision: 0.9319 - recall: 0.9061 - val_loss: 5.4504 - val_accuracy: 0.2913 - val_precision: 0.3016 - val_recall: 0.2761\n","Epoch 1180/10000\n","185/185 [==============================] - 20s 110ms/step - loss: 0.2576 - accuracy: 0.9145 - precision: 0.9290 - recall: 0.9017 - val_loss: 5.5273 - val_accuracy: 0.2943 - val_precision: 0.3071 - val_recall: 0.2791\n","Epoch 1181/10000\n","185/185 [==============================] - 20s 110ms/step - loss: 0.2416 - accuracy: 0.9157 - precision: 0.9294 - recall: 0.9051 - val_loss: 5.5319 - val_accuracy: 0.2979 - val_precision: 0.3085 - val_recall: 0.2852\n","Epoch 1182/10000\n","185/185 [==============================] - 20s 110ms/step - loss: 0.2583 - accuracy: 0.9142 - precision: 0.9266 - recall: 0.9005 - val_loss: 5.7475 - val_accuracy: 0.3009 - val_precision: 0.3101 - val_recall: 0.2842\n","Epoch 1183/10000\n","185/185 [==============================] - 22s 120ms/step - loss: 0.2533 - accuracy: 0.9093 - precision: 0.9241 - recall: 0.8953 - val_loss: 5.5824 - val_accuracy: 0.2867 - val_precision: 0.3006 - val_recall: 0.2730\n","Epoch 1184/10000\n","185/185 [==============================] - 20s 110ms/step - loss: 0.2515 - accuracy: 0.9176 - precision: 0.9309 - recall: 0.9035 - val_loss: 5.7274 - val_accuracy: 0.2801 - val_precision: 0.2893 - val_recall: 0.2649\n","Epoch 1185/10000\n","185/185 [==============================] - 20s 111ms/step - loss: 0.2462 - accuracy: 0.9181 - precision: 0.9314 - recall: 0.9035 - val_loss: 5.5756 - val_accuracy: 0.2979 - val_precision: 0.3089 - val_recall: 0.2842\n","Epoch 1186/10000\n","185/185 [==============================] - 21s 112ms/step - loss: 0.2312 - accuracy: 0.9206 - precision: 0.9330 - recall: 0.9084 - val_loss: 5.8845 - val_accuracy: 0.2786 - val_precision: 0.2888 - val_recall: 0.2649\n","Epoch 1187/10000\n","185/185 [==============================] - 21s 114ms/step - loss: 0.2585 - accuracy: 0.9160 - precision: 0.9295 - recall: 0.9000 - val_loss: 5.5998 - val_accuracy: 0.2893 - val_precision: 0.2973 - val_recall: 0.2715\n","Epoch 1188/10000\n","185/185 [==============================] - 20s 110ms/step - loss: 0.2532 - accuracy: 0.9152 - precision: 0.9295 - recall: 0.9022 - val_loss: 5.5833 - val_accuracy: 0.2928 - val_precision: 0.3013 - val_recall: 0.2766\n","Epoch 1189/10000\n","185/185 [==============================] - 22s 118ms/step - loss: 0.2543 - accuracy: 0.9128 - precision: 0.9247 - recall: 0.8981 - val_loss: 5.6985 - val_accuracy: 0.2908 - val_precision: 0.3011 - val_recall: 0.2741\n","Epoch 1190/10000\n","185/185 [==============================] - 21s 116ms/step - loss: 0.2426 - accuracy: 0.9192 - precision: 0.9316 - recall: 0.9062 - val_loss: 5.7300 - val_accuracy: 0.2801 - val_precision: 0.2875 - val_recall: 0.2639\n","Epoch 1191/10000\n","185/185 [==============================] - 21s 113ms/step - loss: 0.2425 - accuracy: 0.9172 - precision: 0.9309 - recall: 0.9061 - val_loss: 5.6555 - val_accuracy: 0.2888 - val_precision: 0.2987 - val_recall: 0.2771\n","Epoch 1192/10000\n","185/185 [==============================] - 21s 111ms/step - loss: 0.2510 - accuracy: 0.9116 - precision: 0.9254 - recall: 0.8971 - val_loss: 5.8024 - val_accuracy: 0.2877 - val_precision: 0.2970 - val_recall: 0.2720\n","Epoch 1193/10000\n","185/185 [==============================] - 20s 111ms/step - loss: 0.2464 - accuracy: 0.9127 - precision: 0.9284 - recall: 0.9022 - val_loss: 5.5025 - val_accuracy: 0.2862 - val_precision: 0.2966 - val_recall: 0.2725\n","Epoch 1194/10000\n","185/185 [==============================] - 22s 117ms/step - loss: 0.2564 - accuracy: 0.9116 - precision: 0.9269 - recall: 0.9000 - val_loss: 5.6405 - val_accuracy: 0.2964 - val_precision: 0.3031 - val_recall: 0.2796\n","Epoch 1195/10000\n","185/185 [==============================] - 20s 110ms/step - loss: 0.2496 - accuracy: 0.9179 - precision: 0.9317 - recall: 0.9051 - val_loss: 5.6266 - val_accuracy: 0.2736 - val_precision: 0.2903 - val_recall: 0.2619\n","Epoch 1196/10000\n","185/185 [==============================] - 20s 110ms/step - loss: 0.2724 - accuracy: 0.9052 - precision: 0.9233 - recall: 0.8929 - val_loss: 5.6849 - val_accuracy: 0.2948 - val_precision: 0.3048 - val_recall: 0.2812\n","Epoch 1197/10000\n","185/185 [==============================] - 20s 110ms/step - loss: 0.2447 - accuracy: 0.9149 - precision: 0.9295 - recall: 0.8993 - val_loss: 5.8766 - val_accuracy: 0.2822 - val_precision: 0.2921 - val_recall: 0.2700\n","Epoch 1198/10000\n","185/185 [==============================] - 22s 119ms/step - loss: 0.2403 - accuracy: 0.9179 - precision: 0.9316 - recall: 0.9015 - val_loss: 5.8702 - val_accuracy: 0.2857 - val_precision: 0.3006 - val_recall: 0.2756\n","Epoch 1199/10000\n","185/185 [==============================] - 21s 114ms/step - loss: 0.2647 - accuracy: 0.9027 - precision: 0.9183 - recall: 0.8904 - val_loss: 5.6385 - val_accuracy: 0.3014 - val_precision: 0.3138 - val_recall: 0.2903\n","Epoch 1200/10000\n","185/185 [==============================] - 21s 112ms/step - loss: 0.2411 - accuracy: 0.9211 - precision: 0.9350 - recall: 0.9067 - val_loss: 5.7326 - val_accuracy: 0.2928 - val_precision: 0.3038 - val_recall: 0.2817\n","Epoch 1201/10000\n","185/185 [==============================] - 22s 120ms/step - loss: 0.2466 - accuracy: 0.9184 - precision: 0.9307 - recall: 0.9049 - val_loss: 5.6125 - val_accuracy: 0.2822 - val_precision: 0.2920 - val_recall: 0.2685\n","Epoch 1202/10000\n","185/185 [==============================] - 22s 118ms/step - loss: 0.2293 - accuracy: 0.9238 - precision: 0.9380 - recall: 0.9130 - val_loss: 5.6060 - val_accuracy: 0.2948 - val_precision: 0.3032 - val_recall: 0.2806\n","Epoch 1203/10000\n","185/185 [==============================] - 20s 110ms/step - loss: 0.2391 - accuracy: 0.9203 - precision: 0.9344 - recall: 0.9103 - val_loss: 5.6387 - val_accuracy: 0.2913 - val_precision: 0.2973 - val_recall: 0.2730\n","Epoch 1204/10000\n","185/185 [==============================] - 21s 111ms/step - loss: 0.2381 - accuracy: 0.9203 - precision: 0.9350 - recall: 0.9086 - val_loss: 5.5489 - val_accuracy: 0.2862 - val_precision: 0.2941 - val_recall: 0.2725\n","Epoch 1205/10000\n","185/185 [==============================] - 21s 116ms/step - loss: 0.2497 - accuracy: 0.9142 - precision: 0.9288 - recall: 0.9017 - val_loss: 5.5770 - val_accuracy: 0.2852 - val_precision: 0.3010 - val_recall: 0.2736\n","Epoch 1206/10000\n","185/185 [==============================] - 22s 116ms/step - loss: 0.2403 - accuracy: 0.9169 - precision: 0.9305 - recall: 0.9064 - val_loss: 5.5843 - val_accuracy: 0.2872 - val_precision: 0.2973 - val_recall: 0.2730\n","Epoch 1207/10000\n","185/185 [==============================] - 21s 111ms/step - loss: 0.2443 - accuracy: 0.9184 - precision: 0.9319 - recall: 0.9059 - val_loss: 5.7929 - val_accuracy: 0.3050 - val_precision: 0.3159 - val_recall: 0.2943\n","Epoch 1208/10000\n","185/185 [==============================] - 21s 112ms/step - loss: 0.2488 - accuracy: 0.9157 - precision: 0.9305 - recall: 0.9018 - val_loss: 5.7522 - val_accuracy: 0.2796 - val_precision: 0.2878 - val_recall: 0.2670\n","Epoch 1209/10000\n","185/185 [==============================] - 22s 117ms/step - loss: 0.2359 - accuracy: 0.9177 - precision: 0.9319 - recall: 0.9042 - val_loss: 5.8073 - val_accuracy: 0.2923 - val_precision: 0.3066 - val_recall: 0.2852\n","Epoch 1210/10000\n","185/185 [==============================] - 21s 114ms/step - loss: 0.2345 - accuracy: 0.9214 - precision: 0.9336 - recall: 0.9091 - val_loss: 5.7354 - val_accuracy: 0.2822 - val_precision: 0.2904 - val_recall: 0.2639\n","Epoch 1211/10000\n","185/185 [==============================] - 21s 111ms/step - loss: 0.2410 - accuracy: 0.9165 - precision: 0.9309 - recall: 0.9035 - val_loss: 5.6082 - val_accuracy: 0.2857 - val_precision: 0.2962 - val_recall: 0.2746\n","Epoch 1212/10000\n","185/185 [==============================] - 21s 111ms/step - loss: 0.2324 - accuracy: 0.9197 - precision: 0.9328 - recall: 0.9098 - val_loss: 5.8508 - val_accuracy: 0.2877 - val_precision: 0.2994 - val_recall: 0.2746\n","Epoch 1213/10000\n","185/185 [==============================] - 23s 124ms/step - loss: 0.2329 - accuracy: 0.9197 - precision: 0.9360 - recall: 0.9072 - val_loss: 5.7976 - val_accuracy: 0.2918 - val_precision: 0.3011 - val_recall: 0.2761\n","Epoch 1214/10000\n","185/185 [==============================] - 22s 118ms/step - loss: 0.2418 - accuracy: 0.9169 - precision: 0.9290 - recall: 0.9064 - val_loss: 5.8362 - val_accuracy: 0.2979 - val_precision: 0.3082 - val_recall: 0.2842\n","Epoch 1215/10000\n","185/185 [==============================] - 20s 111ms/step - loss: 0.2441 - accuracy: 0.9100 - precision: 0.9253 - recall: 0.8978 - val_loss: 5.5574 - val_accuracy: 0.2994 - val_precision: 0.3058 - val_recall: 0.2796\n","Epoch 1216/10000\n","185/185 [==============================] - 21s 111ms/step - loss: 0.2321 - accuracy: 0.9206 - precision: 0.9350 - recall: 0.9106 - val_loss: 5.5608 - val_accuracy: 0.2928 - val_precision: 0.3041 - val_recall: 0.2776\n","Epoch 1217/10000\n","185/185 [==============================] - 22s 118ms/step - loss: 0.2452 - accuracy: 0.9155 - precision: 0.9269 - recall: 0.9037 - val_loss: 5.7885 - val_accuracy: 0.3009 - val_precision: 0.3138 - val_recall: 0.2872\n","Epoch 1218/10000\n","185/185 [==============================] - 21s 113ms/step - loss: 0.2308 - accuracy: 0.9268 - precision: 0.9382 - recall: 0.9164 - val_loss: 5.6590 - val_accuracy: 0.2847 - val_precision: 0.2951 - val_recall: 0.2736\n","Epoch 1219/10000\n","185/185 [==============================] - 21s 112ms/step - loss: 0.2340 - accuracy: 0.9199 - precision: 0.9333 - recall: 0.9059 - val_loss: 5.7216 - val_accuracy: 0.2953 - val_precision: 0.3086 - val_recall: 0.2806\n","Epoch 1220/10000\n","185/185 [==============================] - 21s 112ms/step - loss: 0.2391 - accuracy: 0.9150 - precision: 0.9296 - recall: 0.9039 - val_loss: 5.5528 - val_accuracy: 0.3014 - val_precision: 0.3109 - val_recall: 0.2857\n","Epoch 1221/10000\n","185/185 [==============================] - 22s 120ms/step - loss: 0.2436 - accuracy: 0.9157 - precision: 0.9294 - recall: 0.9030 - val_loss: 5.6946 - val_accuracy: 0.2948 - val_precision: 0.3069 - val_recall: 0.2781\n","Epoch 1222/10000\n","185/185 [==============================] - 21s 112ms/step - loss: 0.2419 - accuracy: 0.9213 - precision: 0.9343 - recall: 0.9088 - val_loss: 5.6678 - val_accuracy: 0.2888 - val_precision: 0.2991 - val_recall: 0.2756\n","Epoch 1223/10000\n","185/185 [==============================] - 21s 112ms/step - loss: 0.2425 - accuracy: 0.9197 - precision: 0.9331 - recall: 0.9079 - val_loss: 5.6680 - val_accuracy: 0.2918 - val_precision: 0.3060 - val_recall: 0.2812\n","Epoch 1224/10000\n","185/185 [==============================] - 21s 114ms/step - loss: 0.2423 - accuracy: 0.9172 - precision: 0.9297 - recall: 0.9042 - val_loss: 5.5657 - val_accuracy: 0.2913 - val_precision: 0.3037 - val_recall: 0.2806\n","Epoch 1225/10000\n","185/185 [==============================] - 22s 117ms/step - loss: 0.2351 - accuracy: 0.9226 - precision: 0.9382 - recall: 0.9108 - val_loss: 5.7133 - val_accuracy: 0.2984 - val_precision: 0.3068 - val_recall: 0.2817\n","Epoch 1226/10000\n","185/185 [==============================] - 22s 117ms/step - loss: 0.2270 - accuracy: 0.9199 - precision: 0.9339 - recall: 0.9101 - val_loss: 5.8846 - val_accuracy: 0.2923 - val_precision: 0.3036 - val_recall: 0.2806\n","Epoch 1227/10000\n","185/185 [==============================] - 21s 113ms/step - loss: 0.2540 - accuracy: 0.9143 - precision: 0.9274 - recall: 0.9000 - val_loss: 5.7519 - val_accuracy: 0.2918 - val_precision: 0.3034 - val_recall: 0.2771\n","Epoch 1228/10000\n","185/185 [==============================] - 22s 119ms/step - loss: 0.2447 - accuracy: 0.9179 - precision: 0.9282 - recall: 0.9081 - val_loss: 5.5945 - val_accuracy: 0.2903 - val_precision: 0.3024 - val_recall: 0.2761\n","Epoch 1229/10000\n","185/185 [==============================] - 21s 113ms/step - loss: 0.2582 - accuracy: 0.9132 - precision: 0.9266 - recall: 0.9017 - val_loss: 5.5593 - val_accuracy: 0.2867 - val_precision: 0.3011 - val_recall: 0.2746\n","Epoch 1230/10000\n","185/185 [==============================] - 21s 112ms/step - loss: 0.2491 - accuracy: 0.9169 - precision: 0.9273 - recall: 0.9057 - val_loss: 5.7251 - val_accuracy: 0.2867 - val_precision: 0.2948 - val_recall: 0.2710\n","Epoch 1231/10000\n","185/185 [==============================] - 21s 113ms/step - loss: 0.2439 - accuracy: 0.9194 - precision: 0.9317 - recall: 0.9078 - val_loss: 5.7262 - val_accuracy: 0.2943 - val_precision: 0.3055 - val_recall: 0.2817\n","Epoch 1232/10000\n","185/185 [==============================] - 22s 118ms/step - loss: 0.2375 - accuracy: 0.9186 - precision: 0.9325 - recall: 0.9034 - val_loss: 5.6521 - val_accuracy: 0.2928 - val_precision: 0.3056 - val_recall: 0.2796\n","Epoch 1233/10000\n","185/185 [==============================] - 21s 113ms/step - loss: 0.2500 - accuracy: 0.9149 - precision: 0.9291 - recall: 0.9010 - val_loss: 5.8616 - val_accuracy: 0.2933 - val_precision: 0.3032 - val_recall: 0.2786\n","Epoch 1234/10000\n","185/185 [==============================] - 21s 114ms/step - loss: 0.2189 - accuracy: 0.9252 - precision: 0.9355 - recall: 0.9133 - val_loss: 5.5717 - val_accuracy: 0.2933 - val_precision: 0.3039 - val_recall: 0.2776\n","Epoch 1235/10000\n","185/185 [==============================] - 22s 119ms/step - loss: 0.2366 - accuracy: 0.9206 - precision: 0.9320 - recall: 0.9100 - val_loss: 5.7245 - val_accuracy: 0.2938 - val_precision: 0.3053 - val_recall: 0.2791\n","Epoch 1236/10000\n","185/185 [==============================] - 21s 115ms/step - loss: 0.2245 - accuracy: 0.9225 - precision: 0.9326 - recall: 0.9121 - val_loss: 5.7101 - val_accuracy: 0.3009 - val_precision: 0.3112 - val_recall: 0.2867\n","Epoch 1237/10000\n","185/185 [==============================] - 21s 111ms/step - loss: 0.2252 - accuracy: 0.9250 - precision: 0.9361 - recall: 0.9140 - val_loss: 5.4493 - val_accuracy: 0.3029 - val_precision: 0.3142 - val_recall: 0.2862\n","Epoch 1238/10000\n","185/185 [==============================] - 22s 119ms/step - loss: 0.2386 - accuracy: 0.9211 - precision: 0.9304 - recall: 0.9086 - val_loss: 5.7273 - val_accuracy: 0.2867 - val_precision: 0.2955 - val_recall: 0.2705\n","Epoch 1239/10000\n","185/185 [==============================] - 22s 119ms/step - loss: 0.2610 - accuracy: 0.9121 - precision: 0.9260 - recall: 0.8986 - val_loss: 5.6109 - val_accuracy: 0.2958 - val_precision: 0.3069 - val_recall: 0.2822\n","Epoch 1240/10000\n","185/185 [==============================] - 21s 113ms/step - loss: 0.2410 - accuracy: 0.9149 - precision: 0.9259 - recall: 0.9072 - val_loss: 5.5762 - val_accuracy: 0.2984 - val_precision: 0.3115 - val_recall: 0.2872\n","Epoch 1241/10000\n","185/185 [==============================] - 21s 112ms/step - loss: 0.2388 - accuracy: 0.9170 - precision: 0.9302 - recall: 0.9032 - val_loss: 5.8035 - val_accuracy: 0.2761 - val_precision: 0.2903 - val_recall: 0.2639\n","Epoch 1242/10000\n","185/185 [==============================] - 21s 112ms/step - loss: 0.2262 - accuracy: 0.9233 - precision: 0.9355 - recall: 0.9113 - val_loss: 5.5614 - val_accuracy: 0.3009 - val_precision: 0.3127 - val_recall: 0.2888\n","Epoch 1243/10000\n","185/185 [==============================] - 22s 118ms/step - loss: 0.2301 - accuracy: 0.9214 - precision: 0.9351 - recall: 0.9111 - val_loss: 5.6484 - val_accuracy: 0.2918 - val_precision: 0.3045 - val_recall: 0.2796\n","Epoch 1244/10000\n","185/185 [==============================] - 21s 111ms/step - loss: 0.2223 - accuracy: 0.9226 - precision: 0.9361 - recall: 0.9140 - val_loss: 5.7920 - val_accuracy: 0.3009 - val_precision: 0.3103 - val_recall: 0.2893\n","Epoch 1245/10000\n","185/185 [==============================] - 21s 111ms/step - loss: 0.2469 - accuracy: 0.9135 - precision: 0.9311 - recall: 0.9018 - val_loss: 5.5768 - val_accuracy: 0.2908 - val_precision: 0.3048 - val_recall: 0.2781\n","Epoch 1246/10000\n","185/185 [==============================] - 21s 115ms/step - loss: 0.2505 - accuracy: 0.9138 - precision: 0.9258 - recall: 0.9045 - val_loss: 5.6984 - val_accuracy: 0.2938 - val_precision: 0.3052 - val_recall: 0.2786\n","Epoch 1247/10000\n","185/185 [==============================] - 21s 116ms/step - loss: 0.2418 - accuracy: 0.9152 - precision: 0.9274 - recall: 0.9044 - val_loss: 5.5263 - val_accuracy: 0.3009 - val_precision: 0.3177 - val_recall: 0.2908\n","Epoch 1248/10000\n","185/185 [==============================] - 21s 112ms/step - loss: 0.2394 - accuracy: 0.9150 - precision: 0.9286 - recall: 0.9037 - val_loss: 5.6441 - val_accuracy: 0.2867 - val_precision: 0.2997 - val_recall: 0.2741\n","Epoch 1249/10000\n","185/185 [==============================] - 21s 112ms/step - loss: 0.2259 - accuracy: 0.9196 - precision: 0.9342 - recall: 0.9094 - val_loss: 5.7616 - val_accuracy: 0.3090 - val_precision: 0.3177 - val_recall: 0.2958\n","Epoch 1250/10000\n","185/185 [==============================] - 23s 126ms/step - loss: 0.2084 - accuracy: 0.9282 - precision: 0.9381 - recall: 0.9159 - val_loss: 5.7628 - val_accuracy: 0.2877 - val_precision: 0.2995 - val_recall: 0.2766\n","Epoch 1251/10000\n","185/185 [==============================] - 21s 112ms/step - loss: 0.2483 - accuracy: 0.9149 - precision: 0.9265 - recall: 0.9030 - val_loss: 5.8088 - val_accuracy: 0.2872 - val_precision: 0.2959 - val_recall: 0.2736\n","Epoch 1252/10000\n","185/185 [==============================] - 21s 112ms/step - loss: 0.2118 - accuracy: 0.9274 - precision: 0.9392 - recall: 0.9133 - val_loss: 5.5678 - val_accuracy: 0.3045 - val_precision: 0.3134 - val_recall: 0.2893\n","Epoch 1253/10000\n","185/185 [==============================] - 21s 114ms/step - loss: 0.2445 - accuracy: 0.9164 - precision: 0.9285 - recall: 0.9064 - val_loss: 5.7827 - val_accuracy: 0.2928 - val_precision: 0.3036 - val_recall: 0.2827\n","Epoch 1254/10000\n","185/185 [==============================] - 22s 120ms/step - loss: 0.2164 - accuracy: 0.9285 - precision: 0.9386 - recall: 0.9174 - val_loss: 5.5539 - val_accuracy: 0.3029 - val_precision: 0.3098 - val_recall: 0.2822\n","Epoch 1255/10000\n","185/185 [==============================] - 21s 112ms/step - loss: 0.2431 - accuracy: 0.9147 - precision: 0.9273 - recall: 0.9056 - val_loss: 5.7021 - val_accuracy: 0.2898 - val_precision: 0.2999 - val_recall: 0.2761\n","Epoch 1256/10000\n","185/185 [==============================] - 21s 113ms/step - loss: 0.2275 - accuracy: 0.9172 - precision: 0.9289 - recall: 0.9076 - val_loss: 5.5798 - val_accuracy: 0.2918 - val_precision: 0.3032 - val_recall: 0.2756\n","Epoch 1257/10000\n","185/185 [==============================] - 22s 119ms/step - loss: 0.2418 - accuracy: 0.9201 - precision: 0.9318 - recall: 0.9094 - val_loss: 5.6207 - val_accuracy: 0.2948 - val_precision: 0.3026 - val_recall: 0.2791\n","Epoch 1258/10000\n","185/185 [==============================] - 21s 114ms/step - loss: 0.2290 - accuracy: 0.9211 - precision: 0.9340 - recall: 0.9064 - val_loss: 5.7454 - val_accuracy: 0.2852 - val_precision: 0.2946 - val_recall: 0.2710\n","Epoch 1259/10000\n","185/185 [==============================] - 21s 111ms/step - loss: 0.2465 - accuracy: 0.9152 - precision: 0.9275 - recall: 0.9052 - val_loss: 5.9040 - val_accuracy: 0.2923 - val_precision: 0.3012 - val_recall: 0.2781\n","Epoch 1260/10000\n","185/185 [==============================] - 21s 112ms/step - loss: 0.2327 - accuracy: 0.9162 - precision: 0.9323 - recall: 0.9044 - val_loss: 5.5184 - val_accuracy: 0.2994 - val_precision: 0.3085 - val_recall: 0.2847\n","Epoch 1261/10000\n","185/185 [==============================] - 22s 120ms/step - loss: 0.2431 - accuracy: 0.9154 - precision: 0.9262 - recall: 0.9047 - val_loss: 5.7559 - val_accuracy: 0.2984 - val_precision: 0.3074 - val_recall: 0.2827\n","Epoch 1262/10000\n"," 94/185 [==============>...............] - ETA: 9s - loss: 0.2208 - accuracy: 0.9219 - precision: 0.9342 - recall: 0.9112"]}],"source":["history = model.fit(X_train,y_train,batch_size=32, epochs =10000, verbose =1, validation_data=(X_Val, y_Val))"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"AxyU4bJZl-yG"},"outputs":[],"source":["valuesToPredict = X\n","pca.fit_transform(valuesToPredict)\n","output = model.predict(valuesToPredict)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"nqtiEyXmljba"},"outputs":[],"source":["import pickle\n","pickle.dump(model, open('/content/drive/MyDrive/ENG 4000/model2.pkl', 'wb'))"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"UP28t7WLoz_S"},"outputs":[],"source":["import pandas as pd\n","from sklearn.decomposition import PCA\n","def create():\n","  labels = pd.read_csv(\"/content/drive/MyDrive/ENG 4000/labels.csv\") \n","  lifetime = pd.read_csv(\"/content/drive/MyDrive/ENG 4000/lifetime.csv\")\n","  spectrum = pd.read_csv(\"/content/drive/MyDrive/ENG 4000/spectrum.csv\")\n","  scattering = pd.read_csv(\"/content/drive/MyDrive/ENG 4000/scattering.csv\")\n","  size = pd.read_csv(\"/content/drive/MyDrive/ENG 4000/size.csv\")\n","  lifetime_features = pd.read_csv(\"/content/drive/MyDrive/ENG 4000/lifetime_features.csv\")\n","  data = {'lifetime':lifetime,\n","          'spectrum':spectrum,\n","          'scattering':scattering,\n","          'size':size,\n","          'lifetime_features':lifetime_features}\n","  pd.set_option('display.max_rows',None)\n","\n","  features = pd.DataFrame()\n","\n","  for x in data:\n","    features = pd.concat([features,data[x].iloc[: , 1:]], axis=1)\n","\n","  results = pd.concat([labels, features],axis=1)\n","  results.drop(['Sample ID'], axis=1, inplace=True)\n","  X = results.drop(['Pollen'], axis=1)\n","  valuesToPredict = X\n","  pca = PCA(n_components = 0.95)\n","  pca.fit_transform(valuesToPredict)\n","  return valuesToPredict"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"0FEu3VUyl05c"},"outputs":[],"source":["# !pip install cloud-sql-python-connector==0.9.3\n","# !pip install pg8000\n","import pickle\n","valuesToPredict = create()\n","model = pickle.load(open('/content/drive/MyDrive/ENG 4000/model.pkl', 'rb'))\n","output = model.predict(valuesToPredict)\n","\n","#Working code, modified by Randy and Jimmy to be compatable with new SQL database\n","\n","from google.cloud.sql.connector import Connector, IPTypes\n","import sqlalchemy\n","\n","def getconn():\n","    with Connector() as connector:\n","        conn = connector.connect(\n","            \"potent-comfort-376221:northamerica-northeast2:the-pollen-project\", \n","            \"pg8000\",\n","            user=\"postgres\",\n","            password=\"lLyl3\\\"{xg9`X*t`Q\",\n","            db=\"postgres\",\n","            ip_type=IPTypes.PUBLIC \n","        )\n","    return conn\n","\n","pool = sqlalchemy.create_engine(\n","    \"postgresql+pg8000://\",\n","    creator=getconn,\n",")\n","\n","with pool.connect() as db_conn:\n","\n","    for X in output:\n","        cursor.execute(\"INSERT INTO model_values VALUES (\" + \"'\" + str(X[0]) + \"', \" + \"'\" + str(X[1]) + \"', \" + \"'\" + str(X[2]) + \"', \" + \"'\" + str(X[3])\n","      + \"', \" + \"'\" + str(X[4]) + \"', \" + \"'\" + str(X[5]) + \"', \" + \"'\" + str(X[6]) + \"', \" + \"'\" + str(X[7]) + \"', \" + \"'\" + str(X[8]) + \"', \" + \"'\" +\n","        str(X[9]) + \"', \" + \"'\" + str(X[10]) + \"', \" + \"'\" + str(X[11]) + \"');\")"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"R9LF3Mf-scyz"},"outputs":[],"source":["# true = 0\n","# false = 0\n","# import numpy as np\n","# import pandas as pd\n","# labels = pd.read_csv(\"/content/drive/MyDrive/ENG 4000/labels.csv\")\n","\n","# for i in range(len(output)):\n","#   if (np.argmax(output[i]) == labels.iloc[i][1]):\n","#     true += 1\n","#   else:\n","#     false += 1\n","# print(f\"True {true}\") #This value is high because a lot of these data points were used to train the model, using the validation data set, it's around 25% accurate\n","# print(f\"False {false}\")"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"_JnQx6PYmeBE"},"outputs":[],"source":["# import csv\n","\n","# with open(\"data.csv\",\"w+\") as my_csv:\n","#     csvWriter = csv.writer(my_csv,delimiter=',')\n","#     csvWriter.writerows(output)\n"]}],"metadata":{"anaconda-cloud":{},"colab":{"provenance":[]},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.7.3"}},"nbformat":4,"nbformat_minor":0}